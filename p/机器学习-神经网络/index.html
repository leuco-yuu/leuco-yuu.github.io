<!doctype html><html lang=zh_CN dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="【5】机器学习第五部分 神经网络是深度学习的开端"><meta name=keywords content="交叉熵损失,反向传播,BP,梯度下降,Dropout,BN,CNN,卷积神经网络,RNN,循环神经网络,卷积层,池化层,词嵌入层"><title>机器学习-神经网络</title><link rel=canonical href=http://localhost:1313/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/><link rel=stylesheet href=/scss/style.min.85f75f3209ee69adac3c94c489274ecc9d07b319e20cd3c86717f7734ee67869.css><meta property='og:title' content="机器学习-神经网络"><meta property='og:description' content="【5】机器学习第五部分 神经网络是深度学习的开端"><meta property='og:url' content='http://localhost:1313/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/'><meta property='og:site_name' content="Leuco's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='交叉熵损失'><meta property='article:tag' content='反向传播'><meta property='article:tag' content='BP'><meta property='article:tag' content='梯度下降'><meta property='article:tag' content='Dropout'><meta property='article:tag' content='BN'><meta property='article:tag' content='CNN'><meta property='article:tag' content='卷积神经网络'><meta property='article:tag' content='RNN'><meta property='article:tag' content='循环神经网络'><meta property='article:tag' content='卷积层'><meta property='article:tag' content='池化层'><meta property='article:tag' content='词嵌入层'><meta property='article:published_time' content='2025-12-02T20:51:17+08:00'><meta property='article:modified_time' content='2025-12-02T20:51:17+08:00'><meta property='og:image' content='http://localhost:1313/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/60aa0004-c259-49eb-b742-6515691c6d92.png'><meta name=twitter:title content="机器学习-神经网络"><meta name=twitter:description content="【5】机器学习第五部分 神经网络是深度学习的开端"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='http://localhost:1313/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/60aa0004-c259-49eb-b742-6515691c6d92.png'></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_8cf2f27a1af30ef.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Leuco's Blog</a></h1><h2 class=site-description></h2></div></header><ol class=menu-social><li><a href=https://github.com/leuco-yuu/ target=_blank title=GitHub rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2.5" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li><a href='https://mail.google.com/mail/u/0/?tf=cm&amp;to=leucoyuu@gmail.com&amp;fs=1' target=_blank title=Gmail rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="2" y="4" width="20" height="16" rx="2"/><polyline points="3,5 12,14 21,5"/></svg></a></li><li><a href='https://wpa.qq.com/msgrd?v=3&amp;uin=1286938728&amp;site=qq&amp;menu=yes/' target=_blank title=QQ rel=me><svg height="32" viewBox="0 0 32 32" width="32"><g fill="none" fill-rule="evenodd"><path d="m15.9998867.0-.3175962.00373031C8.84822.16478688 5.08430177 5.52571032 5.05900841 13.1032973L5.06 13.376l-.86256398 2.1053645c-.34339269.8459887-.59479858 1.4918602-.8236549 2.1249911-.16246446.4494579-.31092035.8862129-.4515632 1.3302912-1.41043336 4.4529342-1.46997142 7.7313526 1.14979123 8.0424546l.19586827.0182568c.69853306.0462522 1.18775172-.1357889 1.69345756-.5695745L6.008 26.385l.10703497.1859114.16295747.2641667L6.368 26.972l-.10203891.0725127c-1.18457469.8599516-1.78515849 2.0422997-.8749963 3.5478041.72014893 1.1919865 1.68579016 1.3851809 4.67654251 1.4059241h1.2781117l.7210113-.0101194c1.4578857-.0287327 2.9764342-.1065736 3.9343697-.2001215l.2555297.0243167c1.1291243.09698 2.8606159.1735357 4.3993902.1859242h1.2781118c2.9907546-.0207471 3.95642-.2139816 4.6768437-1.4064227l.0983227-.1723424c.764361-1.4241985.1648309-2.548721-.9747412-3.3755348L25.631 26.971l.0912293-.1362605.1629318-.2641511L25.992 26.385l.0466679.0427821c.5516504.4732059 1.0836451.6468525 1.8890001.5513616 2.6200145-.3116105 2.5604594-3.5895097 1.1502083-8.0424822-.136678-.4315245-.2810058-.8567817-.4385987-1.2939849l-.1781698-.4846461c-.0923296-.2464665-.1903348-.5013359-.2976536-.7744519l-.3954267-.9868956L26.939 13.376l9399e-7-.279262c-.038761-7.60576089-3.8169423-12.93053326-10.6187985-13.09291824zm1023e-7 2c6.339972 32813e-8 9.0947051 5.25726658 8.9334981 11.7557738l.8516442 2.0748544c.5606846 1.3708665.9939584 2.4718584 1.3860782 3.7098724 1.2134003 3.8314013.8203049 5.4169539.5209683 5.4525554-.6424867.0761796-2.5006035-2.8842697-2.5006035-2.8842697.0 1.7141775-.8994592 3.9510027-2.8457046 5.5664147l.3377045.1073023c1.0249215.341207 2.6653848 1.0302704 2.2154641 1.7750936-.4078113.675007-6.9962271.4309917-8.8982689.2207732l-.4753503.0452169c-2.33636.195172-8.04423656.3608021-8.42291849-.2659901-.50418989-.8339832 1.61195836-1.5976385 2.55205373-1.8820678-1.94652419-1.615412-2.84615056-3.852456-2.84615056-5.5667428l-.32111727.4924567c-.56063792.838483-1.70355568 2.4482423-2.17943051 2.391813-.29933663-.0355468-.69254342-1.6211541.52102408-5.4525554l.21887662-.6654718c.52220361-1.5311231 1.13363576-2.9515889 2.01884579-5.1193097C6.8963095 7.36281332 9.58861109 2.00032813 15.999989 2z" fill="currentColor" fill-rule="nonzero"/></g></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/%E5%8D%9A%E4%B8%BB/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>博主</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>博文</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>搜索</span></a></li><li><a href=/%E9%93%BE%E6%8E%A5/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>链接</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ul><li><a href=#前馈神经网络fnn>前馈神经网络（FNN）</a><ul><li><a href=#神经元>神经元</a></li><li><a href=#神经网络结构>神经网络结构</a><ul><li><a href=#神经网络结构模型搭建>神经网络结构模型搭建</a></li></ul></li><li><a href=#损失函数>损失函数</a><ul><li><a href=#二分类任务二元交叉熵损失sigmoid损失>二分类任务——二元交叉熵损失（Sigmoid损失）</a></li><li><a href=#多分类任务多元交叉熵损失softmax损失>多分类任务——多元交叉熵损失（Softmax损失）</a></li><li><a href=#回归损失mae损失函数l1范数曼哈顿距离>回归损失——MAE损失函数（L1范数/曼哈顿距离）</a></li><li><a href=#回归损失mse损失函数l2范数欧氏距离>回归损失——MSE损失函数（L2范数/欧氏距离）</a></li><li><a href=#回归损失smooth-l1损失函数l1与l2的结>回归损失——Smooth L1损失函数（L1与L2的结）</a></li></ul></li><li><a href=#反向传播与梯度下降>反向传播与梯度下降</a><ul><li><a href=#反向传播>反向传播</a></li><li><a href=#梯度下降>梯度下降</a></li></ul></li><li><a href=#正则化>正则化</a><ul><li><a href=#dropout正则化>Dropout正则化</a></li><li><a href=#bn层小批量归一化>BN层（小批量归一化）</a></li></ul></li><li><a href=#实践手机价格分类预测>实践——手机价格分类预测</a><ul><li><a href=#导入工具包>导入工具包</a></li><li><a href=#数据加载>数据加载</a></li><li><a href=#构建模型>构建模型</a></li><li><a href=#模型训练>模型训练</a></li><li><a href=#模型评估>模型评估</a></li><li><a href=#程序入口>程序入口</a></li></ul></li><li><a href=#实践改进手机价格分类预测>实践（改进）——手机价格分类预测</a><ul><li><a href=#工具导入>工具导入</a></li><li><a href=#数据加载-1>数据加载</a></li><li><a href=#模型构建>模型构建</a></li><li><a href=#模型训练-1>模型训练</a></li><li><a href=#模型评估-1>模型评估</a></li><li><a href=#函数入口>函数入口</a></li></ul></li></ul></li><li><a href=#卷积神经网络cnn>卷积神经网络（CNN）</a><ul><li><a href=#图像基础>图像基础</a></li><li><a href=#卷积神经网络结构>卷积神经网络结构</a><ul><li><a href=#卷积层特征提取>卷积层：特征提取</a></li><li><a href=#池化层>池化层</a></li></ul></li><li><a href=#实践--ccn实现图片分类>实践 —— CCN实现图片分类</a><ul><li><a href=#导入工具>导入工具</a></li><li><a href=#数据导入>数据导入</a></li><li><a href=#模型构建-1>模型构建</a></li><li><a href=#模型训练-2>模型训练</a></li><li><a href=#模型评估-2>模型评估</a></li><li><a href=#程序入口-1>程序入口</a></li></ul></li></ul></li><li><a href=#循环神经网络rnn>循环神经网络（RNN）</a><ul><li><a href=#自然语言处理基础>自然语言处理基础</a></li><li><a href=#文本处理与rnn网络>文本处理与RNN网络</a><ul><li><a href=#词嵌入层>词嵌入层</a></li></ul></li><li><a href=#rnn>RNN</a></li><li><a href=#词表生成>词表生成</a></li></ul></li></ul></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/><img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/60aa0004-c259-49eb-b742-6515691c6d92_hu_f396c074e5f0f2b7.png srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/60aa0004-c259-49eb-b742-6515691c6d92_hu_f396c074e5f0f2b7.png 800w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/60aa0004-c259-49eb-b742-6515691c6d92_hu_1a2c6d809391ea7c.png 1600w" width=800 height=254 loading=lazy alt="Featured image of post 机器学习-神经网络"></a></div><div class=article-details><header class=article-category><a href=/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ style=background-color:#2a9d8f;color:#fff>机器学习
</a><a href=/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/ style=background-color:#2a9d8f;color:#fff>学习笔记</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>机器学习-神经网络</a></h2><h3 class=article-subtitle>【5】机器学习第五部分 神经网络是深度学习的开端</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published datetime=2025-12-02T20:51:17+08:00>Dec 02, 2025</time></div></footer></div></header><section class=article-content><div class=custom-toc><h3>目录</h3><nav id=TableOfContents><ul><li><a href=#前馈神经网络fnn>前馈神经网络（FNN）</a><ul><li><a href=#神经元>神经元</a></li><li><a href=#神经网络结构>神经网络结构</a><ul><li><a href=#神经网络结构模型搭建>神经网络结构模型搭建</a></li></ul></li><li><a href=#损失函数>损失函数</a><ul><li><a href=#二分类任务二元交叉熵损失sigmoid损失>二分类任务——二元交叉熵损失（Sigmoid损失）</a></li><li><a href=#多分类任务多元交叉熵损失softmax损失>多分类任务——多元交叉熵损失（Softmax损失）</a></li><li><a href=#回归损失mae损失函数l1范数曼哈顿距离>回归损失——MAE损失函数（L1范数/曼哈顿距离）</a></li><li><a href=#回归损失mse损失函数l2范数欧氏距离>回归损失——MSE损失函数（L2范数/欧氏距离）</a></li><li><a href=#回归损失smooth-l1损失函数l1与l2的结>回归损失——Smooth L1损失函数（L1与L2的结）</a></li></ul></li><li><a href=#反向传播与梯度下降>反向传播与梯度下降</a><ul><li><a href=#反向传播>反向传播</a></li><li><a href=#梯度下降>梯度下降</a></li></ul></li><li><a href=#正则化>正则化</a><ul><li><a href=#dropout正则化>Dropout正则化</a></li><li><a href=#bn层小批量归一化>BN层（小批量归一化）</a></li></ul></li><li><a href=#实践手机价格分类预测>实践——手机价格分类预测</a><ul><li><a href=#导入工具包>导入工具包</a></li><li><a href=#数据加载>数据加载</a></li><li><a href=#构建模型>构建模型</a></li><li><a href=#模型训练>模型训练</a></li><li><a href=#模型评估>模型评估</a></li><li><a href=#程序入口>程序入口</a></li></ul></li><li><a href=#实践改进手机价格分类预测>实践（改进）——手机价格分类预测</a><ul><li><a href=#工具导入>工具导入</a></li><li><a href=#数据加载-1>数据加载</a></li><li><a href=#模型构建>模型构建</a></li><li><a href=#模型训练-1>模型训练</a></li><li><a href=#模型评估-1>模型评估</a></li><li><a href=#函数入口>函数入口</a></li></ul></li></ul></li><li><a href=#卷积神经网络cnn>卷积神经网络（CNN）</a><ul><li><a href=#图像基础>图像基础</a></li><li><a href=#卷积神经网络结构>卷积神经网络结构</a><ul><li><a href=#卷积层特征提取>卷积层：特征提取</a></li><li><a href=#池化层>池化层</a></li></ul></li><li><a href=#实践--ccn实现图片分类>实践 —— CCN实现图片分类</a><ul><li><a href=#导入工具>导入工具</a></li><li><a href=#数据导入>数据导入</a></li><li><a href=#模型构建-1>模型构建</a></li><li><a href=#模型训练-2>模型训练</a></li><li><a href=#模型评估-2>模型评估</a></li><li><a href=#程序入口-1>程序入口</a></li></ul></li></ul></li><li><a href=#循环神经网络rnn>循环神经网络（RNN）</a><ul><li><a href=#自然语言处理基础>自然语言处理基础</a></li><li><a href=#文本处理与rnn网络>文本处理与RNN网络</a><ul><li><a href=#词嵌入层>词嵌入层</a></li></ul></li><li><a href=#rnn>RNN</a></li><li><a href=#词表生成>词表生成</a></li></ul></li></ul></nav></div><h1 id=神经网络neural-networknn>神经网络（Neural Network，NN）</h1><h2 id=前馈神经网络fnn>前馈神经网络（FNN）</h2><h3 id=神经元>神经元</h3><ul><li>数学模型：$$output = f(b+\displaystyle{\sum_{i=1}^nx_iw_i})$$，其中 $f(x)$ 为非线性的激活函数（Activation Function）; $n$ 为输入样本的特征数量</li><li>激活函数<ul><li>Sigmoid: $$f(x) = \displaystyle{\frac{1}{1+e^{-x}}}$$<ul><li>优点：可微、有界、单调、直观</li><li>缺点：梯度消失、恒为正、饱和区</li></ul></li><li>Tanh： $$\displaystyle{f(x)=\frac{1-e^{-2x}}{1+e^{-2x}}}$$<ul><li>优点：零均值、导数幅度大、可微</li><li>缺点：梯度消失、饱和区</li></ul></li><li>ReLU： $$f(x)=\max(0,x)$$<ul><li>优点：无梯度消失、计算极简、稀疏激活、收敛更快、无界输出</li><li>缺点：神经元永久关闭、非0对称、不可微点0、对噪声敏感</li><li>ReLU扩展：<ul><li>PReLU： $$
f(x;\alpha) =
\begin{cases}
\alpha x,\ &x<0 \\
\ x, &x \ge 0
\end{cases}
$$</li><li>ELU: $$
f(x;\alpha) =
\begin{cases}
\alpha(e^x-1),\ &x<0 \\
\ x, &x \ge 0
\end{cases}
$$</li></ul></li></ul></li><li>Softmax： $f_i(x) = \displaystyle{\frac{e^{x_i}}{\sum_{j=1}^ke^{z_j}}}$<ul><li>Sigmoid常用于二分类任务的单输出结点，代表概率</li><li>Softmax常用于多分类任务的k个输出节点，代表概率</li></ul></li><li>求导：$$\displaystyle{\frac{\partial Out(w)}{\partial w}=\frac{\partial Out(w)}{\partial In(w)}\frac{\partial In(w)}{\partial w} = \frac{d f(In)}{d In}\frac{\partial In(w)}{\partial w}}$$</li></ul></li><li>图示：<img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/0039768b-8f5b-4368-8c7c-65a12aefee01.png width=427 height=288 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/0039768b-8f5b-4368-8c7c-65a12aefee01_hu_779bbf2fcc9ee41f.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/0039768b-8f5b-4368-8c7c-65a12aefee01_hu_2e68507bc6d0204d.png 1024w" loading=lazy alt=image.png class=gallery-image data-flex-grow=148 data-flex-basis=355px></li></ul><h3 id=神经网络结构>神经网络结构</h3><ul><li>MLP结构：（神经元串联）<ul><li>输入层（Input Layer）<ul><li>输入层共有n个结点（n为特征数）</li><li>每个输入结点为所有样本的某一个特征值，m行1列（m为样本数）</li></ul></li><li>隐藏层（Hidden Layer）<ul><li>MLP中神经元之间为全连接</li><li>每个连接都有一个权重值</li></ul></li><li>输出层（Output Layer）</li></ul></li><li>超参数<ul><li>隐藏层的层数</li><li>每个隐藏层的神经元个数</li></ul></li><li>参数初始化<ul><li>均匀分布初始化参数：从 $$\displaystyle{(-\frac{1}{\sqrt d},\frac{1}{\sqrt{d}})}$$，其中 d 为每个神经元的输入数量<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>uniform_</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li>正态分布初始化参数：从标准正态随机取值<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>mean</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li>全0初始化参数<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>zeros_</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>weight0</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li>全1初始化参数<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>ones_</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>weight0</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li>固定值初始化参数</li><li>KaiMing初始化（HE初始化）<ul><li>正态HE初始化： $$\displaystyle{\mathcal{N}\left(0,\sqrt{\frac{2}{in\_dim}}\right)}$$<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>kaiming_normal_</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li>均匀分布HE初始化：$$\displaystyle{\mathcal{U}\left(-\sqrt{\frac{6}{in_dim}},+\sqrt{\frac{6}{in_dim}}\right)}$$<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>kaiming_uniform_</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li></ul></li><li>Xavier初始化（Glorot初始化）<ul><li>正态Glorot初始化（默认）： $$\displaystyle{\mathcal{N}\left(0,\sqrt{\frac{2}{in\_dim+out\_dim}}\right)}$$<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>xavier_normal_</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li>均匀Glorot初始化： $$\displaystyle{\mathcal{U}\left(-\sqrt{\frac{6}{in_dim+out_dim}},+\sqrt{\frac{6}{in_dim+out_dim}}\right)}$$<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>xavier_uniform_</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li></ul></li></ul></li><li>反向传播：链式求导：Loss函数对所有参数求导</li><li>图示：（构建如下）<img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/e7cc8128-0d86-4720-8d60-551ea29186a8.png width=616 height=672 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/e7cc8128-0d86-4720-8d60-551ea29186a8_hu_1d437ce676a84211.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/e7cc8128-0d86-4720-8d60-551ea29186a8_hu_d5fadfc9d7f116a1.png 1024w" loading=lazy alt=image.png class=gallery-image data-flex-grow=91 data-flex-basis=220px></li><li>在线可视化神经网络：<a class=link href=https://playground.tensorflow.org target=_blank rel=noopener>Neural Network Playground</a></li></ul><h4 id=神经网络结构模型搭建>神经网络结构模型搭建</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchviz</span> <span class=kn>import</span> <span class=n>make_dot</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchsummary</span> <span class=kn>import</span> <span class=n>summary</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Model</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>Model</span><span class=p>,</span><span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span> <span class=c1># 调用父类初始化方法</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>in_h1_linear</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span><span class=mi>5</span><span class=p>)</span> <span class=c1># 输入层到第一隐藏层</span>
</span></span><span class=line><span class=cl>        <span class=c1># nn.init.xavier_normal_(self.in_h1_linear.weight) # 初始化方法，不用写</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>h1_h2_linear</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span><span class=mi>4</span><span class=p>)</span> <span class=c1># 第一隐藏层到第二隐藏层</span>
</span></span><span class=line><span class=cl>        <span class=c1># nn.init.kaiming_normal_(self.h1_h2_linear.weight)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>h2_out_linear</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span><span class=mi>3</span><span class=p>)</span> <span class=c1># 第二隐藏层到输出层</span>
</span></span><span class=line><span class=cl>        <span class=c1># nn.init.normal_(self.h2_out_linear.weight)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>in_h1_linear</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># 到达第一隐藏层</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># Sigmoid激活函数</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>h1_h2_linear</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># 到达第二隐藏层</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># ReLU激活函数</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>h2_out_linear</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># 到达输出层</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>x</span><span class=p>,</span><span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span> <span class=c1># 在输出层通过Softmax概率化输出（如果是多分类任务）</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span><span class=o>==</span><span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 定义模型</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>Model</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 参数量统计</span>
</span></span><span class=line><span class=cl>    <span class=n>summary</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>input_size</span><span class=o>=</span><span class=p>(</span><span class=mi>4</span><span class=p>,),</span><span class=n>batch_size</span><span class=o>=</span><span class=mi>520</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 参数打印</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>name</span><span class=p>,</span><span class=n>params</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=n>name</span><span class=p>,</span><span class=n>params</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 计算图绘制</span>
</span></span><span class=line><span class=cl>    <span class=c1># y = model(torch.tensor([1,2,3,4],dtype=torch.float32))</span>
</span></span><span class=line><span class=cl>    <span class=c1># dot = make_dot(y,params=dict(model.named_parameters()))</span>
</span></span><span class=line><span class=cl>    <span class=c1># print(dot)</span>
</span></span><span class=line><span class=cl>    
</span></span></code></pre></td></tr></table></div></div><pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Linear-1                   [520, 5]              25
            Linear-2                   [520, 4]              24
            Linear-3                   [520, 3]              15
================================================================
Total params: 64
Trainable params: 64
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.05
Params size (MB): 0.00
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
in_h1_linear.weight Parameter containing:
tensor([[-0.1587, -0.1239,  0.4235,  0.3390],
        [-0.0211, -0.4489, -0.0343, -0.0293],
        [ 0.4945,  0.1847, -0.2413, -0.1682],
        [-0.0767, -0.0808, -0.0054,  0.4703],
        [ 0.4768,  0.4413, -0.2241, -0.2929]], requires_grad=True)
in_h1_linear.bias Parameter containing:
tensor([ 0.3772,  0.1606, -0.4499,  0.3997, -0.2885], requires_grad=True)
h1_h2_linear.weight Parameter containing:
tensor([[ 0.3114,  0.1786, -0.2437,  0.1051, -0.3297],
        [ 0.2338,  0.4141,  0.3638, -0.1816,  0.1560],
        [-0.1107, -0.1953, -0.0770, -0.0711, -0.1429],
        [-0.3616, -0.2039, -0.3213, -0.0980, -0.3732]], requires_grad=True)
h1_h2_linear.bias Parameter containing:
tensor([0.0112, 0.3500, 0.1824, 0.0403], requires_grad=True)
h2_out_linear.weight Parameter containing:
tensor([[ 0.4316, -0.1131, -0.4884, -0.1070],
        [-0.4599, -0.1800, -0.4684, -0.0996],
        [-0.3372, -0.1655, -0.3222,  0.2816]], requires_grad=True)
h2_out_linear.bias Parameter containing:
tensor([0.3777, 0.2212, 0.3185], requires_grad=True)
</code></pre><p><img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/01100ff2-6efa-4602-ab43-809f23c7d51b.png width=1152 height=80 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/01100ff2-6efa-4602-ab43-809f23c7d51b_hu_50d2fca3b0c8cef3.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/01100ff2-6efa-4602-ab43-809f23c7d51b_hu_3fc3945148002637.png 1024w" loading=lazy alt=image.png class=gallery-image data-flex-grow=1440 data-flex-basis=3456px></p><h3 id=损失函数>损失函数</h3><h4 id=二分类任务二元交叉熵损失sigmoid损失>二分类任务——二元交叉熵损失（Sigmoid损失）</h4><ul><li>损失函数： $$\displaystyle{\mathcal{L}=-y\log \hat y - (1-y)\log(1-\hat y)}$$<ul><li>$ y_i $（采用 $One-Hot$ 编码）是第 $ i $ 条样本 $ x_i $ 对应的真实标签（共 $ m $ 条样本）</li><li>$\hat{y}$ 是模型预测值 $\hat{y} = \sigma(f_\theta(x_i))$</li><li>$ \sigma(·) $ 是 $ Sigmoid $ 函数，将模型输出转换为概率</li><li>$ \mathcal{L} $ 用来衡量真实值 $ y $ 与预测值 $ f_\theta(x) $ 之间的差异性损失</li></ul></li><li>Pytorch: <code>torch.nn.BCELoss()</code></li></ul><h4 id=多分类任务多元交叉熵损失softmax损失>多分类任务——多元交叉熵损失（Softmax损失）</h4><ul><li>损失函数：$$\mathcal{L} = \displaystyle{-\sum_{i=1}^my_i\log(\operatorname{S}(f_\theta(x_i)))}$$<ul><li>$ y_i $（采用 $One-Hot$ 编码）是第 $ i $ 条样本 $ x_i $ 对应的真实标签（共 $ m $ 条样本）</li><li>$ f_\theta(x_i) $ 是第 $ i $ 条样本 $ x_i $ 对应的预测值</li><li>$S(·)$ 是 $Softmax$ 激活函数，将 $x_i$ 的预测值进行概率化，输出 $x_i$ 对应每个类别的概率</li><li>$ \mathcal{L} $ 用来衡量真实值 $ y $ 与预测值 $ f_\theta(x) $ 之间的差异性损失</li></ul></li><li>Pytorch: <code>torch.nn.CrossEntropyLoss()</code></li></ul><h4 id=回归损失mae损失函数l1范数曼哈顿距离>回归损失——MAE损失函数（L1范数/曼哈顿距离）</h4><ul><li>损失函数： $$\mathcal{L} = \displaystyle{\frac{1}{m}\sum_{i=1}^m|y_i-f_\theta(x_i)|}$$<ul><li>$ y_i $ 是第 $ i $ 条样本 $ x_i $ 对应的真实值（共 $ m $ 条样本）</li><li>$ f_\theta(x_i) $ 是第 $ i $ 条样本 $ x_i $ 对应的预测值</li></ul></li><li>Pytorch： <code>torch.nn.L1Loss()</code></li></ul><h4 id=回归损失mse损失函数l2范数欧氏距离>回归损失——MSE损失函数（L2范数/欧氏距离）</h4><ul><li>损失函数： $$\mathcal{L} = \displaystyle{\frac{1}{m}\sum_{i=1}^m(y_i-f_\theta(x_i))^2}$$<ul><li>$ y_i $ 是第 $ i $ 条样本 $ x_i $ 对应的真实值（共 $ m $ 条样本）</li><li>$ f_\theta(x_i) $ 是第 $ i $ 条样本 $ x_i $ 对应的预测值</li><li>L2 Loss也常作为正则项。当预测值与目标值相差很大时容易发生梯度爆炸</li></ul></li><li>Pytorch： <code>torch.nn.MSELoss()</code></li></ul><h4 id=回归损失smooth-l1损失函数l1与l2的结>回归损失——Smooth L1损失函数（L1与L2的结）</h4><ul><li>损失函数： $$
\mathcal{L} = \displaystyle{\frac{1}{m}\sum_{i=1}^m}
\left[
\begin{cases}
\displaystyle{\frac{1}{2}(y_i-f_\theta(x_i))^2},\ & |y_i-f_\theta(x_i)|<1 \\
\displaystyle{|y_i-f_\theta(x_i)|-\frac{1}{2}}, & otherwise
\end{cases}
\right]
$$<ul><li>$ y_i $ 是第 $ i $ 条样本 $ x_i $ 对应的真实值（共 $ m $ 条样本）</li><li>$ f_\theta(x_i) $ 是第 $ i $ 条样本 $ x_i $ 对应的预测值</li><li>真实值与预测值差值在 $[-1,1]$ 区间内实际上为L2损失，解决了L1的不光滑问题</li><li>真实值与预测值差值在 $[-1,1]$ 区间外实际上为L1损失，解决了L2梯度爆炸问题</li></ul></li><li>Pytorch: <code>torch.nn.SmoothL1Loss()</code></li></ul><h3 id=反向传播与梯度下降>反向传播与梯度下降</h3><h4 id=反向传播>反向传播</h4><ul><li>前向传播（计算输出）： $$\displaystyle{Out = h(g(f(x_1w_1+Other_1)w_2+Other_2)w_3+Other_3)}$$</li><li>反向传播（链式求导）： $$\displaystyle{\frac{\partial \mathcal{Loss}}{\partial w_1} = \frac{\partial \mathcal{Loss}}{\partial Out}·\frac{\partial Out}{\partial M_3}·\frac{\partial M_3}{\partial O_2}·\frac{\partial O_2}{\partial M_2}·\frac{\partial M_2}{\partial O_1}·\frac{\partial O_1}{\partial M_1}·\frac{\partial M_1}{\partial w_1}}$$ $$\Rightarrow\displaystyle{\nabla_{w_1} \mathcal{Loss} = { \mathcal{L}}'_{\hat y}·h'_{M_3}·w_3·g'_{M_2}·w_2·f'_{M_1}·x_1}$$</li><li>参数迭代（梯度下降）： $$\displaystyle{w_1^{new} = w_1^{old}-\eta·\nabla_{w_1} \mathcal{Loss}}$$</li><li>注意：全体参数同时更新，无先后顺序。因此在计算 $$\displaystyle{\nabla_{w_1} \mathcal{Loss}}$$ 时用到的 $w_3$ 和 $w_2$ ，为 $w_3^{old}$ 和 $w_2^{old}$
<img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/601b87f3-58a2-4951-9f80-e17a7a143379.png width=704 height=493 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/601b87f3-58a2-4951-9f80-e17a7a143379_hu_785226c0dc417f37.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/601b87f3-58a2-4951-9f80-e17a7a143379_hu_437806ceb2d39330.png 1024w" loading=lazy alt=image.png class=gallery-image data-flex-grow=142 data-flex-basis=342px></li></ul><h4 id=梯度下降>梯度下降</h4><ul><li>迭代函数： $$\displaystyle{w^{new}_{ij} = w^{old}_{ij} - \eta·\frac{\partial\mathcal{L}}{\partial w_{ij}}}$$</li><li>梯度下降方式：全梯度（BGD）、随机梯度（SGD）、小批量梯度（Mini-Batch SGD，深度学习用）</li><li>传统梯度下降存在的问题<ul><li>问题一：平坦区域梯度下降缓慢</li></ul></li><li>梯度下降算法优化<ul><li>动量算法（Momentum）—— 基于指数加权平均<ul><li>设第 $ k $ 次迭代时的梯度为 $ \mathcal{G}_k $，指数加权平均梯度为$ \mathcal{E}_k $，$ k \in {1,2\dots K}$， $\beta$ 为权重系数（通常设为0.9）。有：
$$
\mathcal{E}_k =
\begin{cases}
\mathcal{G}_1,\ & k=1 \\
\beta·\mathcal{E}_{k-1} + (1-\beta)·\mathcal{G}_k,& k \ge 2
\end{cases}
$$</li><li>参数迭代： $$\displaystyle{w^{new}_{ij} = w^{old}_{ij} - \eta·\mathcal{E}_k}$$</li><li>Pytorch： <code>torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9)</code></li></ul></li><li>AdaGrad算法<ul><li>初始化学习率 $\alpha_0$ 、小常数 $\sigma=1e-6$ 、 梯度累积变量 $s_0=0$</li><li>迭代流程（第 $k$ 轮迭代）：<ol><li>从训练集中采样 $n$ 个样本的小批量，计算梯度 $\mathcal{G}_k$</li><li>累计平方梯度 $$s_k=s_{k-1}+\mathcal{G}_k\odot \mathcal{G}_k$$，$\odot$ 为逐元素相乘</li><li>学习率迭代： $$\displaystyle{\alpha_{k}=\frac{\alpha_{k-1}}{\sqrt{s_k}+\sigma}}$$</li></ol></li><li>参数迭代： $$\displaystyle{w^{new}_{ij} = w^{old}_{ij} - \alpha_{k}·\mathcal{G}_k}$$</li><li>Pytorch： <code>torch.optim.Adagrad(model.parameters(),lr=0.01)</code></li></ul></li><li>RMSProp算法 —— 对AdaGrad算法的优化<ul><li>初始化学习率 $\alpha_0$ 、小常数 $\sigma=1e-6$ 、 梯度累积变量 $s_0=0$</li><li>迭代流程（第 $k$ 轮迭代）：<ol><li>从训练集中采样 $n$ 个样本的小批量，计算梯度 $\mathcal{G}_k$</li><li>累计指数加权平均平方梯度 $$s_k=\beta·s_{k-1}+(1-\beta)·\mathcal{G}_k\odot \mathcal{G}_k$$</li><li>学习率迭代： $$\displaystyle{\alpha_k=\frac{\alpha_{k-1}}{\sqrt{s_k}+\sigma}}$$</li></ol></li><li>参数迭代： $$\displaystyle{w^{new}_{ij} = w^{old}_{ij} - \alpha_{k}·\mathcal{G}_k}$$</li><li>Pytorch： <code>torch.optim.Adagrad(model.parameters(),lr=0.01,alpha=0.9)</code></li></ul></li><li>Adam算法 —— Momentum算法+RMSProp算法<ul><li>初始化学习率 $\alpha_0$ 、小常数 $\sigma=1e-6$ 、 梯度累积变量 $s_0=0$</li><li>迭代流程（第 $k$ 轮迭代）：<ol><li>从训练集中采样 $n$ 个样本的小批量，计算梯度 $\mathcal{G}_k$</li><li>计算指数加权平均梯度为$ \mathcal{E}_k $：$$
\mathcal{E}_k =
\begin{cases}
\mathcal{G}_1,\ & k=1 \\
\beta_1·\mathcal{E}_{k-1} + (1-\beta_1)·\mathcal{G}_k,& k \ge 2
\end{cases}
$$</li><li>累计指数加权平均平方梯度 $$s_k=\beta_2·s_{k-1}+(1-\beta_2)·\mathcal{E}_k\odot \mathcal{E}_k$$</li><li>学习率迭代： $$\displaystyle{\alpha_k=\frac{\alpha_{k-1}}{\sqrt{s_k}+\sigma}}$$</li></ol></li><li>参数迭代： $$\displaystyle{w^{new}_{ij} = w^{old}_{ij} - \alpha_{k}·\mathcal{E}_k}$$</li><li>Pytorch： <code>torch.optim.Adam(model.parameters(),lr=0.01,betas=[0.9,0.99])</code></li></ul></li></ul></li><li>学习率调整策略<ul><li>等间隔学习率衰减策略：<ul><li>每隔 <code>step_size</code> 轮， <code>lr</code> 衰减至 <code>lr*gamma</code><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span><span class=n>lr</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span><span class=n>momentum</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>decelerator</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>lr_scheduler</span><span class=o>.</span><span class=n>StepLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span><span class=n>step_size</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span><span class=n>gamma</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1>#......迭代过程：</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>decelerator</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div></li></ul></li><li>指定间隔学习率衰减：指定轮次[50,125,160]<ul><li>每到指定 <code>momentum</code> 轮， <code>lr</code> 衰减至 <code>lr*gamma</code><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span><span class=n>lr</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span><span class=n>momentum</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>decelerator</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>lr_scheduler</span><span class=o>.</span><span class=n>MultiStepLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span><span class=n>milestones</span><span class=o>=</span><span class=p>[</span><span class=mi>50</span><span class=p>,</span><span class=mi>125</span><span class=p>,</span><span class=mi>160</span><span class=p>],</span><span class=n>gamma</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1>#......迭代过程：</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>decelerator</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div></li></ul></li><li>指数学习率衰减<ul><li>每次迭代 <code>lr</code> 衰减至 <code>lr*(gamma**epoch)</code><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span><span class=n>lr</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span><span class=n>momentum</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>decelerator</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>lr_scheduler</span><span class=o>.</span><span class=n>ExponentialLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span><span class=n>gamma</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1>#......迭代过程：</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>decelerator</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div></li></ul></li></ul></li></ul><h3 id=正则化>正则化</h3><ul><li>正则化目的：提高模型泛化能力，缓解过拟合。机器学习中常用L1/L2范数</li></ul><h4 id=dropout正则化>Dropout正则化</h4><ul><li>正则化思想：在训练过程中，让隐藏层神经元以超参数 $p$ 的概率停止工作或者激活函数输出置$0$，未被置$0$的神经元放大至 $\displaystyle{\frac{1}{(1-p)}}$ 倍</li><li>Pytorch：在forward方法中：<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># layer = nn.Linear(4,5)</span>
</span></span><span class=line><span class=cl><span class=c1># dropout = nn.Dropout(p=0.4) # 失活概率0.4</span>
</span></span><span class=line><span class=cl><span class=n>M</span> <span class=o>=</span> <span class=n>layer</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>dropout</span><span class=p>(</span><span class=n>M</span><span class=p>)</span> <span class=c1># 失活</span>
</span></span></code></pre></td></tr></table></div></div></li></ul><h4 id=bn层小批量归一化>BN层（小批量归一化）</h4><ul><li>BN层思想：BN层位于神经元中求和计算与非线性计算之间，即 $$\displaystyle{Input\overset{x}{\rightarrow}\left(\sum\overset{s_1}{\rightarrow} \mathcal{BN}\overset{s_2}{\rightarrow} f(s_2) \right)\rightarrow Output}$$，对 $s_1$ 进行小批量的归一化与平移缩放，数据范围为该批次的输入数据</li><li>$\mathcal{BN}$ 层实现：
$$\displaystyle{s_2 =\lambda·\left(\frac{ s_1 - \mu_B}{\sqrt{\sigma^2_B+\epsilon}}\right)+\beta}
$$<ul><li>$\lambda$ （系数）和 $\beta$ （偏置）为可学习参数，相当于对标准化后的值做一次线性变换</li><li>$ \epsilon $ 通常取 $ 1e-5 $ ，避免分母为 $ 0 $</li><li>$ \mu_B $ 为该批次样本均值， $ \mu_B = \displaystyle{\frac{1}{m}\sum^m_{i=1}x_i} $ ， $ m $ 为该批次样本数</li><li>$ \sigma^2_B $ 为该批次样本方差， $ \sigma^2_B = \displaystyle{\frac{1}{m}\sum^m_{i=1}(x_i-\mu_B)^2} $</li></ul></li></ul><h3 id=实践手机价格分类预测>实践——手机价格分类预测</h3><h4 id=导入工具包>导入工具包</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.optim</span> <span class=k>as</span> <span class=nn>optim</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>TensorDataset</span><span class=p>,</span><span class=n>DataLoader</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchsummary</span> <span class=kn>import</span> <span class=n>summary</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>make_regression</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=数据加载>数据加载</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_data</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># 数据读取</span>
</span></span><span class=line><span class=cl>    <span class=n>data_path</span> <span class=o>=</span> <span class=s1>&#39;./Dataset/4_Phone_Price_Predict/phone_price_dataset.csv&#39;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>data_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span><span class=p>,</span><span class=n>y</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,:</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span><span class=n>data</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 数据划分</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train</span><span class=p>,</span><span class=n>X_test</span><span class=p>,</span><span class=n>y_train</span><span class=p>,</span><span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>X</span><span class=p>,</span><span class=n>y</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_size</span><span class=o>=</span><span class=mf>0.8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>random_state</span><span class=o>=</span><span class=mi>428</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>stratify</span><span class=o>=</span><span class=n>y</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 转为Dataset对象</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span> <span class=o>=</span> <span class=n>TensorDataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>X_train</span><span class=o>.</span><span class=n>values</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>y_train</span><span class=o>.</span><span class=n>values</span><span class=p>)</span><span class=o>.</span><span class=n>long</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>test_dataset</span> <span class=o>=</span> <span class=n>TensorDataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>X_test</span><span class=o>.</span><span class=n>values</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>y_test</span><span class=o>.</span><span class=n>values</span><span class=p>)</span><span class=o>.</span><span class=n>long</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>train_dataset</span><span class=p>,</span><span class=n>test_dataset</span><span class=p>,</span><span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span><span class=nb>len</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>y</span><span class=p>)),</span><span class=n>X</span><span class=o>.</span><span class=n>columns</span><span class=p>,</span><span class=n>y</span><span class=o>.</span><span class=n>name</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=构建模型>构建模型</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>PhonePriceModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>in_dim</span><span class=p>,</span><span class=n>out_dim</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>PhonePriceModel</span><span class=p>,</span><span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>linear_in_h1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>in_dim</span><span class=p>,</span><span class=mi>128</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>linear_h1_h2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span><span class=mi>256</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>linear_h2_out</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span><span class=n>out_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>X</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tanh</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>linear_in_h1</span><span class=p>(</span><span class=n>X</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>X</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>linear_h1_h2</span><span class=p>(</span><span class=n>X</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>linear_h2_out</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>forward</span><span class=p>(</span><span class=n>X</span><span class=p>),</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=模型训练>模型训练</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>train_data_loader</span><span class=p>,</span><span class=n>epochs</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 准则：损失函数——交叉熵</span>
</span></span><span class=line><span class=cl>    <span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 优化方法</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span><span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>,</span><span class=n>momentum</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span> <span class=c1># 将模型搬到gpu</span>
</span></span><span class=line><span class=cl>    <span class=n>total_start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>round_start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>best</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;model&#39;</span><span class=p>:</span><span class=n>model</span><span class=p>,</span><span class=s1>&#39;loss&#39;</span><span class=p>:</span><span class=mf>10.</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span> <span class=c1># 迭代</span>
</span></span><span class=line><span class=cl>        <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>batch_index</span><span class=p>,(</span><span class=n>X</span><span class=p>,</span><span class=n>y</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_data_loader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>X</span><span class=p>,</span><span class=n>y</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span><span class=n>y</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span> <span class=c1># 梯度清零</span>
</span></span><span class=line><span class=cl>            <span class=n>y_hat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>forward</span><span class=p>(</span><span class=n>X</span><span class=p>)</span> <span class=c1># 前向传播</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>y_hat</span><span class=p>,</span><span class=n>y</span><span class=p>)</span> <span class=c1># 计算损失</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span> <span class=c1># 反向传播</span>
</span></span><span class=line><span class=cl>            <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>total</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>total_loss</span><span class=o>/</span><span class=n>total</span> <span class=o>&lt;</span> <span class=n>best</span><span class=p>[</span><span class=s1>&#39;loss&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=n>best</span><span class=p>[</span><span class=s1>&#39;model&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>model</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Model degradation!&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>epoch</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;epoch[</span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2>] | AVG_Loss:=</span><span class=si>{</span><span class=n>total_loss</span><span class=o>/</span><span class=n>total</span><span class=si>:</span><span class=s2>0.5f</span><span class=si>}</span><span class=s2> | round_time = </span><span class=si>{</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span><span class=o>-</span><span class=n>round_start</span><span class=si>:</span><span class=s2>0.3</span><span class=si>}</span><span class=s2>s | total_time = </span><span class=si>{</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span><span class=o>-</span><span class=n>total_start</span><span class=si>:</span><span class=s2>0.3</span><span class=si>}</span><span class=s2>s&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>round_start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>best</span><span class=p>[</span><span class=s1>&#39;model&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span><span class=s1>&#39;./Model/4_Phone_Price_Predict/Model.pth&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=模型评估>模型评估</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>evaluate_model</span><span class=p>(</span><span class=n>train_data_loader</span><span class=p>,</span><span class=n>test_data_loader</span><span class=p>,</span><span class=n>in_dim</span><span class=p>,</span><span class=n>out_dim</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 加载模型</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>PhonePriceModel</span><span class=p>(</span><span class=n>in_dim</span><span class=p>,</span><span class=n>out_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;./Model/4_Phone_Price_Predict/Model.pth&#39;</span><span class=p>,</span><span class=n>weights_only</span><span class=o>=</span><span class=kc>True</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>batch_index</span><span class=p>,(</span><span class=n>X</span><span class=p>,</span><span class=n>y</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_data_loader</span> <span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y_hat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>y_hat</span><span class=o>==</span><span class=n>y</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>total</span> <span class=o>+=</span> <span class=nb>len</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;TRAIN-ACC: </span><span class=si>{</span><span class=mi>100</span><span class=o>*</span><span class=p>(</span><span class=n>correct</span><span class=o>/</span><span class=n>total</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>    <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>batch_index</span><span class=p>,(</span><span class=n>X</span><span class=p>,</span><span class=n>y</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>test_data_loader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y_hat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>y_hat</span><span class=o>==</span><span class=n>y</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>total</span> <span class=o>+=</span> <span class=nb>len</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;TEST-ACC: </span><span class=si>{</span><span class=mi>100</span><span class=o>*</span><span class=p>(</span><span class=n>correct</span><span class=o>/</span><span class=n>total</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>evaluate_model</span><span class=p>(</span><span class=n>train_data_loader</span><span class=p>,</span><span class=n>test_data_loader</span><span class=p>,</span><span class=n>features_num</span><span class=p>,</span><span class=n>categories_num</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 迭代了一万次就这个结果</span>
</span></span><span class=line><span class=cl><span class=c1># TRAIN-ACC: 68.81%</span>
</span></span><span class=line><span class=cl><span class=c1># TEST-ACC: 57.50%</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>TRAIN-ACC: 68.81%
TEST-ACC: 57.50%
</code></pre><h4 id=程序入口>程序入口</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span><span class=o>==</span><span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 0、预准备</span>
</span></span><span class=line><span class=cl>    <span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>20030428</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>&#39;cuda&#39;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span> <span class=k>else</span> <span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 1、数据集加载</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span><span class=p>,</span><span class=n>test_dataset</span><span class=p>,</span><span class=n>features_num</span><span class=p>,</span><span class=n>categories_num</span><span class=p>,</span><span class=n>_</span><span class=p>,</span><span class=n>_</span><span class=o>=</span> <span class=n>load_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>train_data_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_size</span><span class=o>=</span><span class=mi>1600</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>test_data_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_size</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 2、构建模型</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>PhonePriceModel</span><span class=p>(</span><span class=n>features_num</span><span class=p>,</span><span class=n>categories_num</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Model structure and parameter statistics:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>summary</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>input_size</span><span class=o>=</span><span class=p>(</span><span class=n>features_num</span><span class=p>,),</span><span class=n>batch_size</span><span class=o>=</span><span class=n>train_data_loader</span><span class=o>.</span><span class=n>batch_size</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 3、模型训练</span>
</span></span><span class=line><span class=cl>    <span class=n>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>train_data_loader</span><span class=p>,</span><span class=n>epochs</span><span class=o>=</span><span class=mi>10000</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 4、模型评估</span>
</span></span><span class=line><span class=cl>    <span class=c1># evaluate_model(train_data_loader,features_num,categories_num)</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>Model structure and parameter statistics:
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Linear-1                [1600, 128]           2,688
            Linear-2                [1600, 256]          33,024
            Linear-3                  [1600, 4]           1,028
================================================================
Total params: 36,740
Trainable params: 36,740
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.12
Forward/backward pass size (MB): 4.74
Params size (MB): 0.14
Estimated Total Size (MB): 5.00
----------------------------------------------------------------
epoch[0] | AVG_Loss:=1.43993 | round_time = 0.0259s | total_time = 0.0259s
epoch[100] | AVG_Loss:=1.02807 | round_time = 2.17s | total_time = 2.19s
epoch[200] | AVG_Loss:=0.97904 | round_time = 2.84s | total_time = 5.03s
epoch[300] | AVG_Loss:=0.95448 | round_time = 2.11s | total_time = 7.14s
epoch[400] | AVG_Loss:=0.93392 | round_time = 2.17s | total_time = 9.32s
epoch[500] | AVG_Loss:=0.91720 | round_time = 2.62s | total_time = 11.9s
epoch[600] | AVG_Loss:=0.90214 | round_time = 2.28s | total_time = 14.2s
epoch[700] | AVG_Loss:=0.88572 | round_time = 2.23s | total_time = 16.5s
epoch[800] | AVG_Loss:=0.87118 | round_time = 2.1s | total_time = 18.6s
epoch[900] | AVG_Loss:=0.85428 | round_time = 2.48s | total_time = 21.0s
epoch[1000] | AVG_Loss:=0.81790 | round_time = 2.39s | total_time = 23.4s
epoch[1100] | AVG_Loss:=0.79489 | round_time = 2.24s | total_time = 25.7s
epoch[1200] | AVG_Loss:=0.75626 | round_time = 2.48s | total_time = 28.1s
epoch[1300] | AVG_Loss:=0.73721 | round_time = 2.29s | total_time = 30.4s
epoch[1400] | AVG_Loss:=0.73688 | round_time = 2.27s | total_time = 32.7s
epoch[1500] | AVG_Loss:=0.75798 | round_time = 2.19s | total_time = 34.9s
epoch[1600] | AVG_Loss:=0.73144 | round_time = 2.56s | total_time = 37.4s
epoch[1700] | AVG_Loss:=0.74993 | round_time = 2.28s | total_time = 39.7s
epoch[1800] | AVG_Loss:=0.73117 | round_time = 2.37s | total_time = 42.1s
epoch[1900] | AVG_Loss:=0.73371 | round_time = 2.53s | total_time = 44.6s
epoch[2000] | AVG_Loss:=0.75547 | round_time = 2.24s | total_time = 46.9s
epoch[2100] | AVG_Loss:=0.75855 | round_time = 2.33s | total_time = 49.2s
epoch[2200] | AVG_Loss:=0.74142 | round_time = 2.24s | total_time = 51.4s
epoch[2300] | AVG_Loss:=0.77747 | round_time = 2.45s | total_time = 53.9s
epoch[2400] | AVG_Loss:=0.73235 | round_time = 2.13s | total_time = 56.0s
epoch[2500] | AVG_Loss:=0.77216 | round_time = 2.22s | total_time = 58.2s
epoch[2600] | AVG_Loss:=0.79436 | round_time = 2.61s | total_time = 60.8s
epoch[2700] | AVG_Loss:=0.70371 | round_time = 2.15s | total_time = 63.0s
epoch[2800] | AVG_Loss:=0.72711 | round_time = 2.2s | total_time = 65.2s
epoch[2900] | AVG_Loss:=0.79875 | round_time = 2.37s | total_time = 67.6s
epoch[3000] | AVG_Loss:=0.77671 | round_time = 2.16s | total_time = 69.7s
epoch[3100] | AVG_Loss:=0.74079 | round_time = 2.42s | total_time = 72.1s
epoch[3200] | AVG_Loss:=0.77159 | round_time = 2.16s | total_time = 74.3s
epoch[3300] | AVG_Loss:=0.74570 | round_time = 2.55s | total_time = 76.9s
epoch[3400] | AVG_Loss:=0.74661 | round_time = 2.29s | total_time = 79.1s
epoch[3500] | AVG_Loss:=0.73534 | round_time = 2.11s | total_time = 81.3s
epoch[3600] | AVG_Loss:=0.73651 | round_time = 2.17s | total_time = 83.4s
epoch[3700] | AVG_Loss:=0.70549 | round_time = 2.32s | total_time = 85.8s
epoch[3800] | AVG_Loss:=0.72406 | round_time = 2.55s | total_time = 88.3s
epoch[3900] | AVG_Loss:=0.73777 | round_time = 2.28s | total_time = 90.6s
epoch[4000] | AVG_Loss:=0.72636 | round_time = 2.23s | total_time = 92.8s
epoch[4100] | AVG_Loss:=0.72083 | round_time = 2.62s | total_time = 95.4s
epoch[4200] | AVG_Loss:=0.76240 | round_time = 2.32s | total_time = 97.7s
epoch[4300] | AVG_Loss:=0.72299 | round_time = 2.28s | total_time = 1e+02s
epoch[4400] | AVG_Loss:=0.72510 | round_time = 2.2s | total_time = 1.02e+02s
epoch[4500] | AVG_Loss:=0.81183 | round_time = 2.7s | total_time = 1.05e+02s
epoch[4600] | AVG_Loss:=0.80652 | round_time = 2.24s | total_time = 1.07e+02s
epoch[4700] | AVG_Loss:=0.75615 | round_time = 2.2s | total_time = 1.09e+02s
epoch[4800] | AVG_Loss:=0.74941 | round_time = 2.1s | total_time = 1.11e+02s
epoch[4900] | AVG_Loss:=0.66527 | round_time = 2.52s | total_time = 1.14e+02s
epoch[5000] | AVG_Loss:=0.67272 | round_time = 2.4s | total_time = 1.16e+02s
epoch[5100] | AVG_Loss:=0.69575 | round_time = 2.28s | total_time = 1.19e+02s
epoch[5200] | AVG_Loss:=0.73091 | round_time = 2.43s | total_time = 1.21e+02s
epoch[5300] | AVG_Loss:=0.73123 | round_time = 2.38s | total_time = 1.23e+02s
epoch[5400] | AVG_Loss:=0.71328 | round_time = 2.45s | total_time = 1.26e+02s
epoch[5500] | AVG_Loss:=0.73237 | round_time = 2.21s | total_time = 1.28e+02s
epoch[5600] | AVG_Loss:=0.69641 | round_time = 2.46s | total_time = 1.31e+02s
epoch[5700] | AVG_Loss:=0.68606 | round_time = 2.3s | total_time = 1.33e+02s
epoch[5800] | AVG_Loss:=0.78586 | round_time = 2.34s | total_time = 1.35e+02s
epoch[5900] | AVG_Loss:=0.72079 | round_time = 2.49s | total_time = 1.38e+02s
epoch[6000] | AVG_Loss:=0.69734 | round_time = 2.15s | total_time = 1.4e+02s
epoch[6100] | AVG_Loss:=0.68501 | round_time = 2.36s | total_time = 1.42e+02s
epoch[6200] | AVG_Loss:=0.71024 | round_time = 2.26s | total_time = 1.45e+02s
epoch[6300] | AVG_Loss:=0.70844 | round_time = 2.48s | total_time = 1.47e+02s
epoch[6400] | AVG_Loss:=0.71109 | round_time = 2.15s | total_time = 1.49e+02s
epoch[6500] | AVG_Loss:=0.71105 | round_time = 2.34s | total_time = 1.51e+02s
epoch[6600] | AVG_Loss:=0.69019 | round_time = 2.67s | total_time = 1.54e+02s
epoch[6700] | AVG_Loss:=0.66574 | round_time = 2.27s | total_time = 1.56e+02s
epoch[6800] | AVG_Loss:=0.70853 | round_time = 2.23s | total_time = 1.59e+02s
epoch[6900] | AVG_Loss:=0.68988 | round_time = 2.46s | total_time = 1.61e+02s
epoch[7000] | AVG_Loss:=0.70364 | round_time = 2.56s | total_time = 1.64e+02s
epoch[7100] | AVG_Loss:=0.68664 | round_time = 2.19s | total_time = 1.66e+02s
epoch[7200] | AVG_Loss:=0.70823 | round_time = 2.2s | total_time = 1.68e+02s
epoch[7300] | AVG_Loss:=0.68428 | round_time = 2.58s | total_time = 1.71e+02s
epoch[7400] | AVG_Loss:=0.68428 | round_time = 2.3s | total_time = 1.73e+02s
epoch[7500] | AVG_Loss:=0.67769 | round_time = 2.25s | total_time = 1.75e+02s
epoch[7600] | AVG_Loss:=0.71397 | round_time = 2.24s | total_time = 1.77e+02s
epoch[7700] | AVG_Loss:=0.68235 | round_time = 2.43s | total_time = 1.8e+02s
epoch[7800] | AVG_Loss:=0.67531 | round_time = 2.45s | total_time = 1.82e+02s
epoch[7900] | AVG_Loss:=0.71229 | round_time = 2.16s | total_time = 1.84e+02s
epoch[8000] | AVG_Loss:=0.69479 | round_time = 2.52s | total_time = 1.87e+02s
epoch[8100] | AVG_Loss:=0.67552 | round_time = 2.37s | total_time = 1.89e+02s
epoch[8200] | AVG_Loss:=0.67883 | round_time = 2.31s | total_time = 1.92e+02s
epoch[8300] | AVG_Loss:=0.67391 | round_time = 2.28s | total_time = 1.94e+02s
epoch[8400] | AVG_Loss:=0.66348 | round_time = 2.26s | total_time = 1.96e+02s
epoch[8500] | AVG_Loss:=0.70879 | round_time = 2.78s | total_time = 1.99e+02s
epoch[8600] | AVG_Loss:=0.70171 | round_time = 2.2s | total_time = 2.01e+02s
epoch[8700] | AVG_Loss:=0.69648 | round_time = 2.2s | total_time = 2.03e+02s
epoch[8800] | AVG_Loss:=0.71258 | round_time = 2.58s | total_time = 2.06e+02s
epoch[8900] | AVG_Loss:=0.67976 | round_time = 2.44s | total_time = 2.08e+02s
epoch[9000] | AVG_Loss:=0.69145 | round_time = 2.22s | total_time = 2.11e+02s
epoch[9100] | AVG_Loss:=0.71203 | round_time = 2.17s | total_time = 2.13e+02s
epoch[9200] | AVG_Loss:=0.72272 | round_time = 2.61s | total_time = 2.15e+02s
epoch[9300] | AVG_Loss:=0.69372 | round_time = 2.31s | total_time = 2.18e+02s
epoch[9400] | AVG_Loss:=0.69941 | round_time = 2.2s | total_time = 2.2e+02s
epoch[9500] | AVG_Loss:=0.70574 | round_time = 2.13s | total_time = 2.22e+02s
epoch[9600] | AVG_Loss:=0.73976 | round_time = 2.55s | total_time = 2.25e+02s
epoch[9700] | AVG_Loss:=0.68331 | round_time = 2.39s | total_time = 2.27e+02s
epoch[9800] | AVG_Loss:=0.71937 | round_time = 2.19s | total_time = 2.29e+02s
epoch[9900] | AVG_Loss:=0.72435 | round_time = 2.47s | total_time = 2.32e+02s
</code></pre><h3 id=实践改进手机价格分类预测>实践（改进）——手机价格分类预测</h3><h4 id=工具导入>工具导入</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.optim</span> <span class=k>as</span> <span class=nn>optim</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>TensorDataset</span><span class=p>,</span><span class=n>DataLoader</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchsummary</span> <span class=kn>import</span> <span class=n>summary</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>make_regression</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=数据加载-1>数据加载</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_data</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># 数据读取</span>
</span></span><span class=line><span class=cl>    <span class=n>data_path</span> <span class=o>=</span> <span class=s1>&#39;./Dataset/4_Phone_Price_Predict/phone_price_dataset.csv&#39;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>data_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span><span class=p>,</span><span class=n>y</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,:</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span><span class=n>data</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 数据划分</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train</span><span class=p>,</span><span class=n>X_test</span><span class=p>,</span><span class=n>y_train</span><span class=p>,</span><span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>X</span><span class=p>,</span><span class=n>y</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_size</span><span class=o>=</span><span class=mf>0.8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>random_state</span><span class=o>=</span><span class=mi>428</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>stratify</span><span class=o>=</span><span class=n>y</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 转为Dataset对象</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span> <span class=o>=</span> <span class=n>TensorDataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>X_train</span><span class=o>.</span><span class=n>values</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>y_train</span><span class=o>.</span><span class=n>values</span><span class=p>)</span><span class=o>.</span><span class=n>long</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>test_dataset</span> <span class=o>=</span> <span class=n>TensorDataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>X_test</span><span class=o>.</span><span class=n>values</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>y_test</span><span class=o>.</span><span class=n>values</span><span class=p>)</span><span class=o>.</span><span class=n>long</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>train_dataset</span><span class=p>,</span><span class=n>test_dataset</span><span class=p>,</span><span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span><span class=nb>len</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>y</span><span class=p>)),</span><span class=n>X</span><span class=o>.</span><span class=n>columns</span><span class=p>,</span><span class=n>y</span><span class=o>.</span><span class=n>name</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=模型构建>模型构建</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>PhonePriceModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>in_dim</span><span class=p>,</span><span class=n>out_dim</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>PhonePriceModel</span><span class=p>,</span><span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>network</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>in_dim</span><span class=p>,</span><span class=mi>128</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm1d</span><span class=p>(</span><span class=mi>128</span><span class=p>),</span> <span class=c1># BN层——批归一化</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.3</span><span class=p>),</span> <span class=c1># </span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span><span class=mi>256</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm1d</span><span class=p>(</span><span class=mi>256</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.3</span><span class=p>),</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span><span class=mi>128</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm1d</span><span class=p>(</span><span class=mi>128</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.3</span><span class=p>),</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span><span class=n>out_dim</span><span class=p>)</span>      
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>network</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>forward</span><span class=p>(</span><span class=n>X</span><span class=p>),</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>       
</span></span></code></pre></td></tr></table></div></div><h4 id=模型训练-1>模型训练</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>train_data_loader</span><span class=p>,</span><span class=n>test_data_loader</span><span class=p>,</span><span class=n>epochs</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span><span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scheduler</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>lr_scheduler</span><span class=o>.</span><span class=n>StepLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span><span class=n>step_size</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span><span class=n>gamma</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>total_start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>round_start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>   
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>losses</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>train_accs</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>test_accs</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>batch_index</span><span class=p>,(</span><span class=n>X</span><span class=p>,</span><span class=n>y</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_data_loader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>X</span><span class=p>,</span><span class=n>y</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span><span class=n>y</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>y_hat</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>y_hat</span><span class=p>,</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>total_loss</span><span class=o>+=</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>total</span><span class=o>+=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>acc_train</span> <span class=o>=</span> <span class=n>evaluate_accuracy</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>train_data_loader</span><span class=p>,</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>acc_test</span> <span class=o>=</span> <span class=n>evaluate_accuracy</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>test_data_loader</span><span class=p>,</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>total_loss</span><span class=o>/</span><span class=n>total</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>train_accs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>acc_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>test_accs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>acc_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>epoch</span> <span class=o>%</span> <span class=mi>10</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Epoch[</span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2>]:: | Acc on Train:</span><span class=si>{</span><span class=n>acc_train</span><span class=si>:</span><span class=s2>6.3f</span><span class=si>}</span><span class=s2>% | Acc on Test:</span><span class=si>{</span><span class=n>acc_test</span><span class=si>:</span><span class=s2>6.3f</span><span class=si>}</span><span class=s2>% | &#34;</span>
</span></span><span class=line><span class=cl>                 <span class=sa>f</span><span class=s2>&#34;Loss: </span><span class=si>{</span><span class=n>total_loss</span><span class=o>/</span><span class=n>total</span><span class=si>:</span><span class=s2>.5f</span><span class=si>}</span><span class=s2> | total_time: </span><span class=si>{</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span><span class=o>-</span><span class=n>total_start</span><span class=si>:</span><span class=s2>.3</span><span class=si>}</span><span class=s2>s&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span><span class=s1>&#39;./Model/4_Phone_Price_Predict/Model_improved.pth&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>losses</span><span class=p>,</span><span class=n>train_accs</span><span class=p>,</span><span class=n>test_accs</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=模型评估-1>模型评估</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>evaluate_accuracy</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>data_loader</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>X</span><span class=p>,</span><span class=n>y</span> <span class=ow>in</span> <span class=n>data_loader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>X</span><span class=p>,</span><span class=n>y</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span><span class=n>y</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>y_hat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>y</span><span class=o>==</span><span class=n>y_hat</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>total</span><span class=o>+=</span><span class=nb>len</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mi>100</span><span class=o>*</span><span class=n>correct</span><span class=o>/</span><span class=n>total</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>evaluate_model</span><span class=p>(</span><span class=n>train_loader</span><span class=p>,</span> <span class=n>test_loader</span><span class=p>,</span> <span class=n>in_dim</span><span class=p>,</span> <span class=n>out_dim</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>PhonePriceModel</span><span class=p>(</span><span class=n>in_dim</span><span class=p>,</span><span class=n>out_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;./Model/4_Phone_Price_Predict/Model_improved.pth&#39;</span><span class=p>,</span> <span class=n>weights_only</span><span class=o>=</span><span class=kc>True</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>acc_train</span> <span class=o>=</span> <span class=n>evaluate_accuracy</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>train_loader</span><span class=p>,</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>acc_test</span> <span class=o>=</span> <span class=n>evaluate_accuracy</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>test_loader</span><span class=p>,</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Training set accuracy rate: </span><span class=si>{</span><span class=n>acc_train</span><span class=si>:</span><span class=s2>6.3f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Training set accuracy rate: </span><span class=si>{</span><span class=n>acc_test</span><span class=si>:</span><span class=s2>6.3f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>evaluate_model</span><span class=p>(</span><span class=n>train_data_loader</span><span class=p>,</span><span class=n>test_data_loader</span><span class=p>,</span><span class=n>features_num</span><span class=p>,</span><span class=n>categories_num</span><span class=p>,</span><span class=n>device</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>Training set accuracy rate: 98.062%
Training set accuracy rate: 98.750%
</code></pre><h4 id=函数入口>函数入口</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 预准备</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>20030428</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>&#39;cuda&#39;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span> <span class=k>else</span> <span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 数据加载</span>
</span></span><span class=line><span class=cl><span class=n>train_dataset</span><span class=p>,</span><span class=n>test_dataset</span><span class=p>,</span><span class=n>features_num</span><span class=p>,</span><span class=n>categories_num</span><span class=p>,</span><span class=n>_</span><span class=p>,</span><span class=n>_</span><span class=o>=</span> <span class=n>load_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>train_data_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>400</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>test_data_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>20030428</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 构建模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>PhonePriceModel</span><span class=p>(</span><span class=n>features_num</span><span class=p>,</span><span class=n>categories_num</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Model structure and parameter statistics:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>summary</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>input_size</span><span class=o>=</span><span class=p>(</span><span class=n>features_num</span><span class=p>,),</span><span class=n>batch_size</span><span class=o>=</span><span class=n>train_data_loader</span><span class=o>.</span><span class=n>batch_size</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 模型训练</span>
</span></span><span class=line><span class=cl><span class=n>losses</span><span class=p>,</span><span class=n>train_acc</span><span class=p>,</span><span class=n>test_acc</span> <span class=o>=</span> <span class=n>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>train_data_loader</span><span class=p>,</span><span class=n>test_data_loader</span><span class=p>,</span><span class=n>epochs</span><span class=o>=</span><span class=mi>110</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 图像绘制</span>
</span></span><span class=line><span class=cl><span class=n>figs</span><span class=p>,</span><span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span><span class=mi>4</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>losses</span><span class=p>)),</span><span class=n>losses</span><span class=p>,</span><span class=n>label</span><span class=o>=</span><span class=s1>&#39;loss&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;loss&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;epoch&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>losses</span><span class=p>)),[</span><span class=n>item</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span> <span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>train_acc</span><span class=p>],</span><span class=n>label</span><span class=o>=</span><span class=s1>&#39;train_acc&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>losses</span><span class=p>)),[</span><span class=n>item</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span> <span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>test_acc</span><span class=p>],</span><span class=n>label</span><span class=o>=</span><span class=s1>&#39;test_acc&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;acc_rate&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;epoch&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>Model structure and parameter statistics:
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Linear-1                 [400, 128]           2,688
       BatchNorm1d-2                 [400, 128]             256
              ReLU-3                 [400, 128]               0
           Dropout-4                 [400, 128]               0
            Linear-5                 [400, 256]          33,024
       BatchNorm1d-6                 [400, 256]             512
              ReLU-7                 [400, 256]               0
           Dropout-8                 [400, 256]               0
            Linear-9                 [400, 128]          32,896
      BatchNorm1d-10                 [400, 128]             256
             ReLU-11                 [400, 128]               0
          Dropout-12                 [400, 128]               0
           Linear-13                   [400, 4]             516
================================================================
Total params: 70,148
Trainable params: 70,148
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.03
Forward/backward pass size (MB): 6.26
Params size (MB): 0.27
Estimated Total Size (MB): 6.56
----------------------------------------------------------------
Epoch[0]:: | Acc on Train:31.812% | Acc on Test:30.750% | Loss: 1.22177 | total_time: 0.0878s
Epoch[10]:: | Acc on Train:90.625% | Acc on Test:89.750% | Loss: 0.27893 | total_time: 0.867s
Epoch[20]:: | Acc on Train:95.625% | Acc on Test:96.250% | Loss: 0.18210 | total_time: 1.64s
Epoch[30]:: | Acc on Train:96.938% | Acc on Test:97.250% | Loss: 0.19135 | total_time: 2.39s
Epoch[40]:: | Acc on Train:97.688% | Acc on Test:97.000% | Loss: 0.14767 | total_time: 3.14s
Epoch[50]:: | Acc on Train:98.188% | Acc on Test:98.250% | Loss: 0.16465 | total_time: 3.91s
Epoch[60]:: | Acc on Train:98.125% | Acc on Test:98.000% | Loss: 0.13739 | total_time: 4.66s
Epoch[70]:: | Acc on Train:98.000% | Acc on Test:97.500% | Loss: 0.13017 | total_time: 5.42s
Epoch[80]:: | Acc on Train:98.125% | Acc on Test:98.250% | Loss: 0.13842 | total_time: 6.22s
Epoch[90]:: | Acc on Train:98.250% | Acc on Test:98.000% | Loss: 0.12420 | total_time: 7.27s
Epoch[100]:: | Acc on Train:98.062% | Acc on Test:98.750% | Loss: 0.14180 | total_time: 8.12s
</code></pre><p><img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_43_1.png width=1189 height=390 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_43_1_hu_419afeff1ad9d4ed.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_43_1_hu_c1a4e9bd04ea7838.png 1024w" loading=lazy alt=png class=gallery-image data-flex-grow=304 data-flex-basis=731px></p><h2 id=卷积神经网络cnn>卷积神经网络（CNN）</h2><h3 id=图像基础>图像基础</h3><ul><li>RGB:[channel,hight,width]/[hight,width,channel]</li><li>Channel:R/G/B</li></ul><h3 id=卷积神经网络结构>卷积神经网络结构</h3><ul><li>卷积层（Conv）：负责提取图像中的局部特征</li><li>池化层（Pool）：用来大幅降低参数数量级（降维）</li><li>全连接层（FC）：输出结果
<img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/8aeabe06-5c3d-4d9a-9e51-28db07e817d8.png width=1271 height=64 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/8aeabe06-5c3d-4d9a-9e51-28db07e817d8_hu_c1e126a5a976e8cb.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/8aeabe06-5c3d-4d9a-9e51-28db07e817d8_hu_6b4d845393de2f2f.png 1024w" loading=lazy alt=image.png class=gallery-image data-flex-grow=1985 data-flex-basis=4766px></li></ul><h4 id=卷积层特征提取>卷积层：特征提取</h4><ul><li>卷积计算方式：<ul><li>单通道卷积层计算过程：$$output = input \otimes conv$$， $conv$ 称为卷积核（Convolutional Kernel），也叫滤波器（Fliter）<ul><li>单层卷积层移步大小为超参数，可以自行设置。当移步不为1时，可以在原输入矩阵四周进行填充0</li><li>计算过程：将输入矩阵的子矩阵与卷积核进行逐元素相乘再相加，得到输出矩阵的对应元素</li><li>数学公式：$$\displaystyle{Output_{[i,j]} = \sum_{m=0}^{k-1}\sum_{n=0}^{k-1}Kernel_{[m,n]}·Input_{[i+m,j+n]}}$$</li><li>图示（分别为[Step=1,NoPadding]与[Step=2,Padding]，这里的$\times$为逐元素相乘）：
<img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/22d0dc01-97bb-4570-82a5-6f3d9d8d0775.png width=492 height=292 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/22d0dc01-97bb-4570-82a5-6f3d9d8d0775_hu_829cedced2e065f9.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/22d0dc01-97bb-4570-82a5-6f3d9d8d0775_hu_ddf4b95804c70968.png 1024w" loading=lazy alt=image.png class=gallery-image data-flex-grow=168 data-flex-basis=404px><img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/bd10bdc1-6512-4aa5-87b6-2aa0919e920e.png width=562 height=371 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/bd10bdc1-6512-4aa5-87b6-2aa0919e920e_hu_77e443bdffad0654.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/bd10bdc1-6512-4aa5-87b6-2aa0919e920e_hu_4eb28bb5e5df6d13.png 1024w" loading=lazy alt=image.png class=gallery-image data-flex-grow=151 data-flex-basis=363px></li></ul></li><li>多通道卷积层计算过程：<ul><li>分别对每个通道进行卷积计算。获得一个三通道的中间计算结果</li><li>将三通道中间计算结果对应位置加和，得到单通道最终结果</li><li>图示（o11=or11+og11+ob11）：<img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/60aa0004-c259-49eb-b742-6515691c6d92.png width=762 height=242 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/60aa0004-c259-49eb-b742-6515691c6d92_hu_7d3ecba8a894780a.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/60aa0004-c259-49eb-b742-6515691c6d92_hu_4058e647d111ffec.png 1024w" loading=lazy alt=image.png class=gallery-image data-flex-grow=314 data-flex-basis=755px></li></ul></li><li>多通道输入与多通道输出<ul><li>多通道输出需多卷积核分别进行卷积计算后结果堆叠</li><li>图示：<img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/93a570a5-1c08-4bbc-b98f-a2d25b252208.png width=742 height=397 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/93a570a5-1c08-4bbc-b98f-a2d25b252208_hu_1dc3480473613471.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/93a570a5-1c08-4bbc-b98f-a2d25b252208_hu_5dcd8e902ffb7728.png 1024w" loading=lazy alt=image.png class=gallery-image data-flex-grow=186 data-flex-basis=448px></li></ul></li><li>参数对应关系：<ul><li>输入图像大小：$I\times I$</li><li>卷积核大小：$C\times C$ ，$C$ 一般为奇数</li><li>步长：$S$</li><li>填充圈：$P$ ，0填充</li><li>输出结果大小： $O\times O$，其中 $$\displaystyle{O = 1+\frac{I-C+2P}{S}}$$</li></ul></li></ul></li><li>Pytorch<ul><li>常用：<code>torch.nn.ConvXd(in_channel,out_channel,kernel_size,stride,padding)</code>，其中X为1，2，3</li><li><code>Con1d</code>：滑动维度1，核形状为$(c,)$，用于文本/语音/时序数据。主要领域：NLP/信号处理</li><li><code>Con2d</code>：滑动维度2，核形状为$(c,c)$，用于图像/视频数据。主要领域：NLP/信号处理</li><li><code>Con3d</code>：滑动维度3，核形状为$(c,c,c)$，用于医学体数据/视频体积。主要领域：医疗影像/视频分析</li></ul></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 图像读取与matplotlib绘制</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=s1>&#39;./Material/CNN/test01.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=nb>type</span><span class=p>(</span><span class=n>img</span><span class=p>),</span><span class=n>img</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 创建卷积层</span>
</span></span><span class=line><span class=cl><span class=n>conv</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span><span class=n>out_channels</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span><span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span><span class=n>padding</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># plt的图像读取顺序为 [hight,width,channel]</span>
</span></span><span class=line><span class=cl><span class=c1># 而Conv2d的图像接收顺序为 [batch_size,channel,hight,width]</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>img</span><span class=p>)</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>)</span> <span class=c1># 维度调整 (380,380,3) =&gt; (3,380,380)</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span> <span class=c1># 插入第一个维度 (3,380,380) =&gt; (1,3,380,380)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>feature_map_img</span> <span class=o>=</span> <span class=n>conv</span><span class=p>(</span><span class=n>img</span><span class=o>.</span><span class=n>float</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 归一化后查看卷积后的第一层输出</span>
</span></span><span class=line><span class=cl><span class=n>f</span> <span class=o>=</span> <span class=n>feature_map_img</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>f</span> <span class=o>=</span> <span class=p>((</span><span class=n>f</span> <span class=o>-</span> <span class=n>f</span><span class=o>.</span><span class=n>min</span><span class=p>())</span> <span class=o>/</span> <span class=p>(</span><span class=n>f</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>-</span> <span class=n>f</span><span class=o>.</span><span class=n>min</span><span class=p>())</span><span class=o>*</span> <span class=mi>255</span><span class=p>)</span><span class=o>.</span><span class=n>int</span><span class=p>()</span><span class=o>.</span><span class=n>squeeze</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>f</span><span class=p>,</span><span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>&lt;class 'numpy.ndarray'&gt; (380, 380, 3)
</code></pre><p><img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_48_1.png width=515 height=245 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_48_1_hu_cd843bfa325a65d3.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_48_1_hu_c72ca132345adcf.png 1024w" loading=lazy alt=png class=gallery-image data-flex-grow=210 data-flex-basis=504px></p><h4 id=池化层>池化层</h4><ul><li>池化处理输入矩阵的思想与卷积相似，但是不设置卷积核。而是在输入矩阵自身进行数据处理</li><li>池化层的目的是降低特征图维度，减少计算量。同时保证平移不变性。防止过拟合</li><li>池化层不会改变输入的通道数</li><li>图示（池化窗口大小为3，步长为1）：<img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/3bbc113c-e0db-4925-9ef2-161cc59edf1e.png width=588 height=298 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/3bbc113c-e0db-4925-9ef2-161cc59edf1e_hu_cec3de2a04ae5c7b.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/3bbc113c-e0db-4925-9ef2-161cc59edf1e_hu_8ed0ef7438e62eb9.png 1024w" loading=lazy alt=image.png class=gallery-image data-flex-grow=197 data-flex-basis=473px></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 图像读取与matplotlib绘制</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=s1>&#39;./Material/CNN/test01.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=nb>type</span><span class=p>(</span><span class=n>img</span><span class=p>),</span><span class=n>img</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>3</span><span class=p>,</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>kernel_size</span><span class=p>,</span><span class=n>stride</span> <span class=o>=</span> <span class=p>(</span><span class=mi>10</span><span class=p>,</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 最大池化</span>
</span></span><span class=line><span class=cl><span class=n>max_pool</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=n>kernel_size</span><span class=p>,</span><span class=n>stride</span><span class=o>=</span><span class=n>stride</span><span class=p>,</span><span class=n>padding</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 平均池化</span>
</span></span><span class=line><span class=cl><span class=n>avg_pool</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>AvgPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=n>kernel_size</span><span class=p>,</span><span class=n>stride</span><span class=o>=</span><span class=n>stride</span><span class=p>,</span><span class=n>padding</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 池化</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>img</span><span class=p>)</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>img</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>max_img</span> <span class=o>=</span> <span class=n>max_pool</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>avg_img</span> <span class=o>=</span> <span class=n>avg_pool</span><span class=p>(</span><span class=n>img</span><span class=o>.</span><span class=n>float</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 可视化</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>3</span><span class=p>,</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>max_img</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>numpy</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>3</span><span class=p>,</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>avg_img</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>int</span><span class=p>()</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>numpy</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>&lt;class 'numpy.ndarray'&gt; (380, 380, 3)
torch.Size([1, 3, 380, 380])
</code></pre><p><img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_50_1.png width=515 height=165 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_50_1_hu_9f00a72b5529c035.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_50_1_hu_f8844d1ac41d3766.png 1024w" loading=lazy alt=png class=gallery-image data-flex-grow=312 data-flex-basis=749px></p><h3 id=实践--ccn实现图片分类>实践 —— CCN实现图片分类</h3><ul><li>数据集简介<ul><li>名称：CIFAR-10 (Canadian Institute For Advanced Research)</li><li>类型：彩色图像分类数据集</li><li>规模：60,000张32×32像素的彩色图像</li><li>类别数：10个类别</li><li>划分：50,000张训练集 + 10,000张测试集</li></ul></li><li>模型结构（原始）：<img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dd2566e8-6e7e-47f1-8eb0-182175408950.png width=524 height=839 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dd2566e8-6e7e-47f1-8eb0-182175408950_hu_eccb23a47963c305.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dd2566e8-6e7e-47f1-8eb0-182175408950_hu_b72595068875283.png 1024w" loading=lazy alt=image.png class=gallery-image data-flex-grow=62 data-flex-basis=149px></li></ul><h4 id=导入工具>导入工具</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision.datasets</span> <span class=kn>import</span> <span class=n>CIFAR10</span> <span class=c1># 数据集</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision.transforms</span> <span class=kn>import</span> <span class=n>ToTensor</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision.transforms</span> <span class=kn>import</span> <span class=n>Compose</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision.transforms</span> <span class=kn>import</span> <span class=n>Normalize</span><span class=p>,</span><span class=n>RandomHorizontalFlip</span><span class=p>,</span><span class=n>RandomCrop</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.optim</span> <span class=k>as</span> <span class=nn>optim</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>DataLoader</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchsummary</span> <span class=kn>import</span> <span class=n>summary</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=数据导入>数据导入</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_dataset</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>transform</span> <span class=o>=</span> <span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=n>RandomHorizontalFlip</span><span class=p>(),</span> <span class=c1># 50%概率进行翻转</span>
</span></span><span class=line><span class=cl>        <span class=n>RandomCrop</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span><span class=n>padding</span><span class=o>=</span><span class=mi>4</span><span class=p>),</span> <span class=c1>#  四周填充4像素0.然后随机裁剪至32*32</span>
</span></span><span class=line><span class=cl>        <span class=n>ToTensor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=n>Normalize</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=p>(</span><span class=mf>0.4914</span><span class=p>,</span> <span class=mf>0.4822</span><span class=p>,</span> <span class=mf>0.4465</span><span class=p>),</span> <span class=n>std</span><span class=o>=</span><span class=p>(</span><span class=mf>0.2023</span><span class=p>,</span> <span class=mf>0.1994</span><span class=p>,</span> <span class=mf>0.2010</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span> <span class=o>=</span> <span class=n>CIFAR10</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>root</span> <span class=o>=</span> <span class=s1>&#39;./Dataset/5_CIFAR10&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>transform</span><span class=o>=</span><span class=n>transform</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>download</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>test_dataset</span> <span class=o>=</span> <span class=n>CIFAR10</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>root</span> <span class=o>=</span> <span class=s1>&#39;./Dataset/5_CIFAR10&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>transform</span><span class=o>=</span><span class=n>Compose</span><span class=p>([</span><span class=n>ToTensor</span><span class=p>(),</span><span class=n>Normalize</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=p>(</span><span class=mf>0.4914</span><span class=p>,</span> <span class=mf>0.4822</span><span class=p>,</span> <span class=mf>0.4465</span><span class=p>),</span> <span class=n>std</span><span class=o>=</span><span class=p>(</span><span class=mf>0.2023</span><span class=p>,</span> <span class=mf>0.1994</span><span class=p>,</span> <span class=mf>0.2010</span><span class=p>))]),</span>
</span></span><span class=line><span class=cl>        <span class=n>download</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>show_train_dataset</span> <span class=o>=</span> <span class=n>CIFAR10</span><span class=p>(</span> <span class=c1>#用来可视化展示</span>
</span></span><span class=line><span class=cl>        <span class=n>root</span> <span class=o>=</span> <span class=s1>&#39;./Dataset/5_CIFAR10&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>transform</span><span class=o>=</span><span class=n>Compose</span><span class=p>([</span><span class=n>ToTensor</span><span class=p>()]),</span>
</span></span><span class=line><span class=cl>        <span class=n>download</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>show_test_dataset</span> <span class=o>=</span> <span class=n>CIFAR10</span><span class=p>(</span> <span class=c1>#用来可视化展示</span>
</span></span><span class=line><span class=cl>        <span class=n>root</span> <span class=o>=</span> <span class=s1>&#39;./Dataset/5_CIFAR10&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>transform</span><span class=o>=</span><span class=n>Compose</span><span class=p>([</span><span class=n>ToTensor</span><span class=p>()]),</span>
</span></span><span class=line><span class=cl>        <span class=n>download</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>sample_shape</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=nb>iter</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>))[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=n>categories_num</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>train_dataset</span><span class=o>.</span><span class=n>targets</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>target_names</span> <span class=o>=</span> <span class=n>train_dataset</span><span class=o>.</span><span class=n>classes</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>train_dataset</span><span class=p>,</span><span class=n>test_dataset</span><span class=p>,</span><span class=n>show_train_dataset</span><span class=p>,</span><span class=n>show_test_dataset</span><span class=p>,</span><span class=n>sample_shape</span><span class=p>,</span><span class=n>categories_num</span><span class=p>,</span><span class=n>target_names</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=模型构建-1>模型构建</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ImageClassifierModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>out_dim</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>ImageClassifierModel</span><span class=p>,</span><span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=c1># 卷积层与池化层</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span><span class=n>out_channels</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span><span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=mi>32</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span><span class=n>out_channels</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span><span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span><span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span><span class=n>out_channels</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span><span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=mi>64</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span><span class=n>out_channels</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span><span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span><span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>           
</span></span><span class=line><span class=cl>            <span class=c1># 全连接层</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Flatten</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>in_features</span><span class=o>=</span><span class=mi>64</span><span class=o>*</span><span class=mi>15</span><span class=o>*</span><span class=mi>15</span><span class=p>,</span><span class=n>out_features</span><span class=o>=</span><span class=mi>512</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm1d</span><span class=p>(</span><span class=mi>512</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.4</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>in_features</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span><span class=n>out_features</span><span class=o>=</span><span class=mi>128</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm1d</span><span class=p>(</span><span class=mi>128</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.4</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>in_features</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span><span class=n>out_features</span><span class=o>=</span><span class=n>out_dim</span><span class=p>),</span>  
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>forward</span><span class=p>(</span><span class=n>X</span><span class=p>),</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>ImageClassifierModel</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>summary</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>input_size</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>32</span><span class=p>,</span><span class=mi>32</span><span class=p>),</span><span class=n>batch_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [1, 32, 32, 32]             896
       BatchNorm2d-2            [1, 32, 32, 32]              64
              ReLU-3            [1, 32, 32, 32]               0
            Conv2d-4            [1, 32, 32, 32]           9,248
              ReLU-5            [1, 32, 32, 32]               0
         MaxPool2d-6            [1, 32, 16, 16]               0
            Conv2d-7            [1, 64, 16, 16]          18,496
       BatchNorm2d-8            [1, 64, 16, 16]             128
              ReLU-9            [1, 64, 16, 16]               0
           Conv2d-10            [1, 64, 16, 16]          36,928
             ReLU-11            [1, 64, 16, 16]               0
        MaxPool2d-12            [1, 64, 15, 15]               0
          Flatten-13                 [1, 14400]               0
           Linear-14                   [1, 512]       7,373,312
      BatchNorm1d-15                   [1, 512]           1,024
             ReLU-16                   [1, 512]               0
          Dropout-17                   [1, 512]               0
           Linear-18                   [1, 128]          65,664
      BatchNorm1d-19                   [1, 128]             256
             ReLU-20                   [1, 128]               0
          Dropout-21                   [1, 128]               0
           Linear-22                    [1, 10]           1,290
================================================================
Total params: 7,507,306
Trainable params: 7,507,306
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 2.18
Params size (MB): 28.64
Estimated Total Size (MB): 30.83
----------------------------------------------------------------
</code></pre><h4 id=模型训练-2>模型训练</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>train_data_loader</span><span class=p>,</span><span class=n>test_data_loader</span><span class=p>,</span><span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span><span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>,</span><span class=n>betas</span><span class=o>=</span><span class=p>[</span><span class=mf>0.9</span><span class=p>,</span><span class=mf>0.99</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>scheduler</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>lr_scheduler</span><span class=o>.</span><span class=n>StepLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span><span class=n>step_size</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span><span class=n>gamma</span><span class=o>=</span><span class=mf>0.8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>total_start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>round_start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>losses</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>accs_train</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>accs_test</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>max_acc</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>epoch_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>epoch_total</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>batch_index</span><span class=p>,(</span><span class=n>X</span><span class=p>,</span><span class=n>y</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_data_loader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>X</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>y_hat</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>y_hat</span><span class=p>,</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>epoch_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>epoch_total</span> <span class=o>+=</span> <span class=mi>1</span>   
</span></span><span class=line><span class=cl>        <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>avg_epo_loss</span> <span class=o>=</span> <span class=n>epoch_loss</span> <span class=o>/</span> <span class=n>epoch_total</span>
</span></span><span class=line><span class=cl>        <span class=n>losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>avg_epo_loss</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>epoch</span> <span class=o>%</span> <span class=mi>10</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>acc_train</span> <span class=o>=</span> <span class=n>evaluate_accuracy</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>train_data_loader</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>acc_test</span><span class=o>=</span> <span class=n>evaluate_accuracy</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>test_data_loader</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>accs_test</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>acc_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>accs_train</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>acc_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Epoch[</span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2>]: Loss=</span><span class=si>{</span><span class=n>loss</span><span class=si>:</span><span class=s2>.5f</span><span class=si>}</span><span class=s2> | &#34;</span>
</span></span><span class=line><span class=cl>                 <span class=sa>f</span><span class=s2>&#34;Acc_train=</span><span class=si>{</span><span class=n>acc_train</span><span class=o>*</span><span class=mi>100</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>% | Acc_test=</span><span class=si>{</span><span class=n>acc_test</span><span class=o>*</span><span class=mi>100</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>% | &#34;</span>
</span></span><span class=line><span class=cl>                 <span class=sa>f</span><span class=s2>&#34;total_time=</span><span class=si>{</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span><span class=o>-</span><span class=n>total_start</span><span class=si>:</span><span class=s2>0.2f</span><span class=si>}</span><span class=s2>s | &#34;</span>
</span></span><span class=line><span class=cl>                 <span class=sa>f</span><span class=s2>&#34;roud_time=</span><span class=si>{</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span><span class=o>-</span><span class=n>round_start</span><span class=si>:</span><span class=s2>0.2f</span><span class=si>}</span><span class=s2>s&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>round_start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span><span class=p>(</span><span class=n>acc_test</span><span class=o>&gt;</span><span class=n>max_acc</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>max_acc</span> <span class=o>=</span> <span class=n>acc_test</span>
</span></span><span class=line><span class=cl>                <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span><span class=s1>&#39;./Model/5_CIFAR10/Model_MAX.pth&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;model saved&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span> <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;*&#34;</span><span class=p>,</span><span class=n>end</span><span class=o>=</span><span class=s2>&#34;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>losses</span><span class=p>,</span><span class=n>accs_train</span><span class=p>,</span><span class=n>accs_test</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 模型保存</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span><span class=s1>&#39;./Model/5_CIFAR10/Model.pth&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 模型加载</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>ImageClassifierModel</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;./Model/5_CIFAR10/Model.pth&#39;</span><span class=p>,</span> <span class=n>weights_only</span><span class=o>=</span><span class=kc>True</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>&lt;All keys matched successfully&gt;
</code></pre><h4 id=模型评估-2>模型评估</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>evaluate_accuracy</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>data_loader</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>epoch_num</span><span class=p>,(</span><span class=n>X</span><span class=p>,</span><span class=n>y</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>data_loader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>X</span><span class=p>,</span><span class=n>y</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span><span class=n>y</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>y</span><span class=o>==</span><span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>))</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>total</span><span class=o>+=</span><span class=nb>len</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>    
</span></span><span class=line><span class=cl>    <span class=k>return</span>  <span class=nb>float</span><span class=p>(</span><span class=n>correct</span><span class=p>)</span> <span class=o>/</span> <span class=nb>float</span><span class=p>(</span><span class=n>total</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>&#39;cuda&#39;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span> <span class=k>else</span> <span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>evaluate_accuracy</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>test_data_loader</span><span class=p>,</span><span class=n>device</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>0.8782
</code></pre><h4 id=程序入口-1>程序入口</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>20030428</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 数据导入</span>
</span></span><span class=line><span class=cl><span class=n>train_dataset</span><span class=p>,</span><span class=n>test_dataset</span><span class=p>,</span><span class=n>show_train_dataset</span><span class=p>,</span><span class=n>show_test_dataset</span><span class=p>,</span><span class=n>sample_shape</span><span class=p>,</span><span class=n>categories_num</span><span class=p>,</span><span class=n>target_names</span><span class=o>=</span><span class=n>load_dataset</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># 图片展示</span>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span><span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>10</span><span class=p>,</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span><span class=mi>4</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>indexs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>show_train_dataset</span><span class=p>),</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>axes</span><span class=o>.</span><span class=n>flatten</span><span class=p>()),))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>ax</span><span class=p>,</span><span class=n>index</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>axes</span><span class=o>.</span><span class=n>flatten</span><span class=p>(),</span><span class=n>indexs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>show_train_dataset</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=n>index</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=n>target_names</span><span class=p>[</span><span class=n>show_train_dataset</span><span class=o>.</span><span class=n>targets</span><span class=p>[</span><span class=n>index</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>​<br><img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_65_0.png width=1189 height=395 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_65_0_hu_547101f09dae52cb.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_65_0_hu_8f7245eaa4a2bc2f.png 1024w" loading=lazy alt=png class=gallery-image data-flex-grow=301 data-flex-basis=722px>
​</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 构建dataloader</span>
</span></span><span class=line><span class=cl><span class=n>train_data_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>800</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>test_data_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>test_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 模型训练</span>
</span></span><span class=line><span class=cl><span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>&#39;cuda&#39;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span> <span class=k>else</span> <span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>ImageClassifierModel</span><span class=p>(</span><span class=n>categories_num</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>losses</span><span class=p>,</span><span class=n>accs_train</span><span class=p>,</span><span class=n>accs_test</span> <span class=o>=</span> <span class=n>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>train_data_loader</span><span class=p>,</span><span class=n>test_data_loader</span><span class=p>,</span><span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>Epoch[0]: Loss=1.28191 | Acc_train=50.70% | Acc_test=53.65% | total_time=37.15s | roud_time=37.15s
model saved
*********
Epoch[10]: Loss=0.60261 | Acc_train=79.50% | Acc_test=79.24% | total_time=260.99s | roud_time=223.84s
model saved
*********
Epoch[20]: Loss=0.43514 | Acc_train=85.86% | Acc_test=83.46% | total_time=485.54s | roud_time=224.55s
model saved
*********
Epoch[30]: Loss=0.47816 | Acc_train=86.80% | Acc_test=84.15% | total_time=715.66s | roud_time=230.11s
model saved
*********
Epoch[40]: Loss=0.35383 | Acc_train=90.38% | Acc_test=85.85% | total_time=937.06s | roud_time=221.40s
model saved
*********
Epoch[50]: Loss=0.28711 | Acc_train=92.13% | Acc_test=86.99% | total_time=1577.17s | roud_time=640.12s
model saved
*********
Epoch[60]: Loss=0.22160 | Acc_train=94.10% | Acc_test=87.74% | total_time=1800.40s | roud_time=223.23s
model saved
*********
Epoch[70]: Loss=0.27528 | Acc_train=94.15% | Acc_test=87.33% | total_time=2026.66s | roud_time=226.26s
*********
Epoch[80]: Loss=0.21769 | Acc_train=94.80% | Acc_test=87.86% | total_time=2271.28s | roud_time=244.62s
model saved
*********
Epoch[90]: Loss=0.23167 | Acc_train=95.58% | Acc_test=88.11% | total_time=2493.92s | roud_time=222.63s
model saved
*********
</code></pre><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 预测结果可视化</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span><span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span><span class=mi>10</span><span class=p>,</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span><span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=c1># indexs1 = []</span>
</span></span><span class=line><span class=cl><span class=c1># max = 0.</span>
</span></span><span class=line><span class=cl><span class=c1># for i in range(1000):</span>
</span></span><span class=line><span class=cl><span class=c1>#     indexs = torch.randint(len(show_test_dataset),size=(len(axes.flatten()),))</span>
</span></span><span class=line><span class=cl><span class=c1>#     X_batch = torch.tensor(test_dataset.data[indexs]).permute(0,3,1,2).float().to(device)</span>
</span></span><span class=line><span class=cl><span class=c1>#     y_hat = model.predict(X_batch).cpu().numpy()</span>
</span></span><span class=line><span class=cl><span class=c1>#     y_true = [test_dataset.targets[index] for index in indexs]</span>
</span></span><span class=line><span class=cl><span class=c1>#     m = (y_hat==y_true).sum()/len(y_hat)</span>
</span></span><span class=line><span class=cl><span class=c1>#     if m&gt;max :</span>
</span></span><span class=line><span class=cl><span class=c1>#         max = m</span>
</span></span><span class=line><span class=cl><span class=c1>#         indexs1 = indexs </span>
</span></span><span class=line><span class=cl><span class=c1># indexs = indexs1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>indexs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>show_test_dataset</span><span class=p>),</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>axes</span><span class=o>.</span><span class=n>flatten</span><span class=p>()),))</span>
</span></span><span class=line><span class=cl><span class=c1># print(f&#34;ACC: {max*100:.2f}%&#34;)</span>
</span></span><span class=line><span class=cl><span class=c1># X_batch = torch.tensor(test_dataset[indexs][0]).permute(0,3,1,2).float().to(device)</span>
</span></span><span class=line><span class=cl><span class=n>X_batch</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>test_dataset</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>indexs</span><span class=p>])</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y_hat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_batch</span><span class=p>)</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>y_true</span> <span class=o>=</span> <span class=p>[</span><span class=n>test_dataset</span><span class=o>.</span><span class=n>targets</span><span class=p>[</span><span class=n>index</span><span class=p>]</span> <span class=k>for</span> <span class=n>index</span> <span class=ow>in</span> <span class=n>indexs</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>m</span> <span class=o>=</span> <span class=p>(</span><span class=n>y_hat</span><span class=o>==</span><span class=n>y_true</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>y_hat</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;ACC: </span><span class=si>{</span><span class=n>m</span><span class=o>*</span><span class=mi>100</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>ind</span><span class=p>,</span><span class=n>ax</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>axes</span><span class=o>.</span><span class=n>flatten</span><span class=p>()):</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>show_test_dataset</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=n>indexs</span><span class=p>[</span><span class=n>ind</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=s1>&#39;√&#39;</span> <span class=k>if</span> <span class=n>test_dataset</span><span class=o>.</span><span class=n>targets</span><span class=p>[</span><span class=n>indexs</span><span class=p>[</span><span class=n>ind</span><span class=p>]]</span><span class=o>==</span><span class=n>y_hat</span><span class=p>[</span><span class=n>ind</span><span class=p>]</span> <span class=k>else</span> <span class=s1>&#39;×&#39;</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=n>target_names</span><span class=p>[</span><span class=n>y_hat</span><span class=p>[</span><span class=n>ind</span><span class=p>]]</span><span class=o>+</span><span class=s2>&#34; &#34;</span><span class=o>+</span> <span class=n>result</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>ACC: 86.00%
</code></pre><p><img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_68_1.png width=1181 height=590 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_68_1_hu_623101a6fab3b0d6.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_68_1_hu_3c05fe13b6d0f738.png 1024w" loading=lazy alt=png class=gallery-image data-flex-grow=200 data-flex-basis=480px></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision</span> <span class=kn>import</span> <span class=n>transforms</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>item_identifier</span><span class=p>(</span><span class=n>path</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>pil_img</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>path</span><span class=p>)</span><span class=o>.</span><span class=n>convert</span><span class=p>(</span><span class=s1>&#39;RGB&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>resize</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Resize</span><span class=p>((</span><span class=mi>320</span><span class=p>,</span> <span class=mi>320</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>pil_img</span> <span class=o>=</span> <span class=n>resize</span><span class=p>(</span><span class=n>pil_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>transform</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>Resize</span><span class=p>((</span><span class=mi>32</span><span class=p>,</span> <span class=mi>32</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>             <span class=c1># ② 转成 tensor，并把 0~255 映射到 0~1</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=p>(</span><span class=mf>0.4914</span><span class=p>,</span> <span class=mf>0.4822</span><span class=p>,</span> <span class=mf>0.4465</span><span class=p>),</span>   <span class=c1># ③ 归一化</span>
</span></span><span class=line><span class=cl>                         <span class=n>std</span> <span class=o>=</span><span class=p>(</span><span class=mf>0.2023</span><span class=p>,</span> <span class=mf>0.1994</span><span class=p>,</span> <span class=mf>0.2010</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>item</span> <span class=o>=</span> <span class=n>transform</span><span class=p>(</span><span class=n>pil_img</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>item</span><span class=p>,</span><span class=n>item</span><span class=p>],</span><span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y_hat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>data</span><span class=p>)</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>[</span><span class=n>target_names</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>y_hat</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;predict: &#34;</span> <span class=o>+</span> <span class=n>item_identifier</span><span class=p>(</span><span class=s1>&#39;./Material/CNN/dog01.jpg&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;predict: &#34;</span> <span class=o>+</span> <span class=n>item_identifier</span><span class=p>(</span><span class=s1>&#39;./Material/CNN/cat01.jpg&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;predict: &#34;</span> <span class=o>+</span> <span class=n>item_identifier</span><span class=p>(</span><span class=s1>&#39;./Material/CNN/cat02.jpg&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;predict: &#34;</span> <span class=o>+</span> <span class=n>item_identifier</span><span class=p>(</span><span class=s1>&#39;./Material/CNN/airplane.webp&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;predict: &#34;</span> <span class=o>+</span> <span class=n>item_identifier</span><span class=p>(</span><span class=s1>&#39;./Material/CNN/airplane02.webp&#39;</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>predict: dog
predict: cat
predict: cat
predict: airplane
predict: airplane
</code></pre><h2 id=循环神经网络rnn>循环神经网络（RNN）</h2><h3 id=自然语言处理基础>自然语言处理基础</h3><ul><li>通过计算机算法来理解自然语言（非结构化数据）</li><li>预处理：分词（对原始自然语言进行分词）</li><li>常用分词库：jieba</li></ul><h3 id=文本处理与rnn网络>文本处理与RNN网络</h3><ul><li>文本预处理：分词、构建词汇表、序列填充</li><li>词嵌入：将离散词ID转换为密集向量</li><li>RNN顺序处理：逐时间步处理、输出下一个词的概率分布</li><li>任务特定输出：序列到序列、序列到标签</li><li>训练与反向传播</li></ul><h4 id=词嵌入层>词嵌入层</h4><ul><li>目的：根据输入词构建词向量矩阵（m个词转换为m*n数值矩阵，n为维度）</li><li>Pytorch：<code>torch.nn.Emnedding(num_embeddings=m,embedding_dim=n)</code></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>jieba</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 分词</span>
</span></span><span class=line><span class=cl><span class=n>jieba</span><span class=o>.</span><span class=n>add_word</span><span class=p>(</span><span class=s2>&#34;电子科技大学&#34;</span><span class=p>)</span> <span class=c1># 指定词</span>
</span></span><span class=line><span class=cl><span class=n>uestc</span> <span class=o>=</span> <span class=s2>&#34;电子科技大学（UESTC）位于四川成都，是中华人民共和国教育部直属全国重点大学&#34;</span>
</span></span><span class=line><span class=cl><span class=n>words</span> <span class=o>=</span> <span class=n>jieba</span><span class=o>.</span><span class=n>lcut</span><span class=p>(</span><span class=n>uestc</span><span class=p>)</span> <span class=c1># 分词</span>
</span></span><span class=line><span class=cl><span class=n>unique_words</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>dict</span><span class=o>.</span><span class=n>fromkeys</span><span class=p>(</span><span class=n>words</span><span class=p>))</span> <span class=c1># 去重</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>unique_words</span><span class=p>)</span> <span class=c1># 打印</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 构建索引映射</span>
</span></span><span class=line><span class=cl><span class=n>words_to_index</span> <span class=o>=</span> <span class=p>{</span><span class=n>word</span><span class=p>:</span><span class=n>index</span> <span class=k>for</span> <span class=n>index</span><span class=p>,</span><span class=n>word</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>unique_words</span><span class=p>)}</span>
</span></span><span class=line><span class=cl><span class=n>index_to_words</span> <span class=o>=</span> <span class=p>{</span><span class=n>index</span><span class=p>:</span><span class=n>word</span> <span class=k>for</span> <span class=n>word</span><span class=p>,</span><span class=n>index</span> <span class=ow>in</span> <span class=n>words_to_index</span><span class=o>.</span><span class=n>items</span><span class=p>()}</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>words_to_index</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 词嵌入</span>
</span></span><span class=line><span class=cl><span class=n>em</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>num_embeddings</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>words_to_index</span><span class=p>),</span><span class=n>embedding_dim</span><span class=o>=</span><span class=mi>128</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=n>words_to_index</span><span class=p>[</span><span class=n>w</span><span class=p>]</span> <span class=k>for</span> <span class=n>w</span> <span class=ow>in</span> <span class=n>unique_words</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>embeddings</span> <span class=o>=</span> <span class=n>em</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>w</span><span class=p>,</span><span class=n>e</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>unique_words</span><span class=p>,</span><span class=n>embeddings</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>w</span><span class=si>:</span><span class=s2>6</span><span class=si>}</span><span class=s2> -&gt; </span><span class=si>{</span><span class=n>e</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>['电子科技大学', '（', 'UESTC', '）', '位于', '四川', '成都', '，', '是', '中华人民共和国教育部', '直属', '全国', '重点', '大学']
{'电子科技大学': 0, '（': 1, 'UESTC': 2, '）': 3, '位于': 4, '四川': 5, '成都': 6, '，': 7, '是': 8, '中华人民共和国教育部': 9, '直属': 10, '全国': 11, '重点': 12, '大学': 13}
电子科技大学 -&gt; [-1.8661956787109375, 0.14031772315502167, 0.569237232208252, -0.6351905465126038, 1.4581512212753296, 0.8839808702468872, -0.26830628514289856, -1.0125757455825806, 0.2074999362230301, -0.6489216089248657, -0.8614919185638428, 0.6430625319480896, -0.34125998616218567, 0.05696817487478256, -0.8416153788566589, 0.41408586502075195, 0.5821987390518188, -0.38703832030296326, 2.076655149459839, 1.748010277748108, 0.4105229079723358, 0.7927635908126831, -0.8366308808326721, 1.916683554649353, -0.6101747155189514, -2.931159496307373, 1.766214370727539, 0.043025221675634384, -0.12068509310483932, 0.8680415749549866, -1.6387929916381836, -0.13087299466133118, -1.0647748708724976, -0.8026946187019348, -0.8269746899604797, 0.7678179740905762, 2.2990498542785645, 1.2841042280197144, -0.4002425968647003, 0.953626811504364, 0.3030221462249756, -1.022480845451355, -0.5992862582206726, -0.9663468599319458, -0.20251023769378662, 0.13608014583587646, 0.2563541531562805, -0.9632070064544678, 2.260848045349121, -0.658707857131958, 1.3305976390838623, 0.03939782455563545, -0.02348286285996437, -0.9760847091674805, -1.251930832862854, -0.8567044138908386, -0.3526257276535034, -0.29332804679870605, 0.8696300983428955, -1.509308099746704, -0.039910510182380676, 0.5476474165916443, 0.9213836789131165, 0.28016602993011475, 0.09089063853025436, 0.33394673466682434, -0.18297728896141052, -1.4990456104278564, 0.06538386642932892, -0.38446682691574097, 0.12130188196897507, 0.9136270880699158, -0.48136553168296814, 0.9031698703765869, 2.146907091140747, 1.0486698150634766, -0.430355429649353, 0.42662137746810913, 0.9957815408706665, -1.9405899047851562, -1.118597149848938, 1.043890357017517, -0.23853331804275513, -1.0037298202514648, -0.2007996290922165, 1.160055160522461, -0.6286444067955017, 1.1414754390716553, -0.2947123050689697, -0.883659303188324, 1.2323781251907349, -1.7133738994598389, 0.19904382526874542, -0.3554721772670746, -1.2625665664672852, -0.8544297218322754, -0.26314494013786316, -0.8184374570846558, 1.5473873615264893, 0.35293450951576233, -0.7004155516624451, -1.0532680749893188, -0.2432229369878769, 0.6805398464202881, -0.03701140731573105, 0.6072845458984375, -0.6753002405166626, 0.8425671458244324, -0.08411392569541931, -0.21248064935207367, 0.2524896264076233, -0.6912890672683716, 0.8931838274002075, -0.7701399922370911, -0.5828043222427368, -0.8595352172851562, 0.3621070086956024, -0.9512089490890503, -0.4713025987148285, 1.0108795166015625, -0.02917095087468624, 2.0270469188690186, 0.5386377573013306, 0.5365355610847473, -0.40485095977783203, -0.9131317138671875, 1.3478076457977295, 2.3932957649230957]
（      -&gt; [-0.12678614258766174, 0.6960875391960144, 0.020521188154816628, -0.3748815357685089, -0.627172589302063, 1.6855566501617432, 1.486499547958374, 0.8489950299263, -1.387132167816162, 0.41744983196258545, 0.907684862613678, -0.8589462637901306, -0.2876525819301605, 1.0203578472137451, 1.0694795846939087, -0.32388126850128174, -0.7307594418525696, -0.6940516829490662, -0.8880891799926758, 0.22381487488746643, -0.6491599082946777, 1.3248082399368286, 0.6615222096443176, 0.6238570809364319, 1.31926691532135, 0.9561002254486084, 0.796594500541687, 0.7809106111526489, -0.9694629907608032, -0.7225248217582703, 0.21616719663143158, 1.3836281299591064, 0.7425621747970581, -0.279922753572464, 0.3032386898994446, -1.7922078371047974, -1.1123464107513428, -0.157507985830307, -0.44032666087150574, -0.895869791507721, 0.22541534900665283, -0.7791991829872131, 0.2667710483074188, 0.5069770216941833, -0.7465759515762329, 1.4846328496932983, -0.8342013955116272, 0.05761035904288292, -0.27527862787246704, 0.5007193088531494, 0.6848788261413574, -1.7736756801605225, 1.9905004501342773, -0.5666214823722839, 0.2690577208995819, 2.0447988510131836, 1.3222894668579102, -1.052148461341858, -0.035423073917627335, -0.2991918921470642, 0.6338981986045837, 0.8307668566703796, -0.47362956404685974, -1.2505531311035156, 0.9754865765571594, -0.3994227349758148, 0.8434854745864868, -0.1257162094116211, -0.6602136492729187, -0.322810560464859, 0.0715293139219284, -1.0767406225204468, 0.06953053921461105, 1.9902366399765015, 2.156857490539551, 1.3994474411010742, 1.1047091484069824, 0.8247582912445068, -0.05698545277118683, 0.37208205461502075, 0.7805140614509583, -0.1558430939912796, -0.49478021264076233, 1.706350564956665, 0.5205206274986267, 0.13300387561321259, -0.6621465682983398, -0.36326512694358826, 0.8889725804328918, 0.6175691485404968, 0.7431073188781738, -0.17847304046154022, 0.08741611242294312, -0.3816048800945282, 1.6248550415039062, 1.0170153379440308, -1.9888108968734741, 1.8885093927383423, -0.006207907572388649, 1.2217708826065063, -1.0140215158462524, 0.44049927592277527, -0.43184012174606323, -0.06671300530433655, 2.0526020526885986, -0.6379009485244751, -1.6314414739608765, -0.6334065198898315, -0.7363719940185547, 1.1962233781814575, 0.5337159633636475, -0.21218398213386536, 0.5309426784515381, 0.07389579713344574, 0.11146420985460281, -1.1044336557388306, -0.7189712524414062, -0.31827273964881897, 1.5980576276779175, 0.9579342007637024, 2.623478889465332, -1.6724075078964233, -0.26611265540122986, -1.2468178272247314, -0.18551334738731384, -0.4349876940250397, 1.8001712560653687, 1.0223889350891113]
UESTC  -&gt; [-0.4736874997615814, 1.355381965637207, -0.00493775587528944, -1.0931262969970703, -2.3410215377807617, 0.8936401009559631, 0.6650726199150085, 1.0417888164520264, -0.49513116478919983, 0.0043176612816751, -0.5583096742630005, 1.758357286453247, 1.4455883502960205, -0.19576455652713776, -1.1610676050186157, -2.317267656326294, -0.6588720083236694, -0.13706523180007935, 1.1463770866394043, 0.7667974233627319, -0.42419421672821045, 0.06066890060901642, 1.4035671949386597, 0.2040967345237732, 1.6177923679351807, 0.22955924272537231, 1.0651345252990723, -1.0725045204162598, 1.1727843284606934, -0.7321259379386902, -1.8999624252319336, -0.6257965564727783, 1.2432847023010254, -0.9686990976333618, -1.569515585899353, -1.3007028102874756, -1.035699725151062, 0.2684550881385803, 0.7886533141136169, -0.10644060373306274, -0.36529019474983215, -0.08155005425214767, -0.7963141798973083, -1.0937591791152954, 0.4869083762168884, 0.6795454025268555, 2.2324459552764893, -0.6131372451782227, -0.4022427499294281, -1.2551276683807373, 0.8329983353614807, 2.2642977237701416, 0.03506528586149216, -2.28579044342041, 2.607224941253662, -0.8421016335487366, -0.26126524806022644, -0.11314589530229568, 1.1180301904678345, -0.31227293610572815, 2.5623223781585693, 0.16087308526039124, 1.1985620260238647, -0.6188108325004578, 1.1842929124832153, 0.005746761802583933, -1.1686954498291016, 0.6173182129859924, 1.2473996877670288, -0.38694095611572266, -0.5713652968406677, 1.560266375541687, 0.33818697929382324, -1.2584021091461182, -1.5353972911834717, -2.0800259113311768, -0.20637056231498718, 1.9889888763427734, -2.2434842586517334, -0.12057679891586304, -2.560797929763794, -0.3289901912212372, 0.9283509850502014, 0.895533561706543, 2.0530848503112793, -1.055206298828125, -0.5434237122535706, -0.8042547702789307, 0.724254846572876, 0.7943518161773682, -2.0686428546905518, -1.1408240795135498, 0.14246274530887604, 1.1389896869659424, -0.8794960379600525, -0.06483657658100128, 0.3716636300086975, -0.774135410785675, 0.9789445400238037, 0.9356880784034729, 1.5726100206375122, 1.0869207382202148, -0.9433879256248474, 0.37225478887557983, -0.05867277830839157, -0.308488130569458, -0.4701962172985077, -1.0970293283462524, -0.5689950585365295, -0.9057802557945251, 1.728075385093689, 0.5420587062835693, -0.2288399040699005, 0.3615356683731079, 0.9640733599662781, -0.35619789361953735, -0.9395654797554016, -0.5666417479515076, 0.5330474376678467, -0.13286754488945007, -0.5451010465621948, -0.20822420716285706, -1.439953088760376, -0.39996537566185, 0.9809983372688293, -0.6372662782669067, -0.7996388077735901, 1.035481572151184]
）      -&gt; [0.8538455367088318, -0.28737425804138184, -0.4954721927642822, 1.4311481714248657, 0.5066145062446594, -1.3862826824188232, -1.0950548648834229, -0.4366549551486969, -0.3736400008201599, 0.9380052089691162, 0.5984531044960022, 0.025163406506180763, 0.18784953653812408, -0.4975185692310333, 0.39198294281959534, -0.19818389415740967, -0.28350281715393066, -0.5530851483345032, 1.4333688020706177, 0.4523366391658783, -0.943611741065979, -0.05974974110722542, 2.2806386947631836, 0.6010316610336304, -0.7775551080703735, 0.3181857466697693, 0.7983736991882324, -0.4904671013355255, 0.020847203209996223, -0.3797513246536255, 0.4124070107936859, -0.4906497299671173, 0.9153454303741455, 0.8117666244506836, 0.45398736000061035, 0.6178997159004211, 0.2887639105319977, 0.7092264890670776, -0.919242262840271, -0.9364564418792725, 0.9499621987342834, 0.20754645764827728, -0.8610689640045166, -0.39362603425979614, 0.6321143507957458, 0.5002573728561401, -0.16191619634628296, -0.09123581647872925, -1.3519253730773926, 0.9296125173568726, -1.4428986310958862, -0.5282418131828308, 0.5145831108093262, -0.4876914322376251, 1.533389687538147, 0.5935625433921814, 1.6638743877410889, 1.3493365049362183, 1.061549425125122, 0.677806556224823, -0.17198362946510315, -0.33146587014198303, 1.5684221982955933, -0.018957924097776413, 0.987183690071106, -2.1270337104797363, -0.15436771512031555, 1.1985297203063965, 1.4738495349884033, -0.592376172542572, 0.3892100155353546, 0.6586661338806152, 0.31610190868377686, -1.039612054824829, 0.23944780230522156, -1.2984569072723389, -0.6445983648300171, 1.9221996068954468, 0.0942683070898056, 0.8915141224861145, -1.515462040901184, 0.4539085030555725, -1.8553234338760376, -1.0513883829116821, -0.7374001741409302, -1.3408923149108887, 1.2866485118865967, -0.7198876142501831, 0.5034555792808533, -0.10861600935459137, 1.0328806638717651, 0.23367278277873993, -0.9914355874061584, -0.44009122252464294, -0.13551035523414612, 0.049741849303245544, -1.230101466178894, -0.4478664994239807, -0.7742400169372559, 0.9170076847076416, 1.1349929571151733, -0.3445286750793457, 0.42910802364349365, 0.5874624252319336, 0.49147021770477295, -1.384164571762085, -0.6557977199554443, 0.2289164811372757, 1.0107190608978271, 1.1270657777786255, -0.5856562852859497, -0.365908145904541, -0.6938067078590393, -1.3915842771530151, 1.2832459211349487, -0.1949014812707901, -0.04525640979409218, 0.12323860824108124, -0.16887104511260986, 0.4024936854839325, -0.3631386458873749, -0.3940415382385254, -0.851615309715271, 0.052415359765291214, 1.0799293518066406, 0.2743575870990753, -0.45772257447242737, -0.02607984095811844]
位于     -&gt; [1.7168090343475342, -0.08993507921695709, 0.42629849910736084, -0.8526725769042969, 0.17064198851585388, 0.5137831568717957, -0.037155650556087494, -1.1192309856414795, 1.5791795253753662, -0.9378558397293091, -1.1923009157180786, -0.04971752688288689, -1.6210458278656006, -1.2578229904174805, 0.468787282705307, -0.017596535384655, 0.5358322262763977, 1.0883111953735352, 0.6899486184120178, 2.2773444652557373, 0.9163282513618469, -0.7395586371421814, 0.12892921268939972, -1.4885333776474, -0.9551274180412292, -0.4179268479347229, 0.4167310297489166, -0.6567360162734985, -0.7738466858863831, 0.9928999543190002, 0.5239269137382507, -0.37249624729156494, -0.6732262372970581, -2.235102891921997, -1.3211236000061035, -0.5702805519104004, 0.7115850448608398, -0.5283679366111755, -0.9706310033798218, 0.4394710063934326, 1.9765151739120483, 2.844550371170044, 1.3933804035186768, -1.071089506149292, 0.2864969074726105, -0.020159661769866943, -1.0760056972503662, 0.7690610289573669, -0.5425635576248169, -0.12007666379213333, -0.6873587369918823, -1.180539846420288, -0.011916521936655045, 1.1096831560134888, 0.6210238933563232, 0.027135400101542473, 0.3639536499977112, 0.993864893913269, -0.4164225161075592, 0.3271690309047699, 0.40985074639320374, 1.4573488235473633, 0.9820419549942017, 0.5789766907691956, 1.1851555109024048, -1.2971205711364746, 0.33617496490478516, -0.3047017753124237, 0.27652761340141296, -0.9369839429855347, -0.026159269735217094, 0.8137128353118896, -0.015559175983071327, -0.2985958755016327, -2.2304558753967285, -2.1107630729675293, 1.0383832454681396, -1.4547908306121826, -1.2483378648757935, 0.4881366789340973, 0.27501043677330017, -0.7989357113838196, 1.4601446390151978, 1.0553253889083862, 0.17138926684856415, -0.45287197828292847, 1.8369266986846924, 0.19166652858257294, -1.0581374168395996, -0.7617331147193909, 0.6080803871154785, -0.5222128033638, 0.2154778242111206, -0.9145902395248413, -0.6550857424736023, 0.6670337319374084, 0.2841850221157074, 1.5520975589752197, -0.41029027104377747, -0.8780690431594849, 0.6484847664833069, -1.389772653579712, -2.39544415473938, -1.698142409324646, -1.6761640310287476, -0.5713211894035339, 0.5054879188537598, -0.439106822013855, -1.0805776119232178, -1.0738043785095215, -0.22147268056869507, -1.2931756973266602, -1.7447654008865356, -0.2635822296142578, -0.38105618953704834, 0.088524229824543, 0.7569169998168945, -0.7295322418212891, -0.1692301481962204, -1.1889735460281372, 1.8446358442306519, -0.8288096189498901, -1.644872784614563, 0.07178768515586853, 0.9296861886978149, 1.2789150476455688, -0.5919066667556763, -0.14757634699344635]
四川     -&gt; [0.7639459371566772, -0.660054624080658, -0.08635374158620834, -0.41890695691108704, 0.7900705337524414, -0.10140606015920639, 0.4720896780490875, -2.1445083618164062, 0.7043130397796631, -0.8396892547607422, -1.7390351295471191, 0.29287344217300415, -0.2598598599433899, 1.1453543901443481, -1.691605806350708, -0.32984253764152527, -1.0771393775939941, 0.12628982961177826, -1.0895458459854126, 0.6557487845420837, 0.9245684146881104, 0.6992956399917603, 0.2929307520389557, 1.2730282545089722, 0.9517784118652344, 1.6362038850784302, -0.06577905267477036, -0.12625154852867126, -0.21007876098155975, 1.417515754699707, 0.06356274336576462, 0.1672062873840332, -0.14522509276866913, -0.6984828114509583, -0.8967545628547668, 0.6959110498428345, 0.08421899378299713, 0.9785493612289429, -0.4335647225379944, -1.9969183206558228, 2.3934972286224365, 1.669681429862976, -1.094510793685913, 1.2458893060684204, -0.26701512932777405, -1.2686049938201904, -0.7705062031745911, 0.7624711394309998, 0.23258371651172638, -1.6723850965499878, 0.6332679390907288, -0.2207077294588089, -0.8182200789451599, 1.0712546110153198, -0.08216150850057602, 0.11058936268091202, -0.2188360095024109, 2.403790235519409, 0.8505138158798218, -0.29030895233154297, -1.3257994651794434, 0.997616171836853, -0.754666268825531, 0.6795787811279297, -1.4827628135681152, -1.29130220413208, -0.306960791349411, -0.004058618564158678, -1.03386652469635, 0.2599014341831207, 1.5488905906677246, -1.1801602840423584, -0.04927394539117813, 2.0203394889831543, 0.34747564792633057, 0.7936400771141052, -1.9471760988235474, -0.2748616337776184, 0.8032112121582031, -0.97441565990448, 1.0562200546264648, 0.4987774193286896, 1.4722212553024292, 1.2849000692367554, 0.5363295674324036, 2.090388536453247, 0.2972404360771179, 0.6321299076080322, -2.443924903869629, -0.5117645263671875, 0.8579564094543457, -0.7760249376296997, 0.7403879165649414, -0.13470539450645447, -1.7935080528259277, -1.0757124423980713, -0.6320903897285461, 0.7336604595184326, 2.0827550888061523, -1.602760910987854, 0.16270942986011505, -1.0851973295211792, 1.267317771911621, -0.44165411591529846, 1.4766086339950562, -1.5308431386947632, -0.7466219663619995, -0.5175436735153198, 2.3212132453918457, 0.8788610100746155, 0.26752519607543945, 1.0927706956863403, 0.2308245152235031, 2.395909547805786, -1.0620023012161255, -1.5863486528396606, -0.37703272700309753, 0.6864315271377563, 0.5820862650871277, 1.4480952024459839, 0.09708879142999649, 0.34581759572029114, -0.3975397050380707, 1.173356056213379, -0.7262426614761353, -0.4707520306110382, -1.6837925910949707, 0.3518792390823364]
成都     -&gt; [0.56243896484375, 1.4777281284332275, 0.4997352063655853, 1.0969278812408447, 0.7628512978553772, 1.7217930555343628, -0.40213480591773987, -0.5143151879310608, -2.4896655082702637, -0.35010015964508057, 2.312429189682007, -0.6234450340270996, 1.5870294570922852, 0.9043256044387817, 0.979636549949646, 2.0384109020233154, -0.01772027090191841, 1.2573158740997314, 1.4020342826843262, 1.0658103227615356, -0.27821195125579834, -1.0903197526931763, 0.40434160828590393, -1.1213923692703247, -0.21690411865711212, -2.405766248703003, 0.2388550341129303, 0.4941626787185669, 0.5749419927597046, -1.6343562602996826, -0.3733586370944977, 0.033875722438097, 1.96085786819458, -0.7303372621536255, 1.248095989227295, 0.05076742544770241, -0.1411282867193222, -0.680297315120697, 2.2530136108398438, -2.905562400817871, 0.028334857895970345, -0.331263929605484, 1.8674354553222656, -0.6284685134887695, 1.0690555572509766, 0.4204407036304474, 1.2775059938430786, 0.20274092257022858, -0.4572921693325043, 1.0441139936447144, -0.04267473891377449, -1.0923773050308228, 2.450409173965454, 0.04830460250377655, 0.07777398079633713, 0.2420053482055664, 0.9271904826164246, -0.6963448524475098, 2.0232656002044678, 0.8172881007194519, -0.5111582279205322, -0.7655945420265198, 2.400362491607666, -2.3128511905670166, -0.49751365184783936, 0.8380289673805237, 0.29281502962112427, -0.2212970107793808, -0.2090066373348236, 1.088941216468811, -1.0725855827331543, -0.07908947765827179, -0.13858187198638916, -0.7048135995864868, -0.18928736448287964, -0.020287740975618362, -1.050644874572754, 0.5913116931915283, 0.006256016902625561, 1.3219653367996216, -0.7687020301818848, 0.14103731513023376, 0.0016240208642557263, -1.2730432748794556, -0.1441194862127304, -0.8608500361442566, -1.0339374542236328, 0.7806683778762817, 0.7678371667861938, -1.5007939338684082, -0.6163219809532166, 0.22171591222286224, 0.6179243922233582, 0.06138891354203224, 1.0564122200012207, 0.6745894551277161, 0.8391706347465515, 0.004445864353328943, -0.5395381450653076, 0.21040350198745728, 0.965447187423706, -0.07339546829462051, 1.7722938060760498, -1.0979887247085571, 0.7095265984535217, -0.22573591768741608, -0.2532839775085449, 0.345893532037735, 0.49645504355430603, -0.22295160591602325, -0.3253420293331146, 0.18388471007347107, -0.7767135500907898, -0.5512225031852722, -0.2734062075614929, -0.15085825324058533, 0.43957316875457764, 1.3614509105682373, 1.2428990602493286, 0.8182045817375183, 0.5461722016334534, -0.41816452145576477, -0.19024881720542908, -0.45834967494010925, -0.6916024088859558, -2.3069822788238525, -2.3388330936431885, 0.294677734375]
，      -&gt; [-0.33787408471107483, -1.3094017505645752, -0.06432336568832397, -1.0921032428741455, -0.04095187038183212, -0.953260600566864, 1.372378945350647, -0.6234164834022522, 0.861510157585144, -0.2992742359638214, -0.5599021315574646, 0.476374089717865, -2.0908029079437256, -1.0384407043457031, 0.2720696032047272, 1.0667717456817627, 0.07459308952093124, -0.264820396900177, -0.7853105068206787, -0.033309247344732285, 0.2928711771965027, 0.4753778576850891, 0.21960414946079254, -1.3768391609191895, -1.0830707550048828, 0.4983312487602234, 1.9078577756881714, 0.138449564576149, -0.8132482767105103, -0.20288391411304474, -1.36941659450531, 0.1078270897269249, -1.6963082551956177, -0.03481857106089592, -1.0912704467773438, 1.4659584760665894, 0.1895529329776764, -0.33048200607299805, 1.1222764253616333, -0.18429803848266602, -0.9224066138267517, -0.46710413694381714, 0.4822205901145935, -0.4209873080253601, -0.04612121731042862, 1.659363031387329, 1.560346007347107, -0.1867826133966446, 0.2480340152978897, 0.13798049092292786, -0.2595059275627136, 0.6765235662460327, -1.193811058998108, -0.9169279932975769, 1.3021773099899292, -1.1234501600265503, 1.3536704778671265, -1.2806051969528198, 1.3554661273956299, -0.8482236862182617, 0.41685938835144043, 2.065185785293579, 1.1324994564056396, -1.1211353540420532, -0.7691621780395508, 0.11613759398460388, 0.013647863641381264, 2.055845260620117, 1.4118510484695435, -0.19109390676021576, 0.6356171369552612, -0.7232450246810913, -1.6852675676345825, -1.0326565504074097, 0.9595025777816772, 0.5682767629623413, -0.8269544839859009, -0.14660421013832092, -1.7345532178878784, -0.05637021362781525, 1.1968082189559937, 0.04985278844833374, -0.5233662128448486, -0.9858769774436951, 0.33265429735183716, 0.04952392727136612, 0.26295122504234314, -1.0770411491394043, 1.9539353847503662, 0.6972767114639282, -0.6182871460914612, -2.249014139175415, 0.7948842644691467, -0.8970513343811035, -0.7566987872123718, -1.8652397394180298, 0.7252744436264038, -2.2766242027282715, -0.30294767022132874, -2.074877977371216, 1.808603048324585, 2.3689382076263428, -0.07377711683511734, -1.1722602844238281, -0.4107270836830139, 0.7841655015945435, -1.2185114622116089, -0.45550736784935, 1.2937835454940796, 0.2953551709651947, 0.28018659353256226, 1.317701816558838, 0.7412610054016113, 0.9395641684532166, -0.7370730638504028, 0.21863065659999847, 1.6849689483642578, -0.9418413043022156, 1.3929885625839233, -0.6308969855308533, 0.4914607107639313, 0.35774946212768555, 0.14206045866012573, -1.0362331867218018, 2.092369794845581, -1.212904453277588, -0.954627513885498, -0.9904732704162598]
是      -&gt; [-1.0381309986114502, 0.13718514144420624, 3.8931920528411865, -2.0787062644958496, -0.9909481406211853, 1.2365304231643677, 0.14260700345039368, 0.13479892909526825, 0.30499759316444397, 0.4600023031234741, 1.8234951496124268, 0.6081579327583313, -1.3596107959747314, 0.7735426425933838, 0.4919971227645874, -1.3641643524169922, 1.237881064414978, -0.6730667352676392, -0.9279845952987671, -0.07291223853826523, 0.005679577123373747, 0.822374701499939, -0.9734363555908203, -0.8951475024223328, 0.46311473846435547, 1.8462002277374268, -0.2588288187980652, 0.4701385498046875, 0.9768430590629578, 1.1862082481384277, -0.532867431640625, -2.6098439693450928, 0.16334624588489532, -0.2312006801366806, 0.04538475722074509, 1.5012876987457275, 1.8384860754013062, -0.946250855922699, -0.43893951177597046, 0.17583389580249786, 1.4166406393051147, 0.8954916596412659, 1.554394006729126, -0.6380833983421326, -0.06268838793039322, 1.1698411703109741, -0.4295130670070648, -0.3615911602973938, -0.9524906873703003, 0.41601669788360596, -0.17511416971683502, -0.020355144515633583, -0.5950009226799011, 1.0813703536987305, -0.11183588206768036, -1.2964600324630737, 2.048386573791504, 0.43394115567207336, -0.34899622201919556, -1.2100651264190674, -0.5326148271560669, 0.38617876172065735, -0.986335039138794, -2.582519769668579, 1.3733240365982056, -0.2605557143688202, -0.21359194815158844, 1.6070479154586792, -0.2156515270471573, -0.19509197771549225, -1.6181598901748657, -1.1318364143371582, -0.5061348676681519, 0.25062844157218933, 0.0032534294296056032, -0.25270673632621765, -0.13427601754665375, -0.06254970282316208, 0.4892120659351349, -0.8235657811164856, -0.6076521873474121, -1.3053886890411377, -0.43925970792770386, 1.324268102645874, 0.9528844952583313, -0.47715362906455994, 0.3556428551673889, 0.211994931101799, -0.6904019713401794, -1.3862437009811401, -0.322297602891922, -0.3010545074939728, -0.836707353591919, -1.6331428289413452, -0.30824604630470276, -1.9453868865966797, -1.624407172203064, -0.5701942443847656, 0.03189626336097717, -1.5300270318984985, 0.397626131772995, 0.09802354127168655, 2.5223982334136963, 1.1541708707809448, -1.5273308753967285, -1.4219385385513306, 0.75459223985672, 1.1492969989776611, -0.47371330857276917, 2.405719041824341, -0.9892557859420776, -1.454994797706604, 0.29766565561294556, -0.22816257178783417, 1.8712615966796875, 1.545329213142395, -0.8563598394393921, 1.5104244947433472, -0.29827380180358887, 0.7789028882980347, 0.7176946401596069, -1.2561675310134888, -0.85163414478302, 0.02971484512090683, -0.5711592435836792, 0.4415961503982544, -1.4320781230926514, 0.44245144724845886]
中华人民共和国教育部 -&gt; [0.14025051891803741, -0.5883216857910156, 1.056982398033142, 1.398756980895996, 1.2855510711669922, -0.9107669591903687, -1.406931757926941, 0.4232429265975952, 0.138737291097641, 0.41513851284980774, 0.24644315242767334, -1.2017205953598022, 0.6361500024795532, -0.03634294122457504, 0.7052356004714966, 0.6098170876502991, -0.3026246726512909, -1.4279675483703613, 1.588690161705017, 0.6018990278244019, 1.6895304918289185, 0.003920222632586956, 1.4023375511169434, -1.3140830993652344, -0.9500641822814941, -0.18963374197483063, 0.7632401585578918, -2.6280431747436523, -0.6997641324996948, 0.8201631307601929, 1.6689854860305786, -0.005850125104188919, 0.8181517720222473, 0.9020212888717651, 0.9376468062400818, 0.6025412678718567, 0.19286642968654633, -2.0545268058776855, -0.5015175938606262, 0.8119596838951111, 0.518287718296051, 0.7443577647209167, 0.12724363803863525, -0.4288278818130493, -0.5430804491043091, 1.6007821559906006, -1.7710744142532349, 1.045377492904663, -0.13337315618991852, 0.5695350170135498, 0.611879825592041, 0.8327794671058655, -3.0777602195739746, -1.4227104187011719, 1.6461505889892578, -1.138787865638733, -0.5175765156745911, -0.6527858972549438, -0.4465395510196686, 0.019725844264030457, -1.4563722610473633, -0.3762948215007782, 1.2026947736740112, 0.7340081930160522, -0.5348214507102966, -0.7487169504165649, -0.3007497489452362, -1.6888025999069214, 0.7306185364723206, -0.469486266374588, -0.9775107502937317, -0.21138161420822144, 0.7867814898490906, 1.2474416494369507, 0.097927987575531, -0.29573315382003784, 0.023264342918992043, -0.1560763567686081, 0.722339928150177, 0.5893672704696655, -0.024296792224049568, 1.7033941745758057, -0.3186756372451782, -2.038273811340332, 0.2632593512535095, 0.7503422498703003, 0.18595272302627563, -1.7183271646499634, 0.7696282267570496, 0.6995213031768799, -0.3682793080806732, -2.2420945167541504, 0.9661995768547058, 1.4557089805603027, 0.1969800740480423, -0.9218257665634155, -0.5476601719856262, -0.30923694372177124, -0.8398916125297546, 1.4972319602966309, -0.3774861693382263, -0.21029157936573029, 2.224287986755371, 0.2102212756872177, 0.18242454528808594, 0.04718697443604469, 0.2859799861907959, -1.1755571365356445, 0.30829644203186035, -0.0006614835583604872, -0.36983150243759155, 1.4986408948898315, 0.9627066850662231, 1.6044225692749023, 1.7419381141662598, -1.3149410486221313, -1.1165934801101685, 2.3712234497070312, 0.8730128407478333, -1.9619089365005493, -0.07330694049596786, 0.688816487789154, -0.4210284650325775, -0.7613076567649841, -0.1594087779521942, 1.3634997606277466, 1.6164549589157104, 0.3564639687538147]
直属     -&gt; [-0.33789971470832825, 1.3584284782409668, -0.5811788439750671, -0.6095796823501587, -0.6302621960639954, -0.6341601014137268, 1.420705795288086, 0.13715553283691406, -2.060513734817505, 1.26814603805542, -0.23949818313121796, 1.1931129693984985, -1.0386868715286255, -0.3954807221889496, 0.5195523500442505, 0.754364550113678, 0.20388828217983246, -0.4023708403110504, -0.02800746262073517, -2.2803475856781006, 1.1303919553756714, -0.5699470639228821, -0.3445722758769989, -1.151837944984436, 0.5616161227226257, -0.07560509443283081, 1.9034521579742432, -0.8097555041313171, 1.5177966356277466, -1.3630318641662598, -0.30350542068481445, 0.39291444420814514, -0.7752071619033813, 1.1337178945541382, 0.5776795744895935, 0.9621323347091675, 0.7165736556053162, -0.7049280405044556, -0.6581589579582214, 2.2558507919311523, 0.6021068692207336, -1.278320074081421, 1.2918076515197754, 0.014823876321315765, -1.7895697355270386, -0.07380425184965134, -0.6859892010688782, -1.3862357139587402, 0.434276819229126, 0.5077678561210632, -0.7565757632255554, 0.7231796383857727, -2.8456947803497314, -0.6417722105979919, 0.189362570643425, -0.839449942111969, 0.5829066634178162, -0.579809308052063, -0.2484005242586136, 0.6170995235443115, -0.9293689727783203, 0.15690799057483673, 0.10465901345014572, -0.22713077068328857, -0.40781092643737793, -0.6484670639038086, -0.09114891290664673, 0.6100202202796936, 0.43622541427612305, -0.31834375858306885, -0.561362087726593, -0.6336369514465332, 1.3107948303222656, 0.8724061250686646, 0.8782907128334045, 0.7980823516845703, -1.503814697265625, 2.432075023651123, -0.39363643527030945, -0.11639916151762009, -0.39047491550445557, 0.3356471657752991, -0.7154036164283752, 0.2089829444885254, -1.274901032447815, -1.2903138399124146, 0.4787827730178833, 0.8754767775535583, -0.36598432064056396, -0.8223683834075928, -0.5764500498771667, 0.5468283295631409, -0.005182052031159401, 2.0755088329315186, -0.20317433774471283, 0.7980713248252869, -0.13998694717884064, 0.845341145992279, -1.0122485160827637, 1.019565224647522, 1.4568798542022705, -1.8541587591171265, -0.08164568245410919, 0.8209619522094727, 0.539742112159729, 1.7721991539001465, 1.7427912950515747, -0.9580423831939697, -1.1708639860153198, -0.07433973252773285, 1.1893250942230225, -0.4009150564670563, -0.5625899434089661, -1.648033618927002, 0.5622848272323608, -1.4640545845031738, -1.2228060960769653, 0.8409449458122253, -0.05045817047357559, -0.7518205642700195, -1.115128517150879, 1.3314285278320312, -0.4583549499511719, -0.22974802553653717, -0.2134741246700287, 1.346194863319397, 0.6285591125488281, 0.04430529847741127]
全国     -&gt; [-1.5520007610321045, 0.3314692974090576, 0.08914195001125336, -0.0056284223683178425, -0.9564746618270874, -0.40461617708206177, 0.13070593774318695, 1.686263084411621, 1.010897159576416, 0.8405971527099609, 0.15378746390342712, 0.9534083008766174, 0.23421438038349152, 0.08166507631540298, -0.25529566407203674, -0.7175579071044922, 0.4626561999320984, 0.7876096963882446, 0.9008212089538574, 0.3049789071083069, -0.09401117265224457, -1.4717092514038086, 1.6372592449188232, -0.24522098898887634, 0.12768657505512238, -0.580763041973114, -0.4987027049064636, 0.8773986101150513, -0.13349944353103638, -0.08767732232809067, -0.28354188799858093, -0.03146464750170708, 0.40214914083480835, -1.0805237293243408, 1.311383605003357, -1.5334444046020508, 1.6689292192459106, 1.8921211957931519, 0.1684861183166504, 1.2055963277816772, 0.06375385820865631, 0.610754132270813, -1.09141206741333, -0.272737979888916, 0.8392224907875061, -0.9453503489494324, -0.15187454223632812, 0.53958660364151, -0.4521462321281433, -0.44379866123199463, 0.5150322914123535, -0.35866037011146545, 1.8172500133514404, 0.6289143562316895, 0.97475665807724, -0.25434234738349915, -0.18379847705364227, -0.8135579824447632, -0.4091949164867401, 0.14109547436237335, -2.461815118789673, 1.3043322563171387, -2.3017876148223877, -0.6164878606796265, -0.4214482605457306, 0.47513189911842346, -0.7553485035896301, -0.2020123153924942, 0.47444117069244385, 1.2666491270065308, -0.46207693219184875, 1.9876667261123657, -1.7732608318328857, 1.075785756111145, -2.8453588485717773, -0.820521891117096, -0.7866068482398987, 0.8140893578529358, -1.9845681190490723, -0.4685239791870117, -0.06957542151212692, 1.1858913898468018, 0.3000602722167969, -1.6092876195907593, 0.44625040888786316, -0.17546935379505157, -0.9834369421005249, -0.12012048065662384, 2.1486434936523438, -1.6368743181228638, 1.181698203086853, -0.09896392375230789, -0.7479424476623535, 0.8604170083999634, -0.1014096736907959, 0.9558519124984741, -0.21039994060993195, -0.18168802559375763, -1.9284073114395142, 0.02403911016881466, -0.5795352458953857, -0.08818890154361725, -0.08199119567871094, 0.039158958941698074, -0.28986191749572754, -0.81545490026474, 0.8709331154823303, -0.8589040637016296, 1.9099797010421753, 1.0797122716903687, -0.657086193561554, -0.5038485527038574, 1.448275089263916, 0.371888667345047, 1.253653883934021, -1.170638918876648, -1.3922667503356934, -0.6512734293937683, 1.5548454523086548, 0.2577717900276184, 0.4874401390552521, 0.13227622210979462, -0.33626890182495117, 0.6618170142173767, -1.2863892316818237, -0.1770940124988556, -0.7055754065513611, 1.3789422512054443]
重点     -&gt; [1.1949406862258911, -0.012182194739580154, 0.8961377739906311, 0.7839514017105103, -0.18879392743110657, -0.39553102850914, -0.2632424235343933, -0.938086986541748, 1.3489576578140259, -0.4624161422252655, -1.3119703531265259, 0.5095743536949158, 0.1330413520336151, -1.4793245792388916, -1.9383506774902344, 0.20698249340057373, 2.5029187202453613, -0.35258620977401733, 0.5366807579994202, -2.0697383880615234, -1.5056042671203613, -0.8820537328720093, -0.3993379473686218, 0.05287330597639084, 0.7160015106201172, -0.47868359088897705, 0.15337057411670685, -0.6627570390701294, -1.9589228630065918, 0.8543242812156677, -0.48553666472435, 0.2018612027168274, -0.26615840196609497, -1.2309821844100952, 0.051297858357429504, -0.20254108309745789, -0.10170754045248032, -0.5889589786529541, 0.7253758311271667, -0.39362308382987976, -0.568123459815979, -0.06739899516105652, -0.9299246668815613, 0.059613823890686035, -1.1932049989700317, 0.1409657895565033, -1.029586672782898, 1.0887030363082886, -1.1189749240875244, -1.730431318283081, 0.005612374283373356, 0.5359809994697571, 0.6329437494277954, 0.4694022834300995, -1.2981356382369995, 0.5264517068862915, -0.10433857887983322, -0.331701397895813, -0.3174913227558136, -1.4151962995529175, 0.005109786055982113, 0.9603325128555298, -0.3973565399646759, 0.23845700919628143, 1.1231367588043213, -0.44293013215065, -0.6706748008728027, 1.1240535974502563, -0.5034427642822266, -0.5822576284408569, 1.5443520545959473, -1.6841453313827515, 0.06877513229846954, -1.740064024925232, 1.1700929403305054, -0.34096410870552063, 0.0911058783531189, 0.6429353952407837, 0.27809223532676697, -0.7784138321876526, 1.1370183229446411, 0.014460142701864243, -0.28068944811820984, -0.30486515164375305, 0.8224811553955078, -2.0884850025177, -0.7780076861381531, 1.1283482313156128, -0.11650309711694717, 2.2403976917266846, 1.5255331993103027, 0.4878126084804535, -0.811322033405304, 1.0219014883041382, 0.6292736530303955, -1.2825417518615723, 0.7980432510375977, 1.142793893814087, -0.4022769033908844, -1.4298145771026611, 0.9908952713012695, 1.0863277912139893, -0.2719363272190094, -1.0888563394546509, 0.32725587487220764, 0.3708494305610657, -0.09677056968212128, 0.27237048745155334, -0.37364158034324646, 0.030335577204823494, 1.1755188703536987, -0.3344758450984955, 0.47455546259880066, -0.6940397024154663, 0.4407373070716858, -1.0097383260726929, -0.017465421929955482, -0.36444470286369324, -1.780834436416626, 0.11095383763313293, 0.44742828607559204, 0.4113369882106781, 0.8977880477905273, -0.5807644128799438, -0.07540850341320038, 0.47065648436546326, -0.4016966223716736, 0.1848985105752945]
大学     -&gt; [-1.4475852251052856, -0.17752867937088013, -0.7879891991615295, 1.2863266468048096, 0.5554264783859253, 0.7422486543655396, 0.647564709186554, -0.4495318830013275, 0.5519548058509827, 0.1076410636305809, -1.4149372577667236, 0.10615064203739166, 0.07769380509853363, -0.8733966946601868, -0.2317454218864441, -0.8407759070396423, -0.6344646215438843, -0.10932822525501251, 0.9894860982894897, 0.518584668636322, 0.12721653282642365, -1.2334426641464233, -0.7602449655532837, -0.1530931144952774, 0.7784685492515564, 0.6280393600463867, -0.34914520382881165, -0.986354649066925, 0.05498924106359482, -0.5254408121109009, -0.15824776887893677, 0.16335463523864746, 0.4538341760635376, -0.08873286098241806, 0.2933367192745209, 0.020767442882061005, -0.8800519704818726, 0.37006673216819763, -0.7811611294746399, -1.2028112411499023, -1.0187177658081055, -0.27793389558792114, 2.092510938644409, 1.4004042148590088, 0.9561623930931091, 0.9958055019378662, -0.9844347238540649, -1.1637202501296997, 0.5800871253013611, -0.6730059385299683, 1.3405460119247437, -0.14193913340568542, 0.8394786715507507, 1.0213227272033691, -0.19199487566947937, -0.69403475522995, -1.3983559608459473, 0.3184455633163452, 0.33800598978996277, 0.9688117504119873, 0.23558557033538818, 1.587860345840454, -1.1090397834777832, -1.1135281324386597, 0.22917072474956512, 0.5204218029975891, 0.8698641061782837, -0.9962738752365112, 0.751709520816803, 0.07302659749984741, -0.5218413472175598, 0.5482472777366638, -0.35429203510284424, -0.20083633065223694, 1.3695396184921265, 1.0042166709899902, 0.4688868820667267, 1.1620533466339111, 2.3771159648895264, 0.8834945559501648, 0.6229496002197266, -0.4971642792224884, -1.3196049928665161, -0.30771127343177795, 0.9008187055587769, 0.5891910195350647, -0.8497917056083679, -0.3938082456588745, -0.3030562996864319, -0.5590260028839111, 0.49924609065055847, -0.42346131801605225, -0.2595711052417755, 0.7297765612602234, -0.3204481899738312, -0.3209802508354187, -1.5807064771652222, 0.7140669822692871, 1.0739787817001343, -0.5437872409820557, -0.810208797454834, 0.5369143486022949, 0.4794268310070038, 0.8579863905906677, -0.5213403105735779, 0.5756368637084961, 1.5243277549743652, 1.427191138267517, 1.70316481590271, 0.6414663791656494, -1.61505126953125, 1.7495568990707397, -0.7892530560493469, 0.7378950119018555, -1.5114903450012207, 0.7335148453712463, -0.6459513902664185, -1.5614869594573975, 0.09263267368078232, -0.19371019303798676, -1.8619593381881714, -0.2190641313791275, -0.62592613697052, 0.7170789837837219, 2.0938637256622314, 0.04755529761314392, 0.8852423429489136, 0.24461376667022705]
</code></pre><h3 id=rnn>RNN</h3><ul><li>用于处理有序列特性的数据：语言、语音、天气等</li><li>图示：<img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/8b5b6139-0e33-48a2-8be8-de0c6cf9588c.png width=798 height=1151 srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/8b5b6139-0e33-48a2-8be8-de0c6cf9588c_hu_c41d1efadeae426c.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/8b5b6139-0e33-48a2-8be8-de0c6cf9588c_hu_2c084a1167693871.png 1024w" loading=lazy alt=image.png class=gallery-image data-flex-grow=69 data-flex-basis=166px></li><li>Pytorch：<code>torch.nn.RNN(input_size,hidden_size,num_layer)</code><ul><li><code>input_size</code>：输入数据的维度，一般为词向量的维度</li><li><code>hidden_size</code>：隐藏层h的维度，也是当前层神经元输出的维度</li><li><code>num_layer</code>：隐藏层h的层数，默认为1</li></ul></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>words_to_index</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义RNN，input_size为每个分词嵌入后的维度，hidden_size为RNN隐状态维度</span>
</span></span><span class=line><span class=cl><span class=n>rnn</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>RNN</span><span class=p>(</span><span class=n>input_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span><span class=n>hidden_size</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span><span class=n>num_layers</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># inputs的第一个维度为时间步数（分词数量），第二个维度为batch，第三个维度为分词嵌入维度</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>embeddings</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># h0第一个维度为RNN层数，第二个维度为batch，第三个维度为每个h的维度</span>
</span></span><span class=line><span class=cl><span class=n>h0</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>,</span><span class=mi>64</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>inputs</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y</span><span class=p>,</span><span class=n>h</span> <span class=o>=</span> <span class=n>rnn</span><span class=p>(</span><span class=n>inputs</span><span class=p>,</span><span class=n>h0</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>{'电子科技大学': 0, '（': 1, 'UESTC': 2, '）': 3, '位于': 4, '四川': 5, '成都': 6, '，': 7, '是': 8, '中华人民共和国教育部': 9, '直属': 10, '全国': 11, '重点': 12, '大学': 13}
torch.Size([14, 1, 128])
</code></pre><h3 id=词表生成>词表生成</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 导入工具包</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>jieba</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn.functional</span> <span class=k>as</span> <span class=nn>F</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.optim</span> <span class=k>as</span> <span class=nn>optim</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>DataLoader</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>D:\Program\Anaconda\envs\dlab\lib\site-packages\jieba\_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.
  import pkg_resources
</code></pre><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 加载数据，构建词表</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>Tokenizer</span><span class=p>(</span><span class=n>path</span> <span class=o>=</span> <span class=s2>&#34;./Dataset/6_RNN_Zhoujielun/jaychou_lyrics.txt&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>all_word_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>path</span><span class=p>,</span><span class=s2>&#34;r&#34;</span><span class=p>,</span><span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>file</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>line</span> <span class=ow>in</span> <span class=n>file</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=ow>not</span> <span class=n>line</span><span class=p>:</span> <span class=k>continue</span> <span class=c1># 跳过空行</span>
</span></span><span class=line><span class=cl>            <span class=n>words</span> <span class=o>=</span> <span class=n>jieba</span><span class=o>.</span><span class=n>lcut</span><span class=p>(</span><span class=n>line</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>all_word_list</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>words</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>word_list</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>dict</span><span class=o>.</span><span class=n>fromkeys</span><span class=p>(</span><span class=n>all_word_list</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>word_to_index</span> <span class=o>=</span> <span class=p>{</span><span class=n>word</span><span class=p>:</span><span class=n>index</span> <span class=k>for</span> <span class=n>index</span><span class=p>,</span><span class=n>word</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>word_list</span><span class=p>)}</span>
</span></span><span class=line><span class=cl>        <span class=n>index_to_word</span> <span class=o>=</span> <span class=p>{</span><span class=n>index</span><span class=p>:</span><span class=n>word</span> <span class=k>for</span> <span class=n>word</span><span class=p>,</span><span class=n>index</span> <span class=ow>in</span> <span class=n>word_to_index</span><span class=o>.</span><span class=n>items</span><span class=p>()}</span>
</span></span><span class=line><span class=cl>        <span class=n>all_index</span> <span class=o>=</span> <span class=p>[</span><span class=n>word_to_index</span><span class=p>[</span><span class=n>word</span><span class=p>]</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>all_word_list</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>word_to_index</span><span class=p>,</span><span class=n>index_to_word</span><span class=p>,</span><span class=n>all_index</span><span class=p>,</span><span class=nb>len</span><span class=p>(</span><span class=n>word_to_index</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 构建数据集类，构建可迭代对象</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>LyricsDataset</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>Dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>all_indix</span><span class=p>,</span><span class=n>sent_len</span><span class=p>):</span> <span class=c1># 输入原始字典和句子长度</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>all_indix</span> <span class=o>=</span> <span class=n>all_indix</span> <span class=c1># 完整索引</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>sent_len</span> <span class=o>=</span> <span class=n>sent_len</span> <span class=c1># 句子长度</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>word_num</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>all_indix</span><span class=p>)</span> <span class=c1># 分词总数</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>sent_num</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>word_num</span> <span class=o>//</span> <span class=bp>self</span><span class=o>.</span><span class=n>sent_len</span> <span class=c1># 句子总数</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>sent_num</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>idx</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>idx</span> <span class=o>&lt;</span> <span class=mi>0</span><span class=p>:</span> <span class=n>idx</span> <span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>idx</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>word_num</span><span class=o>-</span><span class=bp>self</span><span class=o>.</span><span class=n>sent_len</span><span class=o>-</span><span class=mi>1</span> <span class=p>:</span> <span class=n>idx</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>word_num</span><span class=o>-</span><span class=bp>self</span><span class=o>.</span><span class=n>sent_len</span><span class=o>-</span><span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>all_indix</span><span class=p>[</span><span class=n>idx</span><span class=p>:</span><span class=n>idx</span><span class=o>+</span><span class=bp>self</span><span class=o>.</span><span class=n>sent_len</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>all_indix</span><span class=p>[</span><span class=n>idx</span><span class=o>+</span><span class=mi>1</span><span class=p>:</span><span class=n>idx</span><span class=o>+</span><span class=bp>self</span><span class=o>.</span><span class=n>sent_len</span><span class=o>+</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span><span class=p>,</span><span class=n>y</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 构建模型</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>LyricsGenerator</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>word_count</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>LyricsGenerator</span><span class=p>,</span><span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>ebd</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>word_count</span><span class=p>,</span><span class=mi>128</span><span class=p>)</span> <span class=c1># 将一个分析维度转为128</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>RNN</span><span class=p>(</span><span class=n>input_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span><span class=n>hidden_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span><span class=n>num_layers</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>out</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span><span class=n>word_count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>inputs</span><span class=p>,</span><span class=n>hidden</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ebd</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span><span class=p>,</span><span class=n>hidden</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=p>(</span><span class=n>emb</span><span class=p>,</span><span class=n>hidden</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>out</span><span class=p>(</span><span class=n>output</span><span class=o>.</span><span class=n>reshape</span><span class=p>((</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span><span class=n>output</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>])))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output</span><span class=p>,</span><span class=n>hidden</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>init_hidden</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>bs</span><span class=o>=</span><span class=mi>2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span><span class=n>bs</span><span class=p>,</span><span class=mi>128</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>word_index</span><span class=p>,</span><span class=n>index_word</span><span class=p>,</span><span class=n>all_index</span><span class=p>,</span><span class=n>dict_len</span> <span class=o>=</span> <span class=n>Tokenizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>word_dataset</span> <span class=o>=</span> <span class=n>LyricsDataset</span><span class=p>(</span><span class=n>all_index</span><span class=p>,</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>word_dataset</span><span class=o>.</span><span class=fm>__getitem__</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>Building prefix dict from the default dictionary ...
Loading model from cache C:\Users\leuco\AppData\Local\Temp\jieba.cache
Loading model cost 0.566 seconds.
Prefix dict has been built successfully.





(tensor([0, 1, 2, 3, 0, 4, 5, 6, 7, 8]),
 tensor([1, 2, 3, 0, 4, 5, 6, 7, 8, 3]))
</code></pre><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 模型训练</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>data_loader</span><span class=p>,</span><span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span><span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>batch_index</span><span class=p>,(</span><span class=n>X</span><span class=p>,</span><span class=n>y</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>data_loader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>X</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>hidden</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>init_hidden</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>hidden</span> <span class=o>=</span> <span class=n>hidden</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>output</span><span class=p>,</span><span class=n>hidden</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>X</span><span class=p>,</span><span class=n>hidden</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>y</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>y</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=c1># 展平为一维</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>output</span><span class=p>,</span><span class=n>y</span><span class=o>.</span><span class=n>long</span><span class=p>())</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>total_loss</span><span class=o>+=</span><span class=n>loss</span>
</span></span><span class=line><span class=cl>            <span class=n>total</span><span class=o>+=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>epoch</span> <span class=o>%</span> <span class=mi>10</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Epoch[</span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2>] : Loss = </span><span class=si>{</span><span class=n>total_loss</span><span class=o>/</span><span class=n>total</span><span class=si>:</span><span class=s2>.5f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl><span class=n>data_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>word_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>drop_last</span><span class=o>=</span><span class=kc>True</span>       
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>LyricsGenerator</span><span class=p>(</span><span class=n>dict_len</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>data_loader</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>Epoch[0] : Loss = 3.31849
Epoch[10] : Loss = 0.33738
</code></pre><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>```python
</span></span><span class=line><span class=cl>torch.save(model.state_dict(),&#39;./Model/6_Lyrics_Generator/Model.pth&#39;)
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 模型加载</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>LyricsGenerator</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;./Model/6_Lyrics_Generator/Model.pth&#39;</span><span class=p>,</span> <span class=n>weights_only</span><span class=o>=</span><span class=kc>True</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>&lt;All keys matched successfully&gt;
</code></pre><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 模型评估</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_lyrics</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>word_index</span><span class=p>,</span><span class=n>index_word</span><span class=p>,</span><span class=n>start_words</span><span class=p>,</span><span class=n>sentence_length</span><span class=p>,</span><span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>hidden</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>init_hidden</span><span class=p>(</span><span class=n>bs</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>word_idx</span> <span class=o>=</span> <span class=n>word_index</span><span class=p>[</span><span class=n>start_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>generate_sentence</span> <span class=o>=</span> <span class=p>[</span><span class=n>word_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>sentence_length</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span><span class=p>,</span><span class=n>hidden</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=n>word_idx</span><span class=p>]])</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span><span class=n>hidden</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>word_idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>output</span><span class=p>)</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>generate_sentence</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>word_idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>idx</span> <span class=ow>in</span> <span class=n>generate_sentence</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=n>index_word</span><span class=p>[</span><span class=n>idx</span><span class=p>],</span><span class=n>end</span><span class=o>=</span><span class=s1>&#39;&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>start</span> <span class=o>=</span> <span class=s1>&#39;知道&#39;</span>
</span></span><span class=line><span class=cl><span class=n>word_len</span> <span class=o>=</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl><span class=n>generate_lyrics</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>word_index</span><span class=p>,</span><span class=n>index_word</span><span class=p>,</span><span class=n>start</span><span class=p>,</span><span class=n>word_len</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><pre><code>知道这里很美但家乡的你更美原来我只想要你
陪我去吃汉堡 
说穿了其实我的愿望就怎么小
就怎么每天祈祷我的心跳你知道 
杵在伊斯坦堡 却只想你和汉堡
我想要你的微笑每天都能看到 
我知道这里很美但家乡的你更美原来我只想要你
陪我去吃汉堡 
说穿了其实我的愿望就怎么小
就怎么每天
</code></pre></section><footer class=article-footer><section class=article-tags><a href=/tags/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1/>交叉熵损失</a>
<a href=/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/>反向传播</a>
<a href=/tags/bp/>BP</a>
<a href=/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/>梯度下降</a>
<a href=/tags/dropout/>Dropout</a>
<a href=/tags/bn/>BN</a>
<a href=/tags/cnn/>CNN</a>
<a href=/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>卷积神经网络</a>
<a href=/tags/rnn/>RNN</a>
<a href=/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>循环神经网络</a>
<a href=/tags/%E5%8D%B7%E7%A7%AF%E5%B1%82/>卷积层</a>
<a href=/tags/%E6%B1%A0%E5%8C%96%E5%B1%82/>池化层</a>
<a href=/tags/%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%B1%82/>词嵌入层</a></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=[".main-article",".widget--toc"];e.forEach(e=>{const t=document.querySelector(e);t&&renderMathInElement(t,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/><div class=article-image><img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/output_45_1.ac66b82ba1a91437f422db6d948e641f_hu_2e3482a2dbd8838a.jpg width=250 height=150 loading=lazy alt="Featured image of post 机器学习-线性回归" data-hash="md5-rGa4K6GpFDf0ItttlI5kHw=="></div><div class=article-details><h2 class=article-title>机器学习-线性回归</h2></div></a></article><article class=has-image><a href=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/><div class=article-image><img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/output_3_1.97aa252439207abddc3143a10ae1f4f6_hu_d028bd9bd3a40326.png width=250 height=150 loading=lazy alt="Featured image of post 机器学习-集成学习" data-hash="md5-l6olJDkger3cMUOhCuH09g=="></div><div class=article-details><h2 class=article-title>机器学习-集成学习</h2></div></a></article><article class=has-image><a href=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/><div class=article-image><img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/cover.2160315d961f55820735b9d476c635c6_hu_fc8c29d55bf14e3a.png width=250 height=150 loading=lazy alt="Featured image of post 机器学习-无监督学习" data-hash="md5-IWAxXZYfVYIHNbnUdsY1xg=="></div><div class=article-details><h2 class=article-title>机器学习-无监督学习</h2></div></a></article><article class=has-image><a href=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB/><div class=article-image><img src=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB/SVM.b96e9ba18f9f55522ce3f1ae5994872a_hu_3db6860e7015ff5e.jpg width=250 height=150 loading=lazy alt="Featured image of post 机器学习-线性分类" data-hash="md5-uW6boY+fVVIs4/GuWZSHKg=="></div><div class=article-details><h2 class=article-title>机器学习-线性分类</h2></div></a></article><article><a href=/p/web%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%80/><div class=article-details><h2 class=article-title>Web安全基础</h2></div></a></article></div></div></aside><script src=https://utteranc.es/client.js repo=leuco-yuu/blog-comments issue-term=pathname crossorigin=anonymous async></script><style>.utterances{max-width:unset}</style><script>let utterancesLoaded=!1;function setUtterancesTheme(e){let t=document.querySelector(".utterances iframe");t&&t.contentWindow.postMessage({type:"set-theme",theme:`github-${e}`},"https://utteranc.es")}addEventListener("message",e=>{if(e.origin!=="https://utteranc.es")return;utterancesLoaded=!0,setUtterancesTheme(document.documentElement.dataset.scheme)}),window.addEventListener("onColorSchemeChange",e=>{if(!utterancesLoaded)return;setUtterancesTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2025 -
2026 Leuco(leucoyuu@163.com)</section><section class=powerby>Embrace Bit Art<br>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.32.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.29c987cab5419174d4dc85c2a56544a08027cc7f77efb5749447a3e80f85a03d.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>