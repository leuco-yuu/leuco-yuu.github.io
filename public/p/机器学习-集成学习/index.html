<!DOCTYPE html>
<html lang="zh-cn" dir="ltr">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="【4】机器学习第四部分 从决策树到集成学习">
<meta name="keywords" content="决策树, Bagging, Boosting, 随机森林, OOB, 袋外数据, AdaBoost, GBDT"><title>机器学习-集成学习</title>

<link rel='canonical' href='http://localhost:1313/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/'>

<link rel="stylesheet" href="/scss/style.min.4ebb72b19bf107a2d2a8110366ec741defa89660873efbae8076e12ff77b6661.css"><meta property='og:title' content="机器学习-集成学习">
<meta property='og:description' content="【4】机器学习第四部分 从决策树到集成学习">
<meta property='og:url' content='http://localhost:1313/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/'>
<meta property='og:site_name' content='Lecuo&#39;s Blog'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='决策树' /><meta property='article:tag' content='Bagging' /><meta property='article:tag' content='Boosting' /><meta property='article:tag' content='随机森林' /><meta property='article:tag' content='OOB' /><meta property='article:tag' content='袋外数据' /><meta property='article:tag' content='AdaBoost' /><meta property='article:tag' content='GBDT' /><meta property='article:published_time' content='2025-12-02T20:30:43&#43;08:00'/><meta property='article:modified_time' content='2025-12-02T20:30:43&#43;08:00'/><meta property='og:image' content='http://localhost:1313/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/output_3_1.png' />
<meta name="twitter:title" content="机器学习-集成学习">
<meta name="twitter:description" content="【4】机器学习第四部分 从决策树到集成学习"><meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content='http://localhost:1313/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/output_3_1.png' />
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="切换菜单">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu_f6aa26e80a833272.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Lecuo&#39;s Blog</a></h1>
            <h2 class="site-description"></h2>
        </div>
    </header><ol class="menu-social">
            
                <li>
                    <a 
                        href='https://github.com/leuco-yuu/'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg
  xmlns="http://www.w3.org/2000/svg"
  width="24"
  height="24"
  viewBox="0 0 24 24"
  fill="none"
  stroke="currentColor"
  stroke-width="2.5"
  stroke-linecap="round"
  stroke-linejoin="round"
>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22" />
</svg>

                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://mail.google.com/mail/u/0/?tf=cm&amp;to=leucoyuu@gmail.com&amp;fs=1'
                        target="_blank"
                        title="Gmail"
                        rel="me"
                    >
                        
                        
                            <svg
  xmlns="http://www.w3.org/2000/svg"
  width="24"
  height="24"
  viewBox="0 0 24 24"
  fill="none"
  stroke="currentColor"
  stroke-width="2"
  stroke-linecap="round"
  stroke-linejoin="round"
>
  <!-- 信封外框 -->
  <rect x="2" y="4" width="20" height="16" rx="2" />
  
  <!-- 信封内部线条（模拟折叠效果） -->
  <polyline points="3,5 12,14 21,5" />
</svg>
                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://wpa.qq.com/msgrd?v=3&amp;uin=1286938728&amp;site=qq&amp;menu=yes/'
                        target="_blank"
                        title="QQ"
                        rel="me"
                    >
                        
                        
                            <svg height="32" viewBox="0 0 32 32" width="32" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m15.9998867 0-.3175962.00373031c-6.8340705.16105657-10.59798873 5.52198001-10.62328209 13.09956699l.00099159.2727027-.86256398 2.1053645c-.34339269.8459887-.59479858 1.4918602-.8236549 2.1249911-.16246446.4494579-.31092035.8862129-.4515632 1.3302912-1.41043336 4.4529342-1.46997142 7.7313526 1.14979123 8.0424546l.19586827.0182568c.69853306.0462522 1.18775172-.1357889 1.69345756-.5695745l.04666502-.0427837.10703497.1859114.16295747.2641667.09000756.1369219-.10203891.0725127c-1.18457469.8599516-1.78515849 2.0422997-.8749963 3.5478041.72014893 1.1919865 1.68579016 1.3851809 4.67654251 1.4059241h1.2781117l.7210113-.0101194c1.4578857-.0287327 2.9764342-.1065736 3.9343697-.2001215l.2555297.0243167c1.1291243.09698 2.8606159.1735357 4.3993902.1859242h1.2781118c2.9907546-.0207471 3.95642-.2139816 4.6768437-1.4064227l.0983227-.1723424c.764361-1.4241985.1648309-2.548721-.9747412-3.3755348l-.1034569-.072941.0912293-.1362605.1629318-.2641511.1068389-.1855884.0466679.0427821c.5516504.4732059 1.0836451.6468525 1.8890001.5513616 2.6200145-.3116105 2.5604594-3.5895097 1.1502083-8.0424822-.136678-.4315245-.2810058-.8567817-.4385987-1.2939849l-.1781698-.4846461c-.0923296-.2464665-.1903348-.5013359-.2976536-.7744519l-.3954267-.9868956-.8290275-2.020683.0009399-.279262c-.038761-7.60576089-3.8169423-12.93053326-10.6187985-13.09291824zm.0001023 2c6.339972.00032813 9.0947051 5.25726658 8.9334981 11.7557738l.8516442 2.0748544c.5606846 1.3708665.9939584 2.4718584 1.3860782 3.7098724 1.2134003 3.8314013.8203049 5.4169539.5209683 5.4525554-.6424867.0761796-2.5006035-2.8842697-2.5006035-2.8842697 0 1.7141775-.8994592 3.9510027-2.8457046 5.5664147l.3377045.1073023c1.0249215.341207 2.6653848 1.0302704 2.2154641 1.7750936-.4078113.675007-6.9962271.4309917-8.8982689.2207732l-.4753503.0452169c-2.33636.195172-8.04423656.3608021-8.42291849-.2659901-.50418989-.8339832 1.61195836-1.5976385 2.55205373-1.8820678-1.94652419-1.615412-2.84615056-3.852456-2.84615056-5.5667428l-.32111727.4924567c-.56063792.838483-1.70355568 2.4482423-2.17943051 2.391813-.29933663-.0355468-.69254342-1.6211541.52102408-5.4525554l.21887662-.6654718c.52220361-1.5311231 1.13363576-2.9515889 2.01884579-5.1193097-.17029299-6.39290578 2.5220086-11.75539097 8.93338651-11.7557191z" fill="currentColor" fill-rule="nonzero"/></g></svg>
                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>主页</span>
            </a>
        </li>
        
        
        <li >
            <a href='/%E5%8D%9A%E4%B8%BB/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>博主</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>博文</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>搜索</span>
            </a>
        </li>
        
        
        <li >
            <a href='/%E9%93%BE%E6%8E%A5/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5" />
  <path d="M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5" />
</svg>



                
                <span>链接</span>
            </a>
        </li>
        
        <li class="menu-bottom-section">
            <ol class="menu">

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>暗色模式</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">目录</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ul>
    <li><a href="#决策树decision-making-tree">决策树（Decision-Making Tree）</a></li>
    <li><a href="#集成学习ensemble-learning-1">集成学习（Ensemble Learning）</a>
      <ul>
        <li><a href="#分类">分类</a>
          <ul>
            <li><a href="#bagging">Bagging</a></li>
            <li><a href="#boosting">Boosting</a></li>
          </ul>
        </li>
        <li><a href="#随机森林random-forest">随机森林（Random Forest）</a>
          <ul>
            <li><a href="#袋外数据oobout-of-bag-data">袋外数据（OOB，Out of bag data）</a></li>
          </ul>
        </li>
        <li><a href="#adaboostadaptive-boosting自适应增强">AdaBoost（Adaptive Boosting，自适应增强）</a></li>
        <li><a href="#gbdt梯度提升决策树">GBDT（梯度提升决策树）</a></li>
      </ul>
    </li>
  </ul>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="has-image main-article">
    <header class="article-header">
        <div class="article-image">
            <a href="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/">
                <img src="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/output_3_1_hu_8eb4ff774e057c3c.png"
                        srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/output_3_1_hu_8eb4ff774e057c3c.png 800w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/output_3_1_hu_f2893e93595d1534.png 1600w"
                        width="800" 
                        height="591" 
                        loading="lazy"
                        alt="Featured image of post 机器学习-集成学习" />
                
            </a>
        </div>
    

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="background-color: #2a9d8f; color: #fff;">
                机器学习
            </a>
        
            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" style="background-color: #2a9d8f; color: #fff;">
                学习笔记
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/">机器学习-集成学习</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            【4】机器学习第四部分 从决策树到集成学习
        </h3>
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published" datetime='2025-12-02T20:30:43&#43;08:00'>Dec 02, 2025</time>
            </div>
        

        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <div class="custom-toc">
  <h3>目录</h3>
  <nav id="TableOfContents">
  <ul>
    <li><a href="#决策树decision-making-tree">决策树（Decision-Making Tree）</a></li>
    <li><a href="#集成学习ensemble-learning-1">集成学习（Ensemble Learning）</a>
      <ul>
        <li><a href="#分类">分类</a>
          <ul>
            <li><a href="#bagging">Bagging</a></li>
            <li><a href="#boosting">Boosting</a></li>
          </ul>
        </li>
        <li><a href="#随机森林random-forest">随机森林（Random Forest）</a>
          <ul>
            <li><a href="#袋外数据oobout-of-bag-data">袋外数据（OOB，Out of bag data）</a></li>
          </ul>
        </li>
        <li><a href="#adaboostadaptive-boosting自适应增强">AdaBoost（Adaptive Boosting，自适应增强）</a></li>
        <li><a href="#gbdt梯度提升决策树">GBDT（梯度提升决策树）</a></li>
      </ul>
    </li>
  </ul>
</nav>
</div>
<h1 id="集成学习ensemble-learning">集成学习（Ensemble Learning）
</h1><h2 id="决策树decision-making-tree">决策树（Decision-Making Tree）
</h2><ul>
<li>决策树是有监督机器学习的一种</li>
<li>模型生成：通过大量数据生成一棵非常好的树（寻找最优的分裂条件）</li>
<li>预测：按照生成好的树的标准落到某一个叶子节点上</li>
<li>算法思想
$$
  \begin{aligned}
  & function \ \operatorname{DecisionTree}(data:\mathcal{D}=\{(x_n,y_n)\}_{n=1}^N) \\
  &\qquad \operatorname{if} \ termination\ citeria met: \qquad\text{//如果满足终止条件}\\
  &\qquad\qquad \begin{aligned}
  \operatorname{return}\ base\ hypothesis\ g_t(x) \qquad\text{//返回第t个叶子节点的值}
  \end{aligned}\\
  &\qquad\operatorname{else}\\
  &\qquad\qquad \begin{aligned}
  & \operatorname{learn}\ branching\ criteria\ b(x)  \qquad\text{//学习最优分裂条件b(x)，该条件产生C个结果分支}\\
  & split\ \mathcal{D}\ to\ C\ parts\ \mathcal{D}_C=\{(x_n,y_n):b(x_n)=c\} \qquad//把当前的数据集\mathcal{D}切分成C个部分  \\ 
  & \operatorname{build}\ sub-tree\ G_C\ \leftarrow \ \operatorname{DecisionTree}(\mathcal{D}_C) \qquad\text{//递归在子结点上再进行子树划分}\\
  & \operatorname{return}\ G(x)=\displaystyle{\sum^C_{c=1}[[b(x)==c]]G_C(x)} \qquad\text{//返回整体数结构表达式}
  \end{aligned}
  \end{aligned}
  $$</li>
<li>生成决策树所需分裂指标——离散问题（$D_c为特征A的第c个取值样本子集$）
<ul>
<li>Gini系数：
<ul>
<li>公式： $$\displaystyle{Gini^{init}(p)=\sum_{k=1}^Kp_k(1-p_k)=1-\sum_{k=1}^Kp_k^2}$$</li>
<li>基尼系数越小，代表D集合中的数据约纯，所以可以计算分裂前的值在按照某个维度对数据集进行划分，然后计算多个节点的Gini系数：$$\displaystyle{Gini^{Divided}(D,A)=\sum_{c \in Values(A)}\frac{|D_c|}{|D|}Gini(D_c) }$$</li>
<li>收益函数：$$Gain(D,A)=Gini^{init}(D)-Gini^{Devided}(D,A)$$</li>
</ul>
</li>
<li>信息增熵：$H(X) \simeq Gini(X)$
<ul>
<li>公式： $$\displaystyle{H(N) = -\sum_j P(\omega_j)\log_2P(\omega_j) }$$</li>
<li>划分后的多个结点的熵之和：$$\displaystyle{H^{Devided}(D,A)=-\sum_{c \in Values(A)}\frac{|D_c|}{|D|}H(D_c) }$$</li>
<li>收益函数：$$\displaystyle{Gain(D,A)=H^{init}(D)-H^{Devided}(D,A)}$$</li>
</ul>
</li>
<li>信息增益率
<ul>
<li>特征A的固有值（Intrinsic Value）：$$\operatorname{IV}(A)=\displaystyle{-\sum_{c \in Values(A)}\frac{|D_c|}{|D|}log_2\frac{|D_c|}{|D|}}$$</li>
<li>信息增益率：$$\displaystyle{GainRatio(D,A)=\frac{Gain(D,A)}{IV(A)}}$$</li>
</ul>
</li>
<li>MSE（回归问题）</li>
</ul>
</li>
<li>剪枝：解决过拟合问题
<ul>
<li>前剪枝：在构建决策树的过程中，限定最小叶子内的节点数、最大深度等条件</li>
<li>后剪枝:
<ul>
<li>REP——错误率降低剪枝</li>
<li>PEP——悲观剪枝</li>
<li>CCP——代价复杂度剪枝
<ul>
<li>CCP为子树 $ T_t $ 定义了代价（cost）和复杂度（complexity），以及一个可由用户设置的衡量代价与复杂度之间关系的参数 $ \alpha^* $ ，其中代价指的是在剪枝过程中因子树 $ T_t $ 被叶子节点替代而增加的错分样本，复杂度表示剪枝后子树 $ T_t $ 减少的叶子节点数量。 $ \alpha $ 表示剪枝后树的复杂度减低程度与代价之间的关系。当 $ \alpha^* &lt; \alpha $ 时就可以将该节点下的子树剪掉，当前节点作为叶子节点
$$
        \begin{aligned}
        &\alpha = \displaystyle{\frac{R(t)-R(T_t)}{|N_1|-1}}\\
        其中，&|N_1|:子树T_t中的叶子节点数 \\
        & R(t)为结点t的错误代价，R(t)=r(t)*p(t) \\
        & r(t)为结点t的错分样本率，p(t)为落入结点t的样本占所有样本的比例 \\
        & R(T_t)为子树T_t的错误代价，R(T_t)=\displaystyle{\sum_iR(i)},i为子树T_t的叶子节点
        \end{aligned}
      $$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>各特征重要性评估指标：$$FI(j)=\displaystyle{\frac{\displaystyle{\sum_{t\ use\ j}N_t·Gain(t)}}{\displaystyle{\sum_{all\ t}N_t·Gain(t)}}}$$，其中 $ N_t $ 是分裂节点 $ t $ 的样本数</li>
<li>在线绘制工具：<a class="link" href="https://dreampuf.github.io/GraphvizOnline/"  target="_blank" rel="noopener"
    >Graphviz Online</a></li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 决策树实现鸢尾花分类</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">names</span><span class="p">,</span><span class="n">species</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">s</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">product</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span><span class="n">repeat</span><span class="o">=</span><span class="mi">2</span><span class="p">)])))</span> <span class="k">if</span> <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">!=</span><span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">    <span class="n">fig</span><span class="p">,</span><span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">index</span><span class="p">,((</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">),</span><span class="n">ax</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">axs</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">lab</span><span class="p">][:,</span><span class="n">x1</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">lab</span><span class="p">][:,</span><span class="n">x2</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;[</span><span class="si">{</span><span class="n">lab</span><span class="si">}</span><span class="s2">]</span><span class="si">{</span><span class="n">species</span><span class="p">[</span><span class="n">lab</span><span class="p">]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span> <span class="k">for</span> <span class="n">lab</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">names</span><span class="p">[</span><span class="n">x1</span><span class="p">]</span><span class="si">}</span><span class="s2">:Data[</span><span class="si">{</span><span class="n">x1</span><span class="si">}</span><span class="s2">]&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">names</span><span class="p">[</span><span class="n">x2</span><span class="p">]</span><span class="si">}</span><span class="s2">:Data[</span><span class="si">{</span><span class="n">x2</span><span class="si">}</span><span class="s2">]&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">show</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">pip</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s1">&#39;dtc&#39;</span><span class="p">,</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">428</span><span class="p">)),</span>  
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">pip</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Accuracy of the test set (four features): </span><span class="si">{</span><span class="n">pip</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">export_graphviz</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">pip</span><span class="p">[</span><span class="s1">&#39;dtc&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">out_file</span><span class="o">=</span><span class="s2">&#34;Output/Iris_Decision_Tree/tree_dot.dot&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">node_ids</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;feature importances: </span><span class="si">{</span><span class="n">pip</span><span class="p">[</span><span class="s1">&#39;dtc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">feature_importances_</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span> <span class="c1">#特征0与特征1的重要性极低</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">pip</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">],</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Accuracy of the test set (two features): </span><span class="si">{</span><span class="n">pip</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">],</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">export_graphviz</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">pip</span><span class="p">[</span><span class="s1">&#39;dtc&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">out_file</span><span class="o">=</span><span class="s2">&#34;Output/Iris_Decision_Tree/tree1_dot.dot&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">node_ids</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#深度探测：寻找最优树深</span>
</span></span><span class="line"><span class="cl"><span class="n">scores</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">depth</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">15</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">dtc</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">428</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">dtc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">],</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">scores</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">depth</span><span class="p">)]</span><span class="o">=</span><span class="n">dtc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">],</span><span class="n">y_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>​ <br>
<img src="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/output_1_0.png"
	width="1189"
	height="689"
	srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/output_1_0_hu_892aad4067364684.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/output_1_0_hu_f67fb326619163b9.png 1024w"
	loading="lazy"
	
		alt="png"
	
	
		class="gallery-image" 
		data-flex-grow="172"
		data-flex-basis="414px"
	
>
​</p>
<pre><code>Accuracy of the test set (four features): 1.0
feature importances: [0.03334028 0.         0.88947325 0.07718647]
Accuracy of the test set (two features): 1.0
{'1': 0.6333333333333333, '2': 0.9666666666666667, '3': 1.0, '4': 1.0, '5': 1.0, '6': 1.0, '7': 1.0, '8': 1.0, '9': 1.0, '10': 1.0, '11': 1.0, '12': 1.0, '13': 1.0, '14': 1.0}
</code></pre>
<p><img src="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/afe81b13-a054-4d53-b862-efd47e58b46e.png"
	width="884"
	height="1135"
	srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/afe81b13-a054-4d53-b862-efd47e58b46e_hu_1aaed07c82852f48.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/afe81b13-a054-4d53-b862-efd47e58b46e_hu_a5cedf7af55ea54a.png 1024w"
	loading="lazy"
	
		alt="four_feature.png"
	
	
		class="gallery-image" 
		data-flex-grow="77"
		data-flex-basis="186px"
	
>
<img src="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/edb63317-19bf-4f88-a8aa-608ec5a4b587.png"
	width="884"
	height="1135"
	srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/edb63317-19bf-4f88-a8aa-608ec5a4b587_hu_f0ad5320c811b6b6.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/edb63317-19bf-4f88-a8aa-608ec5a4b587_hu_8e001cae38735f5a.png 1024w"
	loading="lazy"
	
		alt="two_feature.png"
	
	
		class="gallery-image" 
		data-flex-grow="77"
		data-flex-basis="186px"
	
></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 决策树拟合回归模型</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">colors</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;#e41a1c&#39;</span><span class="p">,</span> <span class="s1">&#39;#377eb8&#39;</span><span class="p">,</span> <span class="s1">&#39;#4daf4a&#39;</span><span class="p">,</span> <span class="s1">&#39;#984ea3&#39;</span><span class="p">,</span>  <span class="c1"># 红 蓝 绿 紫</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;#ff7f00&#39;</span><span class="p">,</span> <span class="s1">&#39;#ffff33&#39;</span><span class="p">,</span>                         <span class="c1"># 橙 黄</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;#1b9e77&#39;</span><span class="p">,</span> <span class="s1">&#39;#d95f02&#39;</span><span class="p">,</span> <span class="s1">&#39;#7570b3&#39;</span><span class="p">,</span> <span class="s1">&#39;#e7298a&#39;</span><span class="p">,</span>   <span class="c1"># 青 棕 靛 洋红</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;#66a61e&#39;</span><span class="p">,</span> <span class="s1">&#39;#666666&#39;</span>                          <span class="c1"># 草绿 深灰</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">colors</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">mapping</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">20030428</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mf">0.1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 特征数</span>
</span></span><span class="line"><span class="cl"><span class="n">n</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 数据量</span>
</span></span><span class="line"><span class="cl"><span class="n">m</span> <span class="o">=</span> <span class="mi">10000</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 随机生成 x 序列</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">-</span> <span class="mi">4</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 模拟非线性回归分布</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">mapping</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">train_size</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">428</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># plt.scatter(X_train,y_train)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">index</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">scores</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">depth</span><span class="p">,</span><span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">15</span><span class="p">),</span><span class="n">colors</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">dtr</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">428</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">dtr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">scores</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">depth</span><span class="p">)]</span> <span class="o">=</span> <span class="n">dtr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">export_graphviz</span><span class="p">(</span><span class="n">dtr</span><span class="p">,</span><span class="n">out_file</span><span class="o">=</span><span class="s2">&#34;Output/Practice01_Reg_Decision_Tree/depth_&#34;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">depth</span><span class="p">)</span><span class="o">+</span><span class="s2">&#34;.dot&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">depth</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">9</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">dtr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span><span class="n">ms</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&#34;depth=&#34;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">depth</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">depth</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">values</span><span class="p">()))])</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span><span class="n">scores</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">depth</span><span class="p">)])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>3000 3000
{'3': 0.6082955315717642, '4': 0.7350159653921886, '5': 0.8994966783739446, '6': 0.9402911147144416, '7': 0.9630064233693199, '8': 0.969353657452782, '9': 0.9713638580425933, '10': 0.9699000308717682, '11': 0.9676749619741486, '12': 0.9648717916673495, '13': 0.963189780460903, '14': 0.9609148583309566}
9 0.9713638580425933
</code></pre>
<p><img src="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/output_3_1.png"
	width="559"
	height="413"
	srcset="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/output_3_1_hu_334df7bfa543b7.png 480w, /p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/output_3_1_hu_2cebc004e3f10dc1.png 1024w"
	loading="lazy"
	
		alt="png"
	
	
		class="gallery-image" 
		data-flex-grow="135"
		data-flex-basis="324px"
	
></p>
<h2 id="集成学习ensemble-learning-1">集成学习（Ensemble Learning）
</h2><ul>
<li>Advance-Organizer：假设有10个决策树
<ul>
<li>单决策树算法：找到10个决策树中最可靠的决策树树进行预测</li>
<li>随机森林算法：所有决策树进行投票，少数服从多数</li>
<li>Adaboost：更可靠的决策树分到更多的票数</li>
</ul>
</li>
<li>集成学习的单个弱学习器可以基于不同的学习策略构建</li>
<li>
<h3 id="分类">分类
</h3></li>
</ul>
<h4 id="bagging">Bagging
</h4><ul>
<li>训练：有放回地对原始训练集进行均匀抽样（Bootstrap抽样），将抽样结果用于并行独立训练 $g(x)$</li>
<li>模型：同权重投票，对于分类任务少数服从多数；对于回归任务取平均</li>
<li>例如：random forest</li>
</ul>
<h4 id="boosting">Boosting
</h4><ul>
<li>训练：通过训练集训练 $g_i$ ，再通过 $ g_k(k\in{1,2\dots i}) $ 的预测结果调整训练集，训练得到 $ g_{i+1} $</li>
<li>模型：按照某个权重序列进行投票，对于回归任务求加权平均</li>
<li>例如：Adaboost，GBDT，Xgboost</li>
</ul>
<h3 id="随机森林random-forest">随机森林（Random Forest）
</h3><ul>
<li>Bagging思想 + 决策树基学习器 + 同权投票</li>
<li>模型训练：
<ul>
<li>采样：有放回的从原始数据中随机抽取部分样本或特征</li>
<li>训练：使用每次采样获得的子训练集分别并行训练决策树</li>
<li>模型：随机森林投票（同权投票，少数服从多数）</li>
</ul>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span><span class="n">BaggingClassifier</span><span class="p">,</span><span class="n">VotingClassifier</span> <span class="c1"># 集成学习器</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span> <span class="c1"># 逻辑回归</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span> <span class="c1"># 支持向量机</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span> <span class="c1"># 决策树 基学习器</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">428</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">rfc</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span> <span class="c1"># 随机森林</span>
</span></span><span class="line"><span class="cl">    <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="c1"># 多少棵树</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># max_depth=8, # 单棵树最大深度</span>
</span></span><span class="line"><span class="cl">    <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="c1"># 最大叶子节点数</span>
</span></span><span class="line"><span class="cl">    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># 启用所有CPU资源</span>
</span></span><span class="line"><span class="cl">    <span class="n">max_samples</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># 单次抽取的样本数量。默认最大数量的有放回随机取样</span>
</span></span><span class="line"><span class="cl">    <span class="n">max_features</span><span class="o">=</span><span class="s1">&#39;sqrt&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">bootstrap</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">random_state</span><span class="o">=</span><span class="mi">428</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># OOB算法，具体见下文</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># verbose=True</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rfc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;RandomForest Accuracy: </span><span class="si">{</span><span class="n">rfc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;RandomForest OOB Score: </span><span class="si">{</span><span class="n">rfc</span><span class="o">.</span><span class="n">oob_score_</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span> <span class="c1"># OOB_SCORE为无偏估计</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">bgc</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">estimator</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">(),</span> <span class="c1"># 用逻辑回归作为基学习器，默认为决策树</span>
</span></span><span class="line"><span class="cl">    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="c1"># 基学习器个数</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># max_samples=None, # 单次抽样的样本个数</span>
</span></span><span class="line"><span class="cl">    <span class="n">max_features</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="c1"># 随机选择特征</span>
</span></span><span class="line"><span class="cl">    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">bootstrap</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">random_state</span><span class="o">=</span><span class="mi">428</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># OOB算法，具体见下文</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># verbose=True</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">bgc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Bagging Accuracy: </span><span class="si">{</span><span class="n">bgc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Bagging OOB Score: </span><span class="si">{</span><span class="n">bgc</span><span class="o">.</span><span class="n">oob_score_</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span> <span class="c1"># OOB_SCORE为无偏估计</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">vtc</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span><span class="n">LogisticRegression</span><span class="p">()),</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="s1">&#39;svm&#39;</span><span class="p">,</span><span class="n">SVC</span><span class="p">()),</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="s1">&#39;DT&#39;</span><span class="p">,</span><span class="n">DecisionTreeClassifier</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># 全部核</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># verbose=True</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">vtc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Voting Accuracy: </span><span class="si">{</span><span class="n">bgc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>RandomForest Accuracy: 0.9666666666666667
RandomForest OOB Score: 0.95
Bagging Accuracy: 0.9666666666666667
Bagging OOB Score: 0.975
Voting Accuracy: 0.9666666666666667
</code></pre>
<h4 id="袋外数据oobout-of-bag-data">袋外数据（OOB，Out of bag data）
</h4><ul>
<li>一条数据N轮都没有被抽到的概率为 $\displaystyle{\underset{N\rightarrow\infty}{limit}\ (1-\frac{1}{N})^N = \frac{1}{e} \approx 36.79%}$</li>
<li>整个训练过程中有大约 36.79% 的数据未被使用（这部分数据称为OOB），OOB为天然验证集</li>
<li>思想：无需像交叉验证一样显式地将数据集划分为训练集和验证集，就可以在训练过程中天然、无偏地评估模型地泛化能力，解决了验证集需要额外数据或减少训练数据量的问题。OOB判断仅基于样本是否被包含在Bootstrap训练集中，而与特征使用无关</li>
<li>具体算法过程
<ul>
<li>第一步：训练阶段（假设原始训练集 $ D $ ，大小为 $ N $ 。构建一个包含 $ T $ 课决策树的随机森林）
<ol>
<li>对每棵树 $ t_i(i = 1,2\dots T) $ 进行 $ Bootstrap $ 抽样
<ul>
<li>从 $ D $ 中有放回地随机抽取 $ N $ 个样本，形成该树的 $ Bootstrap $ 训练集 $ D_i $</li>
<li>同时，没有被抽中的样本构成袋外样本集 $ OOB_i $ 。每个样本作为袋外样本的概率为36.79%</li>
</ul>
</li>
<li>用 $ D_i $ 训练第 $ i $ 课决策树 $ t_i $
<ul>
<li>训练时，随机森林还会从所有特征中随机选择一部分特征进行节点的分裂，以增加树的多样性。</li>
</ul>
</li>
<li>记录每个样本的OOB预测器
<ul>
<li>对于一个特定的样本 $ (x,y) $ ，找出所有没有使用它进行训练的树。即找到所有 $ OOB_i,(x,y)\in OOB_i $ 。这些树组成了样本 $ (x,y) $ 的OOB预测器</li>
</ul>
</li>
</ol>
</li>
<li>第二步：评估OOB误差（泛化误差估计）
<ol>
<li>对每个样本 $ (x,y) $ 进行OOB预测
<ul>
<li>取出该样本的OOB预测器集合</li>
<li>让这个预测器集合中的每棵决策树对x进行预测</li>
<li>通过投票（对于分类问题）或平均（对于回归问题）的方式，汇总这些树的预测结果，得到样本 $ (x,y) $ 的最终OOB预测值 $ \hat y_{OOB} $</li>
</ul>
</li>
<li>计算所有样本的OOB误差
<ul>
<li>分类问题（分类错误率）： $$OOB\_Error = \displaystyle{\frac{1}{N}\sum^N_{i=1}I(y_i\neq \hat y_{OOB_i})} $$ ，其中 $ I(j) $ 为指示函数，若 $ j $ 为 $ True $ 则输出 $ 1 $ ； $ j $ 为 $ False $ 则输出 $ 0 $</li>
<li>回归问题（均方误差）： $$ OOB\_Error = \displaystyle{\frac{1}{N}\sum^N_{i=1}(y_i-\hat y_{OOB_i})^2} $$</li>
</ul>
</li>
<li>该误差作为模型泛化能力的无偏估计，用于评估模型性能；指导模型超参数的选择，无需额外验证集；确定最优的树数量；进行模型诊断；指导特征选择；作为早期停止准则</li>
</ol>
</li>
<li>第三步：其他应用
<ul>
<li>特征重要性评估：如果一个特征很重要，那么随机打乱其值会显著降低模型性能
<ul>
<li>对于每棵树 $ t_i $ ，计算袋外样本 $ OOB_i $ 的误差，记作 $ Err_{OOB_i} $</li>
<li>随机打乱（排序） $ OOB_i $ 中的某个特征j的值</li>
<li>用打乱后的 $ OOB_i $ 再次计算 $ t_i $ 的预测误差，记作 $ Err_{perm_i} $</li>
<li>对于特征 $ j $ ，它在所有树上的重要性得分可以计算为： $$ \displaystyle{Importance_j = \frac{1}{T}\sum_{i=1}^T(Err_{perm_i}-Err_{OOB_i}) }$$ ，该值衡量了由于特征j被打乱导致的模型性能下降程度。下降得越多，该特征越重要</li>
<li>将所有特征得重要性得分进行归一化，以便比较</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="adaboostadaptive-boosting自适应增强">AdaBoost（Adaptive Boosting，自适应增强）
</h3><ul>
<li>思想：
<ul>
<li>弱分类器：AdaBoost通过将多个比较简单的、性能较弱的基学习器（“弱分类器”）组合起来，构建出强大的、性能优异的“强分类器”。通常一个弱分类器为深度为 1 的二分决策树（决策树桩）。</li>
<li>“自适应”：在每一轮训练中，它都会根据前一轮的分类结果、自动调整训练数据的权重分布，使得算法在后续轮次中更加关注那些被前一个弱分类器分错的样本（提高分错样本在损失函数中的权重）。这样，每个新生成的弱分类器都是在“弥补”前一个分类器的不足。</li>
<li>重点关注错误：在训练过程中更加关注那些被前一个分类器分错的样本。通过不断调整样本的权重实现</li>
<li>专家投票：每个弱分类器的水平有高有低。最终决策时性能好的弱分类器原有更大的投票权重</li>
</ul>
</li>
<li>算法流程：
<ul>
<li>初始化：为每个样本分配相同的初始权重：$$\displaystyle{w_i^{(0)}=\frac{1}{m},i \in \{1,2,\dots m\}}$$</li>
<li>训练T个弱分类器： $$G_t(x),t \in \{1,2,\dots T\}$$
<ul>
<li>使用当前的样本权重分布 $w_t$ 训练一个二分类弱分类器 $G_t(x)$</li>
<li>计算当前弱分类器的加权错误率 $$\displaystyle{\epsilon_t=\sum_{i=1}^mw_i^{(t)}·I(G_t(x_i) \neq y_i)} \le 0.5$$，$$
      其中, I(j) = 
      \begin{cases}
      1,& j=True \\
      0,& j=False \\
      \end{cases}
      $$</li>
<li>计算当前弱分类器的权重： $\alpha_t = \displaystyle{\frac{1}{2}ln(\frac{1-\epsilon_t}{\epsilon_t})}$，
$$
      \begin{cases}
      &\alpha \rightarrow +\infty , &\epsilon=0 \\
      &\alpha = 0 , &\epsilon=0.5 \\
      &\alpha > 0 , &\epsilon < 0.5, \ 且\epsilon_t越小，\alpha_t越大
      \end{cases}
      $$</li>
<li>更新样本权重：
$$
      \begin{array}
       ww_i^{t+1}=w_i^{(t)}\exp(-\alpha_t·y_i·D_t(x_i))·Z_t \\
      y_iG_t(x_i)=\begin{cases}
      +1,x_i分类正确 \\
      -1,x_i分类错误 \\
      \end{cases} \\
      Z_t为规范化因子，为常数，目的是让所有权重加起来等于1
      \end{array}
      $$</li>
</ul>
</li>
<li>组合所有分类器
<ul>
<li>经过T轮迭代，得到T个弱分类器及其权重 $$\{G_t,\alpha_t\}, t \in \{1,2\dots T\}$$</li>
<li>最终的强分类器F(x)是所有弱分类器的加权投票结果：$$F(x)=sign({\displaystyle{\sum_{t=1}^T\alpha_tG_t(x)}})$$</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">],</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">abc</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">learning_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">abc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>1.0
</code></pre>
<h3 id="gbdt梯度提升决策树">GBDT（梯度提升决策树）
</h3><ul>
<li>Boosting思想 + 决策树 + 梯度下降思想</li>
<li>思想：
<ul>
<li>Gradient：通过梯度下降来最小化损失函数。每一棵树的新建都是为了学习之前所有树组合的预测结果的残差</li>
<li>Boosting：串行集成方法。基学习器一个个依次训练，每一都试图修正前一个的错误。</li>
<li>Decision Tree：使用CART回归树作为弱学习器，不论是分类任务还是回归任务</li>
</ul>
</li>
<li>算法流程：
<ul>
<li>第一步：模型初始化
<ul>
<li>用一个常数来初始化一个非常简单的模型，通常取损失函数最小的常数值。对于平方误差损失，这个值就是目标值的均值。 $$F^{(0)}(x) = \underset{\gamma}{argmin}\displaystyle{\sum_{i=1}^nL(y_i,\gamma)=\frac{1}{n}\sum_{i=1}^ny_i}$$</li>
</ul>
</li>
<li>第二步：循环迭代
<ul>
<li>计算伪残差：对于每条样本1-n，计算当前模型的负梯度: $$\gamma_i^{(m)}=-\displaystyle{[\frac{\partial L(y_i,F(x_i))}{\partial F(x_i)}]|_{F(x)=F^{(m-1)}(x)}}$$
<ul>
<li>对于平方误差损失：$$L=\displaystyle{\frac{1}{2}(y_i-F(x_i))^2}$$。有：$$\gamma_i^{(m)}=y_i-F^{(m-1)}(x_i)$$</li>
</ul>
</li>
<li>使用训练数据$$(x_i,\gamma_i^{(m)})_{i=1}^{n}$$ 训练一颗新的CART回归树 $h^{(m)}(x)$。这棵树的叶节点区域记为 $R_j^{(m)}$，其中 $j=1,2\dots J^{(m)} ,\ J^{(m)}$是第 $m$ 棵树的叶子节点数</li>
<li>为树的每个叶子节点计算最佳输出值：对于第m棵树的每一个叶子节点区域$R_j^{(m)}$。计算一个最佳输出值 $\gamma_j^{(m)}$ 。这个值是这个叶子节点区域内，能使损失函数最小化的值：$$\displaystyle{\gamma_j^{(m)}=\underset{\gamma}{argmin}\sum_{x_i \in R_j^{(m)}}L(y_i,F^{(m-1)}(x_i)+\gamma)}$$。对于平方误差损失，这个值就是落入这个叶节点的所有样本的伪残差的均值。</li>
<li>更新模型。将新树加入到当前模型中，进行更新： $$\displaystyle{F^{(m)}(x) = F^{(m-1)}(x) + \nu · \sum_{j=1}^{J^{(m)}}\gamma_{j}^{(m)}I(x \in R_{j}^{(m)})}$$，其中$\nu$为学习率</li>
</ul>
</li>
<li>得到最终模型：$$\displaystyle{F^{(M)}(x) = F^{(0)}(x) + \nu · \sum_{m=1}^{M}h^{(m)}(x)}$$</li>
</ul>
</li>
<li>GBDT+LR架构
<ul>
<li>思想：
<ul>
<li>GBDT负责：自动进行特征组合和转换。 它将原始的特征向量自动转化为一个新的、更高维的、且具有强表征能力的稀疏特征向量。</li>
<li>LR负责：在新生成的特征向量上进行高效训练。 LR模型简单、可解释性强，并且非常适合处理大规模稀疏特征。</li>
</ul>
</li>
<li>架构详解
<ul>
<li>训练GBDT模型：训练一个含有m个基学习器（决策树），每个基学习器有n个叶子节点（n分类）。输入r维样本x。x分别喂给m个基学习器，最终x一定会落到每个基学习器的某个叶子节点上。创建一个m*n维向量X，依次对应每个学习器的叶子节点。若x落到某个叶子节点，则对应X的位置标为1，未落入的位置标为0。至此，r维的x向量转为mn维的X向量。</li>
<li>将稀疏样本X喂给LR模型进行训练</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:,:],</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">pip</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s1">&#39;scl&#39;</span><span class="p">,</span><span class="n">StandardScaler</span><span class="p">()),</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s1">&#39;gbc&#39;</span><span class="p">,</span><span class="n">GradientBoostingClassifier</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
</span></span><span class="line"><span class="cl">    <span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">pip</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">pip</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">),</span><span class="n">pip</span><span class="p">[</span><span class="s1">&#39;gbc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">feature_importances_</span>
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>(1.0, array([0.00135739, 0.01465991, 0.66567719, 0.31830551]))
</code></pre>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># GBDT + LR</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">GradientBoostingClassifierWithLogisticRegression</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">gbdt_model</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">lr_model</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">gbdt_encoder</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">X_train_leafs</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">X_test_leafs</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">X_encoded</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">train_model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">train_gbdt_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">gbdt_model</span><span class="o">=</span><span class="n">GradientBoostingClassifier</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">n_estimators</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">max_features</span><span class="o">=</span><span class="mf">0.5</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">train_lr_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">lr_model</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">train_gbdt_model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">X_train_leafs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gbdt_model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,:,</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 第0个类别分别落到了哪棵树上</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">gbdt_encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse_output</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">X_encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gbdt_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train_leafs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">train_lr_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_encoded</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">X_test_leafs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gbdt_model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,:,</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">X_test_leafs_enconded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gbdt_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_leafs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_leafs_enconded</span><span class="p">),</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_leafs_enconded</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:,:],</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="o">==</span><span class="mi">2</span>
</span></span><span class="line"><span class="cl">    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">fdbtlr</span><span class="o">=</span><span class="n">GradientBoostingClassifierWithLogisticRegression</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">fdbtlr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">fdbtlr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>(array([False, False, False, False, False,  True, False, False, False,
       False,  True, False, False, False, False, False,  True,  True,
       False,  True, False,  True, False, False,  True, False, False,
       False, False, False,  True, False, False, False, False, False,
       False,  True, False, False,  True, False,  True,  True, False,
       False,  True, False, False, False,  True, False, False, False,
        True, False,  True, False, False,  True, False,  True,  True,
        True,  True, False, False, False,  True,  True, False, False,
       False, False,  True, False,  True,  True, False, False, False,
        True, False,  True, False,  True, False,  True, False, False,
       False, False, False, False, False, False,  True,  True, False,
       False,  True,  True, False,  True, False, False,  True,  True,
       False,  True, False, False,  True,  True, False, False,  True,
       False, False,  True]), 0.975)
(array([False, False,  True, False, False, False, False,  True, False,
       False,  True, False, False, False, False, False,  True, False,
       False,  True, False,  True, False,  True,  True,  True,  True,
        True, False, False]), 1.0)
</code></pre>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/">决策树</a>
        
            <a href="/tags/bagging/">Bagging</a>
        
            <a href="/tags/boosting/">Boosting</a>
        
            <a href="/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/">随机森林</a>
        
            <a href="/tags/oob/">OOB</a>
        
            <a href="/tags/%E8%A2%8B%E5%A4%96%E6%95%B0%E6%8D%AE/">袋外数据</a>
        
            <a href="/tags/adaboost/">AdaBoost</a>
        
            <a href="/tags/gbdt/">GBDT</a>
        
    </section>


    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI&#43;WdtXRGWt2kTvGFasHpSy3SV"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG&#43;vnGctmUb0ZY0l8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        const elementsToRender = [".main-article", ".widget--toc"];

        elementsToRender.forEach(selector => {
            const element = document.querySelector(selector);
            if (element) {
                renderMathInElement(element, {
                    delimiters: [
                        { left: "$$", right: "$$", display: true },
                        { left: "$", right: "$", display: false },
                        { left: "\\(", right: "\\)", display: false },
                        { left: "\\[", right: "\\]", display: true }
                    ],
                    ignoredClasses: ["gist"]
                });
            }
        });
    });
</script>
    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">相关文章</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="has-image">
    <a href="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
        
        
            <div class="article-image">
                <img src="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/60aa0004-c259-49eb-b742-6515691c6d92.a2bc150b77d997c7aa74a554d4c80408_hu_137c9c1a94161db0.png" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post 机器学习-神经网络"
                        
                        data-hash="md5-orwVC3fZl8eqdKVU1MgECA==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">机器学习-神经网络</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">
        
        
            <div class="article-image">
                <img src="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/cover.2160315d961f55820735b9d476c635c6_hu_8fb1533feca001c7.png" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post 机器学习-无监督学习"
                        
                        data-hash="md5-IWAxXZYfVYIHNbnUdsY1xg==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">机器学习-无监督学习</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB/">
        
        
            <div class="article-image">
                <img src="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB/SVM.b96e9ba18f9f55522ce3f1ae5994872a_hu_44707e4e44f0c3f4.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post 机器学习-线性分类"
                        
                        data-hash="md5-uW6boY&#43;fVVIs4/GuWZSHKg==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">机器学习-线性分类</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">
        
        
            <div class="article-image">
                <img src="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/output_45_1.ac66b82ba1a91437f422db6d948e641f_hu_53c0b8df678df0da.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post 机器学习-线性回归"
                        
                        data-hash="md5-rGa4K6GpFDf0ItttlI5kHw==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">机器学习-线性回归</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    <script src="https://utteranc.es/client.js" 
        repo="leuco-yuu/blog-comments"
        issue-term="pathname"
        
        crossorigin="anonymous"
        async
        >
</script>

<style>
    .utterances {
        max-width: unset;
    }
</style>

<script>
    let utterancesLoaded = false;

    function setUtterancesTheme(theme) {
        let utterances = document.querySelector('.utterances iframe');
        if (utterances) {
            utterances.contentWindow.postMessage(
                {
                    type: 'set-theme',
                    theme: `github-${theme}`
                },
                'https://utteranc.es'
            );
        }
    }

    addEventListener('message', event => {
        if (event.origin !== 'https://utteranc.es') return;

        
        utterancesLoaded = true;
        setUtterancesTheme(document.documentElement.dataset.scheme)
    });

    window.addEventListener('onColorSchemeChange', (e) => {
        if (!utterancesLoaded) return;
        setUtterancesTheme(e.detail)
    })
</script>


    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
        2025 Leuco(leucoyuu@163.com)
    </section>
    
    <section class="powerby">
        
            Embrace Bit Art <br/>
        使用 <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> 构建 <br />
        主题 <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.32.0">Stack</a></b> 由 <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a> 设计
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.2c897758e5161d223de0f28f0257464da1d3fdbe7af35af6e4f25cba359b5f26.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

	
	<a id="back-to-top" href="#" title="返回顶部" 
   style="position:fixed; bottom:20px; right:20px; display:none;">↑</a>
	<script src="/js/back-to-top.js"></script>


    </body>
</html>
